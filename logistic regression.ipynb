{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71272368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales(PHQ9_total  GAD7_total STAI_X1_total)- MaDE\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2226775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d48322d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0        ID  Gender  Age  PHQ9_total  GAD7_total STAI_X1_total  \\\n",
      "0             0  YAD30211       1   27          14           9            47   \n",
      "1             1  YAD30504       1   24           3           3            33   \n",
      "2             2  YAD30211       1   26          22          12            47   \n",
      "3             3  YAD30212       1   24          22          10            29   \n",
      "4             4  YAD30213       1   28           8           3            36   \n",
      "..          ...       ...     ...  ...         ...         ...           ...   \n",
      "289         289  MDD20019       1   24          10           8            64   \n",
      "290         290  MDD20020       0   25          10          14            71   \n",
      "291         291  MDD20021       0   31          17          12            62   \n",
      "292         292  MDD20022       0   20          14          11         empty   \n",
      "293         293  MDD20023       1   25           4           0            36   \n",
      "\n",
      "    LSAS_performance_fear LSAS_situation_fear LSAS1_total  ...  \\\n",
      "0                      13                  16          29  ...   \n",
      "1                       6                   5          11  ...   \n",
      "2                      23                  24          47  ...   \n",
      "3                      24                  20          44  ...   \n",
      "4                      12                  10          22  ...   \n",
      "..                    ...                 ...         ...  ...   \n",
      "289                    17                  26          43  ...   \n",
      "290                    10                  17          27  ...   \n",
      "291                    27                  15          42  ...   \n",
      "292                    12                  15          27  ...   \n",
      "293                     0                   1           1  ...   \n",
      "\n",
      "    KSSI_atpt_life_impul    site Visit suicide_risk C1_tod C2_sm C3_si C4_sp  \\\n",
      "0                    0.0  Gachon     2          NaN    NaN   NaN   NaN   NaN   \n",
      "1                    0.0  Gachon     2          NaN    NaN   NaN   NaN   NaN   \n",
      "2                    0.0  Gachon     1          2.0    1.0   0.0   1.0   0.0   \n",
      "3                    0.0  Gachon     1          3.0    1.0   0.0   0.0   1.0   \n",
      "4                    0.0  Gachon     1          1.0    0.0   0.0   0.0   0.0   \n",
      "..                   ...     ...   ...          ...    ...   ...   ...   ...   \n",
      "289                  NaN     SNU     1          1.0    0.0   0.0   0.0   0.0   \n",
      "290                  NaN     SNU     1          2.0    1.0   0.0   1.0   0.0   \n",
      "291                  3.0     SNU     1          2.0    1.0   1.0   1.0   0.0   \n",
      "292                  2.0     SNU     1          2.0    1.0   1.0   1.0   0.0   \n",
      "293                  NaN     SNU     1          1.0    0.0   0.0   0.0   0.0   \n",
      "\n",
      "    C5_sa C6_sa_life  \n",
      "0     NaN        NaN  \n",
      "1     NaN        NaN  \n",
      "2     0.0        0.0  \n",
      "3     1.0        0.0  \n",
      "4     0.0        0.0  \n",
      "..    ...        ...  \n",
      "289   0.0        NaN  \n",
      "290   0.0        NaN  \n",
      "291   0.0        NaN  \n",
      "292   0.0        NaN  \n",
      "293   0.0        NaN  \n",
      "\n",
      "[294 rows x 198 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_labelled = pd.read_csv('./YAD/Labelled+webmini.csv')\n",
    "print(df_labelled)\n",
    "print(type(df_labelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94142997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          No                                        ID  \\\n",
      "0        494  438550c7ec70a9ba62a114e93586f6c4f2490cb2   \n",
      "1        501  09f679c6c3be3da2ba3a6b1f09cfc582a1fd138b   \n",
      "2        505  a73b7ab092df5a28b7ea79e6803a876332fe13dc   \n",
      "3        510  72f26d01617b27d594f3c31647d88732014c010c   \n",
      "4        511  38857c6812e0f37b74db69a9f0910cb3a5b933a2   \n",
      "...      ...                                       ...   \n",
      "17247  30490  840842512161278f5da5628a4f4accd5834fa1ed   \n",
      "17248  30491  c474c86376cd13ba738e36dbf58a09789666ed0b   \n",
      "17249  30492  7819ea09468d5e7d78746728bee2392c70c5ba59   \n",
      "17250  30494  56a4001930985c21ef45a8436a77c6e55833f0b6   \n",
      "17251  30497  f3dc642ddf1b0ab1030d08c19a188086a24bc01a   \n",
      "\n",
      "                                           ID_2 appointment_date  Age  Gender  \\\n",
      "0      54efb2832e5ca9e8b299ce827c112a1c965c14e2       2017-03-24   24       1   \n",
      "1      4b012a3cb9d1866e62bf12c018a05e7896ff5b80       2017-03-24   29       1   \n",
      "2      139991fcc7a5504432014eebaaed80479fb37682       2017-03-27   22       1   \n",
      "3      c58b93a8d851ae8ff73af816cba0689a52958b5c       2017-03-29   28       2   \n",
      "4      de993eea90d5c6124584029ae1bb4121636e9247       2017-03-29   26       1   \n",
      "...                                         ...              ...  ...     ...   \n",
      "17247  5cb2ada3af6cb32bbaecd51883f4baf1aa5376d5       2019-03-14   23       1   \n",
      "17248  21571355a25ef17e95aa0ee8c5b81b48a76feab2       2019-03-19   25       1   \n",
      "17249  155363ae7a9e219a13711d0dfcb96ba081ade06f       2019-03-14   33       1   \n",
      "17250  23986eccce2375bf15b382365e5f5619a69a2124       2019-03-12   25       1   \n",
      "17251  df2ed8fcdd2d0eefb4193009a0bfa1ea78ff51c5       2019-03-19   24       1   \n",
      "\n",
      "       Grade  SMOKING_01  SMOKING_cigar  SMOKING_yrs  ...  KSSI_1y_11  \\\n",
      "0          7           1            NaN          NaN  ...         0.0   \n",
      "1          1           1            NaN          NaN  ...         NaN   \n",
      "2          2           1            NaN          NaN  ...         NaN   \n",
      "3          3           1            NaN          NaN  ...         NaN   \n",
      "4          2           1            NaN          NaN  ...         NaN   \n",
      "...      ...         ...            ...          ...  ...         ...   \n",
      "17247      1           1            NaN          NaN  ...         NaN   \n",
      "17248      4           1            NaN          NaN  ...         NaN   \n",
      "17249      3           1            NaN          NaN  ...         NaN   \n",
      "17250      2           2            NaN          NaN  ...         NaN   \n",
      "17251      1           3            3.0          3.0  ...         NaN   \n",
      "\n",
      "       KSSI_1y_12  KSSI_1y_13  KSSI_1y_14  KSSI_1y_Total  KSSI_atpt_1y  \\\n",
      "0             0.0         0.0         0.0            6.0           0.0   \n",
      "1             NaN         NaN         NaN            NaN           NaN   \n",
      "2             NaN         NaN         NaN            NaN           NaN   \n",
      "3             NaN         NaN         NaN            NaN           NaN   \n",
      "4             NaN         NaN         NaN            NaN           NaN   \n",
      "...           ...         ...         ...            ...           ...   \n",
      "17247         NaN         NaN         NaN            NaN           NaN   \n",
      "17248         NaN         NaN         NaN            NaN           NaN   \n",
      "17249         NaN         NaN         NaN            NaN           NaN   \n",
      "17250         NaN         NaN         NaN            NaN           NaN   \n",
      "17251         NaN         NaN         NaN            NaN           NaN   \n",
      "\n",
      "       KSSI_atpt_life  KSSI_atpt_life_no  KSSI_atpt_life_plan  \\\n",
      "0                 0.0                NaN                  NaN   \n",
      "1                 NaN                NaN                  NaN   \n",
      "2                 NaN                NaN                  NaN   \n",
      "3                 NaN                NaN                  NaN   \n",
      "4                 NaN                NaN                  NaN   \n",
      "...               ...                ...                  ...   \n",
      "17247             NaN                NaN                  NaN   \n",
      "17248             NaN                NaN                  NaN   \n",
      "17249             NaN                NaN                  NaN   \n",
      "17250             NaN                NaN                  NaN   \n",
      "17251             NaN                NaN                  NaN   \n",
      "\n",
      "       KSSI_atpt_life_impul  \n",
      "0                       NaN  \n",
      "1                       NaN  \n",
      "2                       NaN  \n",
      "3                       NaN  \n",
      "4                       NaN  \n",
      "...                     ...  \n",
      "17247                   NaN  \n",
      "17248                   NaN  \n",
      "17249                   NaN  \n",
      "17250                   NaN  \n",
      "17251                   NaN  \n",
      "\n",
      "[17252 rows x 291 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CNDLMembers\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (92) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_unlabelled_K = pd.read_csv('./YAD/Unlabelled_KAIST.csv')\n",
    "print(df_unlabelled_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b34207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No', 'ID', 'ID_2', 'appointment_date', 'Age', 'Gender', 'Grade',\n",
      "       'SMOKING_01', 'SMOKING_cigar', 'SMOKING_yrs',\n",
      "       ...\n",
      "       'KSSI_1y_11', 'KSSI_1y_12', 'KSSI_1y_13', 'KSSI_1y_14', 'KSSI_1y_Total',\n",
      "       'KSSI_atpt_1y', 'KSSI_atpt_life', 'KSSI_atpt_life_no',\n",
      "       'KSSI_atpt_life_plan', 'KSSI_atpt_life_impul'],\n",
      "      dtype='object', length=291)\n"
     ]
    }
   ],
   "source": [
    "print(df_unlabelled_K.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5465a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_labelled['PHQ9_total'].dtypes)\n",
    "print(df_labelled['STAI_X1_total'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a036946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "df_labelled['STAI_X1_total'] = pd.to_numeric(df_labelled['STAI_X1_total'], errors='coerce') \n",
    "\n",
    "print(df_labelled['STAI_X1_total'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1eaee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_labelled = df_labelled[df_labelled['site'].isin(['KAIST', 'Gachon'])]\n",
    "test_df_labelled = df_labelled[df_labelled['site'] == 'SMC']\n",
    "valid_df_labelled = df_labelled[df_labelled['site'] == 'SNU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6de2c1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PHQ9_total  GAD7_total  STAI_X1_total\n",
      "0            14           9           47.0\n",
      "1             3           3           33.0\n",
      "2            22          12           47.0\n",
      "3            22          10           29.0\n",
      "4             8           3           36.0\n",
      "..          ...         ...            ...\n",
      "134           2           5           45.0\n",
      "135           9           2           29.0\n",
      "136           4           2           42.0\n",
      "137          15          14           65.0\n",
      "138           6           2           44.0\n",
      "\n",
      "[139 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x = train_df_labelled.loc[:, ['PHQ9_total', 'GAD7_total', 'STAI_X1_total']]\n",
    "test_x = test_df_labelled.loc[:, ['PHQ9_total', 'GAD7_total', 'STAI_X1_total']]\n",
    "valid_x = valid_df_labelled.loc[:, ['PHQ9_total', 'GAD7_total', 'STAI_X1_total']]\n",
    "\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "783695d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MaDE\n",
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "..    ...\n",
      "134     0\n",
      "135     0\n",
      "136     0\n",
      "137     0\n",
      "138     0\n",
      "\n",
      "[139 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_df_labelled.loc[:, 'MaDE'].to_frame()\n",
    "test_y = test_df_labelled.loc[:, 'MaDE'].to_frame()\n",
    "valid_y = valid_df_labelled.loc[:, 'MaDE'].to_frame()\n",
    "\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8ad8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43c61f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b3c2a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbaf4e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139, 3])\n",
      "torch.DoubleTensor\n",
      "torch.Size([139, 1])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.from_numpy(train_x.values)\n",
    "print(x_train.shape)\n",
    "print(x_train.type())\n",
    "y_train = torch.from_numpy(train_y.values)\n",
    "print(y_train.shape)\n",
    "print(y_train.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6f63403",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))\n",
    "hypothesis = torch.sigmoid(x_train.float().matmul(W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65fc724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis) )\n",
    "cost = losses.mean()\n",
    "\n",
    "F.binary_cross_entropy(hypothesis, y_train.float())  #loss와 cost 따로 정의 안해도 한번에 cost 함수 정의해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e33b4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W, b], lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4748488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/10000 Cost: 0.302783 Accuracy 90.65%\n",
      "Epoch  200/10000 Cost: 0.257963 Accuracy 91.37%\n",
      "Epoch  300/10000 Cost: 0.241786 Accuracy 91.37%\n",
      "Epoch  400/10000 Cost: 0.233764 Accuracy 91.37%\n",
      "Epoch  500/10000 Cost: 0.229082 Accuracy 91.37%\n",
      "Epoch  600/10000 Cost: 0.226056 Accuracy 91.37%\n",
      "Epoch  700/10000 Cost: 0.223957 Accuracy 91.37%\n",
      "Epoch  800/10000 Cost: 0.222421 Accuracy 91.37%\n",
      "Epoch  900/10000 Cost: 0.221252 Accuracy 91.37%\n",
      "Epoch 1000/10000 Cost: 0.220333 Accuracy 91.37%\n",
      "Epoch 1100/10000 Cost: 0.219594 Accuracy 91.37%\n",
      "Epoch 1200/10000 Cost: 0.218987 Accuracy 91.37%\n",
      "Epoch 1300/10000 Cost: 0.218481 Accuracy 91.37%\n",
      "Epoch 1400/10000 Cost: 0.218055 Accuracy 91.37%\n",
      "Epoch 1500/10000 Cost: 0.217692 Accuracy 91.37%\n",
      "Epoch 1600/10000 Cost: 0.217380 Accuracy 91.37%\n",
      "Epoch 1700/10000 Cost: 0.217111 Accuracy 91.37%\n",
      "Epoch 1800/10000 Cost: 0.216878 Accuracy 91.37%\n",
      "Epoch 1900/10000 Cost: 0.216674 Accuracy 91.37%\n",
      "Epoch 2000/10000 Cost: 0.216496 Accuracy 91.37%\n",
      "Epoch 2100/10000 Cost: 0.216340 Accuracy 91.37%\n",
      "Epoch 2200/10000 Cost: 0.216203 Accuracy 91.37%\n",
      "Epoch 2300/10000 Cost: 0.216083 Accuracy 91.37%\n",
      "Epoch 2400/10000 Cost: 0.215976 Accuracy 91.37%\n",
      "Epoch 2500/10000 Cost: 0.215881 Accuracy 91.37%\n",
      "Epoch 2600/10000 Cost: 0.215798 Accuracy 91.37%\n",
      "Epoch 2700/10000 Cost: 0.215724 Accuracy 91.37%\n",
      "Epoch 2800/10000 Cost: 0.215658 Accuracy 91.37%\n",
      "Epoch 2900/10000 Cost: 0.215599 Accuracy 91.37%\n",
      "Epoch 3000/10000 Cost: 0.215547 Accuracy 91.37%\n",
      "Epoch 3100/10000 Cost: 0.215500 Accuracy 91.37%\n",
      "Epoch 3200/10000 Cost: 0.215458 Accuracy 91.37%\n",
      "Epoch 3300/10000 Cost: 0.215421 Accuracy 91.37%\n",
      "Epoch 3400/10000 Cost: 0.215387 Accuracy 91.37%\n",
      "Epoch 3500/10000 Cost: 0.215357 Accuracy 91.37%\n",
      "Epoch 3600/10000 Cost: 0.215330 Accuracy 91.37%\n",
      "Epoch 3700/10000 Cost: 0.215305 Accuracy 91.37%\n",
      "Epoch 3800/10000 Cost: 0.215283 Accuracy 91.37%\n",
      "Epoch 3900/10000 Cost: 0.215263 Accuracy 91.37%\n",
      "Epoch 4000/10000 Cost: 0.215245 Accuracy 91.37%\n",
      "Epoch 4100/10000 Cost: 0.215228 Accuracy 90.65%\n",
      "Epoch 4200/10000 Cost: 0.215213 Accuracy 90.65%\n",
      "Epoch 4300/10000 Cost: 0.215199 Accuracy 90.65%\n",
      "Epoch 4400/10000 Cost: 0.215186 Accuracy 90.65%\n",
      "Epoch 4500/10000 Cost: 0.215174 Accuracy 90.65%\n",
      "Epoch 4600/10000 Cost: 0.215163 Accuracy 90.65%\n",
      "Epoch 4700/10000 Cost: 0.215153 Accuracy 90.65%\n",
      "Epoch 4800/10000 Cost: 0.215144 Accuracy 90.65%\n",
      "Epoch 4900/10000 Cost: 0.215135 Accuracy 90.65%\n",
      "Epoch 5000/10000 Cost: 0.215127 Accuracy 90.65%\n",
      "Epoch 5100/10000 Cost: 0.215119 Accuracy 90.65%\n",
      "Epoch 5200/10000 Cost: 0.215112 Accuracy 90.65%\n",
      "Epoch 5300/10000 Cost: 0.215105 Accuracy 90.65%\n",
      "Epoch 5400/10000 Cost: 0.215099 Accuracy 90.65%\n",
      "Epoch 5500/10000 Cost: 0.215093 Accuracy 90.65%\n",
      "Epoch 5600/10000 Cost: 0.215087 Accuracy 90.65%\n",
      "Epoch 5700/10000 Cost: 0.215081 Accuracy 90.65%\n",
      "Epoch 5800/10000 Cost: 0.215076 Accuracy 90.65%\n",
      "Epoch 5900/10000 Cost: 0.215071 Accuracy 90.65%\n",
      "Epoch 6000/10000 Cost: 0.215066 Accuracy 90.65%\n",
      "Epoch 6100/10000 Cost: 0.215061 Accuracy 90.65%\n",
      "Epoch 6200/10000 Cost: 0.215056 Accuracy 90.65%\n",
      "Epoch 6300/10000 Cost: 0.215052 Accuracy 90.65%\n",
      "Epoch 6400/10000 Cost: 0.215047 Accuracy 90.65%\n",
      "Epoch 6500/10000 Cost: 0.215043 Accuracy 90.65%\n",
      "Epoch 6600/10000 Cost: 0.215038 Accuracy 90.65%\n",
      "Epoch 6700/10000 Cost: 0.215034 Accuracy 90.65%\n",
      "Epoch 6800/10000 Cost: 0.215030 Accuracy 90.65%\n",
      "Epoch 6900/10000 Cost: 0.215026 Accuracy 90.65%\n",
      "Epoch 7000/10000 Cost: 0.215022 Accuracy 90.65%\n",
      "Epoch 7100/10000 Cost: 0.215018 Accuracy 90.65%\n",
      "Epoch 7200/10000 Cost: 0.215014 Accuracy 90.65%\n",
      "Epoch 7300/10000 Cost: 0.215010 Accuracy 90.65%\n",
      "Epoch 7400/10000 Cost: 0.215006 Accuracy 90.65%\n",
      "Epoch 7500/10000 Cost: 0.215003 Accuracy 90.65%\n",
      "Epoch 7600/10000 Cost: 0.214999 Accuracy 90.65%\n",
      "Epoch 7700/10000 Cost: 0.214995 Accuracy 90.65%\n",
      "Epoch 7800/10000 Cost: 0.214991 Accuracy 90.65%\n",
      "Epoch 7900/10000 Cost: 0.214988 Accuracy 90.65%\n",
      "Epoch 8000/10000 Cost: 0.214984 Accuracy 90.65%\n",
      "Epoch 8100/10000 Cost: 0.214980 Accuracy 90.65%\n",
      "Epoch 8200/10000 Cost: 0.214977 Accuracy 90.65%\n",
      "Epoch 8300/10000 Cost: 0.214973 Accuracy 90.65%\n",
      "Epoch 8400/10000 Cost: 0.214970 Accuracy 90.65%\n",
      "Epoch 8500/10000 Cost: 0.214966 Accuracy 90.65%\n",
      "Epoch 8600/10000 Cost: 0.214962 Accuracy 90.65%\n",
      "Epoch 8700/10000 Cost: 0.214959 Accuracy 90.65%\n",
      "Epoch 8800/10000 Cost: 0.214955 Accuracy 90.65%\n",
      "Epoch 8900/10000 Cost: 0.214952 Accuracy 90.65%\n",
      "Epoch 9000/10000 Cost: 0.214948 Accuracy 90.65%\n",
      "Epoch 9100/10000 Cost: 0.214945 Accuracy 90.65%\n",
      "Epoch 9200/10000 Cost: 0.214941 Accuracy 90.65%\n",
      "Epoch 9300/10000 Cost: 0.214938 Accuracy 90.65%\n",
      "Epoch 9400/10000 Cost: 0.214934 Accuracy 90.65%\n",
      "Epoch 9500/10000 Cost: 0.214931 Accuracy 90.65%\n",
      "Epoch 9600/10000 Cost: 0.214927 Accuracy 90.65%\n",
      "Epoch 9700/10000 Cost: 0.214924 Accuracy 90.65%\n",
      "Epoch 9800/10000 Cost: 0.214920 Accuracy 90.65%\n",
      "Epoch 9900/10000 Cost: 0.214916 Accuracy 90.65%\n",
      "Epoch 10000/10000 Cost: 0.214913 Accuracy 90.65%\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10000\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = torch.sigmoid(x_train.float().matmul(W) + b)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train.float())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
    "            epoch, nb_epochs, cost, accuracy * 100\n",
    "        ))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af993617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [False]])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor([[ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True]])\n"
     ]
    }
   ],
   "source": [
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "\n",
    "print(prediction)\n",
    "print(y_train)\n",
    "correct_prediction = prediction.float() == y_train\n",
    "print(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc0728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "226df7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class BinaryClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "    \n",
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e83e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb790c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/10000 Cost: 5.603292 Accuracy 23.02%\n",
      "Epoch  200/10000 Cost: 4.874562 Accuracy 21.58%\n",
      "Epoch  300/10000 Cost: 4.198388 Accuracy 17.99%\n",
      "Epoch  400/10000 Cost: 3.586376 Accuracy 17.27%\n",
      "Epoch  500/10000 Cost: 3.049006 Accuracy 16.55%\n",
      "Epoch  600/10000 Cost: 2.598665 Accuracy 15.83%\n",
      "Epoch  700/10000 Cost: 2.244958 Accuracy 11.51%\n",
      "Epoch  800/10000 Cost: 1.987314 Accuracy 14.39%\n",
      "Epoch  900/10000 Cost: 1.811569 Accuracy 19.42%\n",
      "Epoch 1000/10000 Cost: 1.695841 Accuracy 21.58%\n",
      "Epoch 1100/10000 Cost: 1.619416 Accuracy 23.74%\n",
      "Epoch 1200/10000 Cost: 1.567024 Accuracy 28.06%\n",
      "Epoch 1300/10000 Cost: 1.528828 Accuracy 32.37%\n",
      "Epoch 1400/10000 Cost: 1.498912 Accuracy 34.53%\n",
      "Epoch 1500/10000 Cost: 1.473828 Accuracy 34.53%\n",
      "Epoch 1600/10000 Cost: 1.451587 Accuracy 43.17%\n",
      "Epoch 1700/10000 Cost: 1.431046 Accuracy 43.17%\n",
      "Epoch 1800/10000 Cost: 1.411543 Accuracy 43.88%\n",
      "Epoch 1900/10000 Cost: 1.392696 Accuracy 44.60%\n",
      "Epoch 2000/10000 Cost: 1.374285 Accuracy 44.60%\n",
      "Epoch 2100/10000 Cost: 1.356179 Accuracy 46.04%\n",
      "Epoch 2200/10000 Cost: 1.338302 Accuracy 48.92%\n",
      "Epoch 2300/10000 Cost: 1.320616 Accuracy 50.36%\n",
      "Epoch 2400/10000 Cost: 1.303096 Accuracy 53.24%\n",
      "Epoch 2500/10000 Cost: 1.285731 Accuracy 56.12%\n",
      "Epoch 2600/10000 Cost: 1.268516 Accuracy 57.55%\n",
      "Epoch 2700/10000 Cost: 1.251449 Accuracy 58.27%\n",
      "Epoch 2800/10000 Cost: 1.234532 Accuracy 58.27%\n",
      "Epoch 2900/10000 Cost: 1.217767 Accuracy 58.27%\n",
      "Epoch 3000/10000 Cost: 1.201157 Accuracy 58.99%\n",
      "Epoch 3100/10000 Cost: 1.184707 Accuracy 59.71%\n",
      "Epoch 3200/10000 Cost: 1.168420 Accuracy 61.15%\n",
      "Epoch 3300/10000 Cost: 1.152300 Accuracy 61.87%\n",
      "Epoch 3400/10000 Cost: 1.136353 Accuracy 63.31%\n",
      "Epoch 3500/10000 Cost: 1.120581 Accuracy 63.31%\n",
      "Epoch 3600/10000 Cost: 1.104991 Accuracy 63.31%\n",
      "Epoch 3700/10000 Cost: 1.089585 Accuracy 64.75%\n",
      "Epoch 3800/10000 Cost: 1.074368 Accuracy 64.75%\n",
      "Epoch 3900/10000 Cost: 1.059343 Accuracy 65.47%\n",
      "Epoch 4000/10000 Cost: 1.044515 Accuracy 65.47%\n",
      "Epoch 4100/10000 Cost: 1.029888 Accuracy 66.19%\n",
      "Epoch 4200/10000 Cost: 1.015465 Accuracy 66.19%\n",
      "Epoch 4300/10000 Cost: 1.001249 Accuracy 67.63%\n",
      "Epoch 4400/10000 Cost: 0.987243 Accuracy 67.63%\n",
      "Epoch 4500/10000 Cost: 0.973450 Accuracy 67.63%\n",
      "Epoch 4600/10000 Cost: 0.959873 Accuracy 67.63%\n",
      "Epoch 4700/10000 Cost: 0.946514 Accuracy 69.06%\n",
      "Epoch 4800/10000 Cost: 0.933375 Accuracy 69.06%\n",
      "Epoch 4900/10000 Cost: 0.920457 Accuracy 69.06%\n",
      "Epoch 5000/10000 Cost: 0.907762 Accuracy 69.06%\n",
      "Epoch 5100/10000 Cost: 0.895290 Accuracy 69.78%\n",
      "Epoch 5200/10000 Cost: 0.883043 Accuracy 69.78%\n",
      "Epoch 5300/10000 Cost: 0.871020 Accuracy 69.78%\n",
      "Epoch 5400/10000 Cost: 0.859221 Accuracy 69.78%\n",
      "Epoch 5500/10000 Cost: 0.847647 Accuracy 71.22%\n",
      "Epoch 5600/10000 Cost: 0.836295 Accuracy 72.66%\n",
      "Epoch 5700/10000 Cost: 0.825164 Accuracy 72.66%\n",
      "Epoch 5800/10000 Cost: 0.814255 Accuracy 72.66%\n",
      "Epoch 5900/10000 Cost: 0.803563 Accuracy 72.66%\n",
      "Epoch 6000/10000 Cost: 0.793089 Accuracy 72.66%\n",
      "Epoch 6100/10000 Cost: 0.782829 Accuracy 73.38%\n",
      "Epoch 6200/10000 Cost: 0.772780 Accuracy 74.82%\n",
      "Epoch 6300/10000 Cost: 0.762941 Accuracy 74.82%\n",
      "Epoch 6400/10000 Cost: 0.753308 Accuracy 74.82%\n",
      "Epoch 6500/10000 Cost: 0.743877 Accuracy 74.82%\n",
      "Epoch 6600/10000 Cost: 0.734647 Accuracy 75.54%\n",
      "Epoch 6700/10000 Cost: 0.725613 Accuracy 76.98%\n",
      "Epoch 6800/10000 Cost: 0.716772 Accuracy 76.98%\n",
      "Epoch 6900/10000 Cost: 0.708121 Accuracy 76.98%\n",
      "Epoch 7000/10000 Cost: 0.699655 Accuracy 77.70%\n",
      "Epoch 7100/10000 Cost: 0.691371 Accuracy 77.70%\n",
      "Epoch 7200/10000 Cost: 0.683267 Accuracy 77.70%\n",
      "Epoch 7300/10000 Cost: 0.675336 Accuracy 78.42%\n",
      "Epoch 7400/10000 Cost: 0.667577 Accuracy 79.14%\n",
      "Epoch 7500/10000 Cost: 0.659986 Accuracy 79.14%\n",
      "Epoch 7600/10000 Cost: 0.652558 Accuracy 79.86%\n",
      "Epoch 7700/10000 Cost: 0.645290 Accuracy 79.86%\n",
      "Epoch 7800/10000 Cost: 0.638178 Accuracy 79.86%\n",
      "Epoch 7900/10000 Cost: 0.631219 Accuracy 80.58%\n",
      "Epoch 8000/10000 Cost: 0.624410 Accuracy 80.58%\n",
      "Epoch 8100/10000 Cost: 0.617746 Accuracy 80.58%\n",
      "Epoch 8200/10000 Cost: 0.611224 Accuracy 81.29%\n",
      "Epoch 8300/10000 Cost: 0.604842 Accuracy 81.29%\n",
      "Epoch 8400/10000 Cost: 0.598596 Accuracy 82.01%\n",
      "Epoch 8500/10000 Cost: 0.592482 Accuracy 82.01%\n",
      "Epoch 8600/10000 Cost: 0.586497 Accuracy 82.01%\n",
      "Epoch 8700/10000 Cost: 0.580638 Accuracy 82.73%\n",
      "Epoch 8800/10000 Cost: 0.574903 Accuracy 83.45%\n",
      "Epoch 8900/10000 Cost: 0.569288 Accuracy 84.17%\n",
      "Epoch 9000/10000 Cost: 0.563790 Accuracy 84.17%\n",
      "Epoch 9100/10000 Cost: 0.558407 Accuracy 84.17%\n",
      "Epoch 9200/10000 Cost: 0.553136 Accuracy 84.17%\n",
      "Epoch 9300/10000 Cost: 0.547974 Accuracy 84.17%\n",
      "Epoch 9400/10000 Cost: 0.542918 Accuracy 84.17%\n",
      "Epoch 9500/10000 Cost: 0.537967 Accuracy 84.17%\n",
      "Epoch 9600/10000 Cost: 0.533117 Accuracy 84.17%\n",
      "Epoch 9700/10000 Cost: 0.528366 Accuracy 84.17%\n",
      "Epoch 9800/10000 Cost: 0.523712 Accuracy 84.17%\n",
      "Epoch 9900/10000 Cost: 0.519153 Accuracy 84.17%\n",
      "Epoch 10000/10000 Cost: 0.514685 Accuracy 84.17%\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10000\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = model(x_train.float())\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train.float())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        prediction = hypothesis.float() >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train.float()\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
    "            epoch, nb_epochs, cost, accuracy * 100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2c13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02b26bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 3])\n",
      "torch.DoubleTensor\n",
      "torch.Size([91, 1])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "###Test\n",
    "x_test = torch.from_numpy(test_x.values)\n",
    "print(x_test.shape)\n",
    "print(x_test.type())\n",
    "y_test = torch.from_numpy(test_y.values)\n",
    "print(y_test.shape)\n",
    "print(y_test.type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b1fdc2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-bdaa949374d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PModel' is not defined"
     ]
    }
   ],
   "source": [
    "model_t = PModel()\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False) \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "for epoch in range(501):\n",
    "    y_pred =model(x_test.float())\n",
    "    loss = criterion(y_pred, y_test.float()) \n",
    "    if(epoch%10==0):\n",
    "        print(epoch, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd533ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
