{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "71272368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales - SR\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d2226775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d48322d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0        ID  Gender  Age  PHQ9_total  GAD7_total STAI_X1_total  \\\n",
      "0             0  YAD30211       1   27          14           9            47   \n",
      "1             1  YAD30504       1   24           3           3            33   \n",
      "2             2  YAD30211       1   26          22          12            47   \n",
      "3             3  YAD30212       1   24          22          10            29   \n",
      "4             4  YAD30213       1   28           8           3            36   \n",
      "..          ...       ...     ...  ...         ...         ...           ...   \n",
      "289         289  MDD20019       1   24          10           8            64   \n",
      "290         290  MDD20020       0   25          10          14            71   \n",
      "291         291  MDD20021       0   31          17          12            62   \n",
      "292         292  MDD20022       0   20          14          11         empty   \n",
      "293         293  MDD20023       1   25           4           0            36   \n",
      "\n",
      "    LSAS_performance_fear LSAS_situation_fear LSAS1_total  ...  \\\n",
      "0                      13                  16          29  ...   \n",
      "1                       6                   5          11  ...   \n",
      "2                      23                  24          47  ...   \n",
      "3                      24                  20          44  ...   \n",
      "4                      12                  10          22  ...   \n",
      "..                    ...                 ...         ...  ...   \n",
      "289                    17                  26          43  ...   \n",
      "290                    10                  17          27  ...   \n",
      "291                    27                  15          42  ...   \n",
      "292                    12                  15          27  ...   \n",
      "293                     0                   1           1  ...   \n",
      "\n",
      "    KSSI_atpt_life_impul    site Visit suicide_risk C1_tod C2_sm C3_si C4_sp  \\\n",
      "0                    0.0  Gachon     2          NaN    NaN   NaN   NaN   NaN   \n",
      "1                    0.0  Gachon     2          NaN    NaN   NaN   NaN   NaN   \n",
      "2                    0.0  Gachon     1          2.0    1.0   0.0   1.0   0.0   \n",
      "3                    0.0  Gachon     1          3.0    1.0   0.0   0.0   1.0   \n",
      "4                    0.0  Gachon     1          1.0    0.0   0.0   0.0   0.0   \n",
      "..                   ...     ...   ...          ...    ...   ...   ...   ...   \n",
      "289                  NaN     SNU     1          1.0    0.0   0.0   0.0   0.0   \n",
      "290                  NaN     SNU     1          2.0    1.0   0.0   1.0   0.0   \n",
      "291                  3.0     SNU     1          2.0    1.0   1.0   1.0   0.0   \n",
      "292                  2.0     SNU     1          2.0    1.0   1.0   1.0   0.0   \n",
      "293                  NaN     SNU     1          1.0    0.0   0.0   0.0   0.0   \n",
      "\n",
      "    C5_sa C6_sa_life  \n",
      "0     NaN        NaN  \n",
      "1     NaN        NaN  \n",
      "2     0.0        0.0  \n",
      "3     1.0        0.0  \n",
      "4     0.0        0.0  \n",
      "..    ...        ...  \n",
      "289   0.0        NaN  \n",
      "290   0.0        NaN  \n",
      "291   0.0        NaN  \n",
      "292   0.0        NaN  \n",
      "293   0.0        NaN  \n",
      "\n",
      "[294 rows x 198 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_labelled = pd.read_csv('./YAD/Labelled+webmini.csv')\n",
    "print(df_labelled)\n",
    "print(type(df_labelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "94142997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          No                                        ID  \\\n",
      "0        494  438550c7ec70a9ba62a114e93586f6c4f2490cb2   \n",
      "1        501  09f679c6c3be3da2ba3a6b1f09cfc582a1fd138b   \n",
      "2        505  a73b7ab092df5a28b7ea79e6803a876332fe13dc   \n",
      "3        510  72f26d01617b27d594f3c31647d88732014c010c   \n",
      "4        511  38857c6812e0f37b74db69a9f0910cb3a5b933a2   \n",
      "...      ...                                       ...   \n",
      "17247  30490  840842512161278f5da5628a4f4accd5834fa1ed   \n",
      "17248  30491  c474c86376cd13ba738e36dbf58a09789666ed0b   \n",
      "17249  30492  7819ea09468d5e7d78746728bee2392c70c5ba59   \n",
      "17250  30494  56a4001930985c21ef45a8436a77c6e55833f0b6   \n",
      "17251  30497  f3dc642ddf1b0ab1030d08c19a188086a24bc01a   \n",
      "\n",
      "                                           ID_2 appointment_date  Age  Gender  \\\n",
      "0      54efb2832e5ca9e8b299ce827c112a1c965c14e2       2017-03-24   24       1   \n",
      "1      4b012a3cb9d1866e62bf12c018a05e7896ff5b80       2017-03-24   29       1   \n",
      "2      139991fcc7a5504432014eebaaed80479fb37682       2017-03-27   22       1   \n",
      "3      c58b93a8d851ae8ff73af816cba0689a52958b5c       2017-03-29   28       2   \n",
      "4      de993eea90d5c6124584029ae1bb4121636e9247       2017-03-29   26       1   \n",
      "...                                         ...              ...  ...     ...   \n",
      "17247  5cb2ada3af6cb32bbaecd51883f4baf1aa5376d5       2019-03-14   23       1   \n",
      "17248  21571355a25ef17e95aa0ee8c5b81b48a76feab2       2019-03-19   25       1   \n",
      "17249  155363ae7a9e219a13711d0dfcb96ba081ade06f       2019-03-14   33       1   \n",
      "17250  23986eccce2375bf15b382365e5f5619a69a2124       2019-03-12   25       1   \n",
      "17251  df2ed8fcdd2d0eefb4193009a0bfa1ea78ff51c5       2019-03-19   24       1   \n",
      "\n",
      "       Grade  SMOKING_01  SMOKING_cigar  SMOKING_yrs  ...  KSSI_1y_11  \\\n",
      "0          7           1            NaN          NaN  ...         0.0   \n",
      "1          1           1            NaN          NaN  ...         NaN   \n",
      "2          2           1            NaN          NaN  ...         NaN   \n",
      "3          3           1            NaN          NaN  ...         NaN   \n",
      "4          2           1            NaN          NaN  ...         NaN   \n",
      "...      ...         ...            ...          ...  ...         ...   \n",
      "17247      1           1            NaN          NaN  ...         NaN   \n",
      "17248      4           1            NaN          NaN  ...         NaN   \n",
      "17249      3           1            NaN          NaN  ...         NaN   \n",
      "17250      2           2            NaN          NaN  ...         NaN   \n",
      "17251      1           3            3.0          3.0  ...         NaN   \n",
      "\n",
      "       KSSI_1y_12  KSSI_1y_13  KSSI_1y_14  KSSI_1y_Total  KSSI_atpt_1y  \\\n",
      "0             0.0         0.0         0.0            6.0           0.0   \n",
      "1             NaN         NaN         NaN            NaN           NaN   \n",
      "2             NaN         NaN         NaN            NaN           NaN   \n",
      "3             NaN         NaN         NaN            NaN           NaN   \n",
      "4             NaN         NaN         NaN            NaN           NaN   \n",
      "...           ...         ...         ...            ...           ...   \n",
      "17247         NaN         NaN         NaN            NaN           NaN   \n",
      "17248         NaN         NaN         NaN            NaN           NaN   \n",
      "17249         NaN         NaN         NaN            NaN           NaN   \n",
      "17250         NaN         NaN         NaN            NaN           NaN   \n",
      "17251         NaN         NaN         NaN            NaN           NaN   \n",
      "\n",
      "       KSSI_atpt_life  KSSI_atpt_life_no  KSSI_atpt_life_plan  \\\n",
      "0                 0.0                NaN                  NaN   \n",
      "1                 NaN                NaN                  NaN   \n",
      "2                 NaN                NaN                  NaN   \n",
      "3                 NaN                NaN                  NaN   \n",
      "4                 NaN                NaN                  NaN   \n",
      "...               ...                ...                  ...   \n",
      "17247             NaN                NaN                  NaN   \n",
      "17248             NaN                NaN                  NaN   \n",
      "17249             NaN                NaN                  NaN   \n",
      "17250             NaN                NaN                  NaN   \n",
      "17251             NaN                NaN                  NaN   \n",
      "\n",
      "       KSSI_atpt_life_impul  \n",
      "0                       NaN  \n",
      "1                       NaN  \n",
      "2                       NaN  \n",
      "3                       NaN  \n",
      "4                       NaN  \n",
      "...                     ...  \n",
      "17247                   NaN  \n",
      "17248                   NaN  \n",
      "17249                   NaN  \n",
      "17250                   NaN  \n",
      "17251                   NaN  \n",
      "\n",
      "[17252 rows x 291 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CNDLMembers\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (92) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_unlabelled_K = pd.read_csv('./YAD/Unlabelled_KAIST.csv')\n",
    "print(df_unlabelled_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b34207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No', 'ID', 'ID_2', 'appointment_date', 'Age', 'Gender', 'Grade',\n",
      "       'SMOKING_01', 'SMOKING_cigar', 'SMOKING_yrs',\n",
      "       ...\n",
      "       'KSSI_1y_11', 'KSSI_1y_12', 'KSSI_1y_13', 'KSSI_1y_14', 'KSSI_1y_Total',\n",
      "       'KSSI_atpt_1y', 'KSSI_atpt_life', 'KSSI_atpt_life_no',\n",
      "       'KSSI_atpt_life_plan', 'KSSI_atpt_life_impul'],\n",
      "      dtype='object', length=291)\n"
     ]
    }
   ],
   "source": [
    "print(df_unlabelled_K.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5465a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_labelled['PHQ9_total'].dtypes)\n",
    "print(df_labelled['STAI_X1_total'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9a036946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "df_labelled['STAI_X1_total'] = pd.to_numeric(df_labelled['STAI_X1_total'], errors='coerce') \n",
    "\n",
    "print(df_labelled['STAI_X1_total'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b1eaee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_labelled = df_labelled[df_labelled['site'].isin(['KAIST', 'Gachon'])]\n",
    "test_df_labelled = df_labelled[df_labelled['site'] == 'SMC']\n",
    "valid_df_labelled = df_labelled[df_labelled['site'] == 'SNU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6de2c1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PHQ9_total  GAD7_total  STAI_X1_total\n",
      "0            14           9           47.0\n",
      "1             3           3           33.0\n",
      "2            22          12           47.0\n",
      "3            22          10           29.0\n",
      "4             8           3           36.0\n",
      "..          ...         ...            ...\n",
      "134           2           5           45.0\n",
      "135           9           2           29.0\n",
      "136           4           2           42.0\n",
      "137          15          14           65.0\n",
      "138           6           2           44.0\n",
      "\n",
      "[139 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x = train_df_labelled.loc[:, ['PHQ9_total', 'GAD7_total', 'STAI_X1_total']]\n",
    "test_x = test_df_labelled.loc[:, ['PHQ9_total', 'GAD7_total', 'STAI_X1_total']]\n",
    "valid_x = valid_df_labelled.loc[:, ['PHQ9_total', 'GAD7_total', 'STAI_X1_total']]\n",
    "\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "783695d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    KSSI_total suicidal_idea suicidal_plan suicidal_attempt\n",
      "0           12             1             0                0\n",
      "1            1             0             0                0\n",
      "2           25             1             0                0\n",
      "3           50             1             1                1\n",
      "4            1             0             0                0\n",
      "..         ...           ...           ...              ...\n",
      "134          0             0             0                0\n",
      "135          0             0             0                0\n",
      "136          1             0             0                0\n",
      "137         44             1             1                0\n",
      "138          3             0             0                0\n",
      "\n",
      "[139 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "float64\n",
      "int64\n",
      "int64\n",
      "int64\n",
      "0      13.0\n",
      "1       1.0\n",
      "2      26.0\n",
      "3      53.0\n",
      "4       1.0\n",
      "       ... \n",
      "134     0.0\n",
      "135     0.0\n",
      "136     1.0\n",
      "137    46.0\n",
      "138     3.0\n",
      "Name: sum, Length: 139, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "train_y = train_df_labelled.loc[:, ['KSSI_total', 'suicidal_idea', 'suicidal_plan', 'suicidal_attempt']]\n",
    "test_y = test_df_labelled.loc[:, ['KSSI_total', 'suicidal_idea', 'suicidal_plan', 'suicidal_attempt']]\n",
    "valid_y = valid_df_labelled.loc[:, ['KSSI_total', 'suicidal_idea', 'suicidal_plan', 'suicidal_attempt']]\n",
    "\n",
    "print(train_y)\n",
    "print(type(train_y))\n",
    "print(train_df_labelled['KSSI_total'].dtype)\n",
    "print(train_df_labelled['suicidal_idea'].dtype)\n",
    "print(train_df_labelled['suicidal_plan'].dtype)\n",
    "print(train_df_labelled['suicidal_attempt'].dtype)\n",
    "\n",
    "train_y = train_y.apply(pd.to_numeric, errors='coerce')\n",
    "test_y = test_y.apply(pd.to_numeric, errors='coerce')\n",
    "valid_y = valid_y.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(train_y['KSSI_total'].dtype)\n",
    "print(train_y['suicidal_idea'].dtype)\n",
    "print(train_y['suicidal_plan'].dtype)\n",
    "print(train_y['suicidal_attempt'].dtype)\n",
    "\n",
    "train_y['sum'] = train_y['KSSI_total'] + train_y['suicidal_idea'] + train_y['suicidal_plan'] + train_y['suicidal_attempt']\n",
    "train_y = train_y.iloc[:, 4]\n",
    "#train_y = train_y.drop(['KSSI_total', 'suicidal_idea', 'suicidal_plan', 'suicidal_attempt'], axis=1)\n",
    "print(train_y)\n",
    "print(type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8ad8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "43c61f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3b3c2a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dbaf4e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([139, 3])\n",
      "torch.DoubleTensor\n",
      "torch.Size([139])\n",
      "tensor([[ 13.],\n",
      "        [  1.],\n",
      "        [ 26.],\n",
      "        [ 53.],\n",
      "        [  1.],\n",
      "        [ 39.],\n",
      "        [ 54.],\n",
      "        [ nan],\n",
      "        [ 70.],\n",
      "        [ 97.],\n",
      "        [ 52.],\n",
      "        [ 77.],\n",
      "        [ 10.],\n",
      "        [  5.],\n",
      "        [ 41.],\n",
      "        [ 36.],\n",
      "        [ 27.],\n",
      "        [107.],\n",
      "        [ 14.],\n",
      "        [ 93.],\n",
      "        [ 23.],\n",
      "        [ 24.],\n",
      "        [ 20.],\n",
      "        [ 38.],\n",
      "        [ 51.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  4.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [ 45.],\n",
      "        [ 19.],\n",
      "        [  4.],\n",
      "        [ 43.],\n",
      "        [ 32.],\n",
      "        [ 67.],\n",
      "        [ 59.],\n",
      "        [ 18.],\n",
      "        [ 83.],\n",
      "        [ 26.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  5.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [ 50.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  8.],\n",
      "        [ 14.],\n",
      "        [  0.],\n",
      "        [ 17.],\n",
      "        [  5.],\n",
      "        [ 14.],\n",
      "        [ 33.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  7.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  7.],\n",
      "        [  1.],\n",
      "        [  6.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 15.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  9.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [  4.],\n",
      "        [ 12.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [ 46.],\n",
      "        [  3.]], dtype=torch.float64)\n",
      "torch.Size([139, 1])\n",
      "tensor([[ 13.],\n",
      "        [  1.],\n",
      "        [ 26.],\n",
      "        [ 53.],\n",
      "        [  1.],\n",
      "        [ 39.],\n",
      "        [ 54.],\n",
      "        [  0.],\n",
      "        [ 70.],\n",
      "        [ 97.],\n",
      "        [ 52.],\n",
      "        [ 77.],\n",
      "        [ 10.],\n",
      "        [  5.],\n",
      "        [ 41.],\n",
      "        [ 36.],\n",
      "        [ 27.],\n",
      "        [107.],\n",
      "        [ 14.],\n",
      "        [ 93.],\n",
      "        [ 23.],\n",
      "        [ 24.],\n",
      "        [ 20.],\n",
      "        [ 38.],\n",
      "        [ 51.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  4.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [ 45.],\n",
      "        [ 19.],\n",
      "        [  4.],\n",
      "        [ 43.],\n",
      "        [ 32.],\n",
      "        [ 67.],\n",
      "        [ 59.],\n",
      "        [ 18.],\n",
      "        [ 83.],\n",
      "        [ 26.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  5.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 13.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [ 50.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  8.],\n",
      "        [ 14.],\n",
      "        [  0.],\n",
      "        [ 17.],\n",
      "        [  5.],\n",
      "        [ 14.],\n",
      "        [ 33.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  7.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  7.],\n",
      "        [  1.],\n",
      "        [  6.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [ 15.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  9.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  6.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [  4.],\n",
      "        [ 12.],\n",
      "        [  0.],\n",
      "        [  2.],\n",
      "        [  0.],\n",
      "        [  0.],\n",
      "        [  1.],\n",
      "        [ 46.],\n",
      "        [  3.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.from_numpy(train_x.values)\n",
    "print(x_train.shape)\n",
    "print(x_train.type())\n",
    "y_train = torch.from_numpy(train_y.values)\n",
    "torch.nan_to_num_(x_train)\n",
    "print(y_train.shape)\n",
    "print(y_train.unsqueeze_(1))\n",
    "print(y_train.shape)\n",
    "torch.nan_to_num_(y_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c6f63403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "hypothesis = x_train.float().matmul(W) + b \n",
    "print(hypothesis)\n",
    "# model = nn.Linear(3, 1)\n",
    "# print(hypothesis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "65fc724f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cost = torch.mean((hypothesis - y_train.float())**2)\n",
    "# print(cost.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e33b4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W, b], lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e4748488",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  100/10000 hypothesis: tensor([26.2151,  6.4332, 39.4670, 37.8211, 13.0521, 40.3487, 47.4437,  7.2925,\n",
      "        35.5111, 30.7624, 29.3542, 37.3369, 13.1410, 14.3937, 39.0717, 21.0772,\n",
      "        22.3278, 40.3870, 12.6487, 46.5177, 36.0095, 28.5696, 31.0648, 24.8412,\n",
      "        31.1274, 26.4051,  1.0972,  3.7723, -0.2484, -0.2181, -0.2484,  2.4428,\n",
      "        -0.2666,  1.9748, -0.2362,  0.5988,  1.1336,  6.4311,  2.3882, -0.2726,\n",
      "         0.6534, -0.2241, -0.3030,  5.1098, 34.6982, 28.4888, 24.6014, 42.9792,\n",
      "        17.0565, 26.2535, 23.7381, 12.6386, 33.4355, 32.4286, -0.2302,  5.9691,\n",
      "         2.4246, -0.2120, -0.2302,  1.0790, -0.2726,  4.6963,  2.4610,  1.0972,\n",
      "         1.5128,  2.3943, -0.2241, -0.2848,  0.5988, 18.1899, 11.2020,  3.7824,\n",
      "         5.5071, 10.2659,  2.4671,  2.4732, -0.1635,  6.3887, 14.2724,  1.5552,\n",
      "         2.0294, 16.9555, 32.2204, 19.5295, 29.2652,  8.9788, 13.8912, 24.3933,\n",
      "        24.3711, 10.7865,  2.0415, 23.9070,  1.0912,  2.0172,  5.9348,  8.9667,\n",
      "         5.9509, 12.9510,  5.0916,  1.1700, -0.1149, -0.1271,  0.6959,  7.8617,\n",
      "         2.4368, 12.0371,  7.2723, -0.2362,  8.5957,  2.4792, -0.1817,  6.4514,\n",
      "        30.0437, -0.1877,  1.2004,  1.1640,  0.6656,  3.2779,  5.5617, 20.8872,\n",
      "        13.8993, -0.1149,  1.1276, -0.1513,  1.5188,  3.7460, -0.1635,  1.1458,\n",
      "        -0.1392, -0.2181,  7.2723,  3.7035, -0.1513,  1.9323,  6.7881, 13.5444,\n",
      "         6.8285, 31.8210,  9.4712]) Cost: 219.533417\n",
      "Epochs  200/10000 hypothesis: tensor([29.4622,  5.5415, 46.2425, 45.6015, 13.7217, 47.8321, 57.1982,  6.3772,\n",
      "        41.7715, 36.7506, 34.3573, 44.7402, 14.7615, 15.8291, 46.4210, 24.7057,\n",
      "        25.5252, 47.9368, 13.5661, 55.4181, 43.0526, 34.1414, 35.6946, 27.3360,\n",
      "        36.1428, 31.7135, -1.8003,  2.0805, -3.7455, -3.3162, -3.7455,  0.1448,\n",
      "        -4.0031, -0.7071, -3.5738, -3.0815, -1.2852,  5.2933, -0.6280, -4.0889,\n",
      "        -2.3088, -3.4020, -4.5182,  3.6916, 41.3745, 33.4357, 28.8400, 50.8638,\n",
      "        18.8797, 30.2256, 28.1666, 13.6426, 40.3833, 37.8974, -3.4879,  4.5273,\n",
      "        -0.1128, -3.2303, -3.4879, -2.0579, -4.0889,  3.6125,  0.4024, -1.8003,\n",
      "        -1.4731, -0.5421, -3.4020, -4.2607, -3.0815, 18.4783, 10.4095,  2.0041,\n",
      "         3.7613,  8.7058,  0.4882,  0.5741, -2.5434,  4.6923, 14.1119, -0.8720,\n",
      "         0.0657, 17.6682, 35.3885, 20.3376, 32.6589,  7.3711, 14.0516, 26.3312,\n",
      "        26.2359, 10.0822,  0.2374, 25.2218, -1.8862, -0.1060,  4.2603,  7.1994,\n",
      "         4.2697, 12.5102,  3.4341, -0.7700, -1.8565, -2.0283, -1.7077,  8.4405,\n",
      "         0.0589, 10.9018,  5.8714, -3.5738,  7.7213,  0.6600, -2.8010,  5.7991,\n",
      "        32.7888, -2.8869, -0.3407, -0.8559, -2.1370,  0.6370,  4.5341, 22.4544,\n",
      "        14.3857, -1.8565, -1.3710, -2.3717, -1.3872,  1.4889, -2.5434, -1.1135,\n",
      "        -2.2000, -3.3162,  5.8714,  0.8879, -2.3717, -1.3081,  5.0102, 14.9170,\n",
      "         5.3630, 35.0707,  8.5664]) Cost: 198.830368\n",
      "Epochs  300/10000 hypothesis: tensor([ 3.0336e+01,  5.2904e+00,  4.8094e+01,  4.7755e+01,  1.3934e+01,\n",
      "         4.9745e+01,  5.9731e+01,  6.1053e+00,  4.3401e+01,  3.8415e+01,\n",
      "         3.5628e+01,  4.6711e+01,  1.5291e+01,  1.6199e+01,  4.8407e+01,\n",
      "         2.5769e+01,  2.6420e+01,  4.9985e+01,  1.3882e+01,  5.7733e+01,\n",
      "         4.4917e+01,  3.5699e+01,  3.6894e+01,  2.7939e+01,  3.7565e+01,\n",
      "         3.3264e+01, -2.5691e+00,  1.5963e+00, -4.6850e+00, -4.1473e+00,\n",
      "        -4.6850e+00, -4.5326e-01, -5.0076e+00, -1.4316e+00, -4.4699e+00,\n",
      "        -4.0851e+00, -1.9239e+00,  5.0340e+00, -1.4211e+00, -5.1152e+00,\n",
      "        -3.1173e+00, -4.2548e+00, -5.6529e+00,  3.3483e+00,  4.3190e+01,\n",
      "         3.4706e+01,  3.0129e+01,  5.2901e+01,  1.9487e+01,  3.1237e+01,\n",
      "         2.9463e+01,  1.3924e+01,  4.2324e+01,  3.9333e+01, -4.3624e+00,\n",
      "         4.1632e+00, -7.7589e-01, -4.0397e+00, -4.3624e+00, -2.8918e+00,\n",
      "        -5.1152e+00,  3.3379e+00, -1.3064e-01, -2.5691e+00, -2.3023e+00,\n",
      "        -1.3136e+00, -4.2548e+00, -5.3302e+00, -4.0851e+00,  1.8501e+01,\n",
      "         1.0195e+01,  1.5551e+00,  3.2925e+00,  8.2379e+00, -2.3101e-02,\n",
      "         8.4440e-02, -3.1794e+00,  4.2812e+00,  1.4048e+01, -1.5495e+00,\n",
      "        -4.6370e-01,  1.7916e+01,  3.6082e+01,  2.0509e+01,  3.3610e+01,\n",
      "         6.9411e+00,  1.4170e+01,  2.6878e+01,  2.6704e+01,  9.9277e+00,\n",
      "        -2.4862e-01,  2.5577e+01, -2.6767e+00, -6.7878e-01,  3.7744e+00,\n",
      "         6.7260e+00,  3.8406e+00,  1.2362e+01,  3.0257e+00, -1.2786e+00,\n",
      "        -2.3191e+00, -2.5342e+00, -2.3645e+00,  8.6554e+00, -5.6081e-01,\n",
      "         1.0579e+01,  5.5263e+00, -4.4699e+00,  7.4684e+00,  1.9198e-01,\n",
      "        -3.5020e+00,  5.6130e+00,  3.3432e+01, -3.6096e+00, -7.4094e-01,\n",
      "        -1.3862e+00, -2.9022e+00, -6.8488e-02,  4.2603e+00,  2.2840e+01,\n",
      "         1.4534e+01, -2.3191e+00, -2.0314e+00, -2.9643e+00, -2.1948e+00,\n",
      "         9.0982e-01, -3.1794e+00, -1.7088e+00, -2.7493e+00, -4.1473e+00,\n",
      "         5.5263e+00,  1.5703e-01, -2.9643e+00, -2.1844e+00,  4.4818e+00,\n",
      "         1.5342e+01,  4.9782e+00,  3.5881e+01,  8.3496e+00]) Cost: 197.275986\n",
      "Epochs  400/10000 hypothesis: tensor([ 3.0573e+01,  5.2126e+00,  4.8623e+01,  4.8393e+01,  1.4020e+01,\n",
      "         5.0177e+01,  6.0339e+01,  6.0093e+00,  4.3797e+01,  3.8913e+01,\n",
      "         3.5909e+01,  4.7228e+01,  1.5516e+01,  1.6285e+01,  4.8954e+01,\n",
      "         2.6134e+01,  2.6694e+01,  5.0556e+01,  1.4029e+01,  5.8293e+01,\n",
      "         4.5398e+01,  3.6173e+01,  3.7181e+01,  2.8043e+01,  3.8014e+01,\n",
      "         3.3793e+01, -2.7688e+00,  1.4397e+00, -4.9393e+00, -4.3711e+00,\n",
      "        -4.9393e+00, -5.9822e-01, -5.2803e+00, -1.6311e+00, -4.7120e+00,\n",
      "        -4.3699e+00, -2.0869e+00,  5.0043e+00, -1.6211e+00, -5.3939e+00,\n",
      "        -3.3471e+00, -4.4847e+00, -5.9622e+00,  3.2883e+00,  4.3701e+01,\n",
      "         3.4999e+01,  3.0609e+01,  5.3382e+01,  1.9755e+01,  3.1463e+01,\n",
      "         2.9907e+01,  1.4010e+01,  4.2914e+01,  3.9692e+01, -4.5984e+00,\n",
      "         4.0850e+00, -9.3917e-01, -4.2574e+00, -4.5984e+00, -3.1097e+00,\n",
      "        -5.3939e+00,  3.2782e+00, -2.5727e-01, -2.7688e+00, -2.5504e+00,\n",
      "        -1.5074e+00, -4.4847e+00, -5.6212e+00, -4.3699e+00,  1.8459e+01,\n",
      "         1.0134e+01,  1.4587e+00,  3.1658e+00,  8.0686e+00, -1.4362e-01,\n",
      "        -2.9976e-02, -3.3483e+00,  4.2087e+00,  1.4012e+01, -1.7548e+00,\n",
      "        -6.0828e-01,  1.8031e+01,  3.6131e+01,  2.0516e+01,  3.3902e+01,\n",
      "         6.8261e+00,  1.4267e+01,  2.7048e+01,  2.6801e+01,  9.9160e+00,\n",
      "        -3.8099e-01,  2.5674e+01, -2.8824e+00, -8.3558e-01,  3.6115e+00,\n",
      "         6.5988e+00,  3.7441e+00,  1.2296e+01,  2.9474e+00, -1.4050e+00,\n",
      "        -2.4391e+00, -2.6664e+00, -2.5515e+00,  8.7659e+00, -7.1187e-01,\n",
      "         1.0476e+01,  5.4600e+00, -4.7120e+00,  7.3843e+00,  8.3674e-02,\n",
      "        -3.6892e+00,  5.5536e+00,  3.3524e+01, -3.8029e+00, -8.3675e-01,\n",
      "        -1.5186e+00, -3.1198e+00, -2.5611e-01,  4.1886e+00,  2.2914e+01,\n",
      "         1.4589e+01, -2.4391e+00, -2.2005e+00, -3.1210e+00, -2.4367e+00,\n",
      "         7.7679e-01, -3.3483e+00, -1.8596e+00, -2.8937e+00, -4.3711e+00,\n",
      "         5.4600e+00, -1.8751e-02, -3.1210e+00, -2.4267e+00,  4.2945e+00,\n",
      "         1.5507e+01,  4.8817e+00,  3.6045e+01,  8.3136e+00]) Cost: 197.106674\n",
      "Epochs  500/10000 hypothesis: tensor([ 3.0640e+01,  5.1829e+00,  4.8793e+01,  4.8619e+01,  1.4068e+01,\n",
      "         5.0224e+01,  6.0442e+01,  5.9636e+00,  4.3868e+01,  3.9094e+01,\n",
      "         3.5933e+01,  4.7358e+01,  1.5650e+01,  1.6297e+01,  4.9114e+01,\n",
      "         2.6302e+01,  2.6798e+01,  5.0729e+01,  1.4122e+01,  5.8390e+01,\n",
      "         4.5512e+01,  3.6351e+01,  3.7227e+01,  2.8020e+01,  3.8195e+01,\n",
      "         3.4035e+01, -2.8168e+00,  1.3745e+00, -5.0099e+00, -4.4320e+00,\n",
      "        -5.0099e+00, -6.2367e-01, -5.3567e+00, -1.6894e+00, -4.7788e+00,\n",
      "        -4.4604e+00, -2.1233e+00,  5.0311e+00, -1.6639e+00, -5.4723e+00,\n",
      "        -3.4202e+00, -4.5476e+00, -6.0502e+00,  3.3003e+00,  4.3860e+01,\n",
      "         3.5037e+01,  3.0855e+01,  5.3454e+01,  1.9918e+01,  3.1485e+01,\n",
      "         3.0111e+01,  1.4043e+01,  4.3133e+01,  3.9767e+01, -4.6632e+00,\n",
      "         4.0810e+00, -9.7041e-01, -4.3165e+00, -4.6632e+00, -3.1635e+00,\n",
      "        -5.4723e+00,  3.2748e+00, -2.7693e-01, -2.8168e+00, -2.6395e+00,\n",
      "        -1.5483e+00, -4.5476e+00, -5.7034e+00, -4.4604e+00,  1.8405e+01,\n",
      "         1.0116e+01,  1.4539e+00,  3.1308e+00,  7.9844e+00, -1.6135e-01,\n",
      "        -4.5769e-02, -3.3918e+00,  4.2220e+00,  1.3986e+01, -1.8305e+00,\n",
      "        -6.4916e-01,  1.8105e+01,  3.6025e+01,  2.0483e+01,  3.4011e+01,\n",
      "         6.7952e+00,  1.4350e+01,  2.7113e+01,  2.6803e+01,  9.9385e+00,\n",
      "        -4.1800e-01,  2.5701e+01, -2.9324e+00, -8.8032e-01,  3.5393e+00,\n",
      "         6.5641e+00,  3.7342e+00,  1.2255e+01,  2.9535e+00, -1.4298e+00,\n",
      "        -2.4672e+00, -2.6983e+00, -2.6111e+00,  8.8423e+00, -7.3925e-01,\n",
      "         1.0434e+01,  5.4650e+00, -4.7788e+00,  7.3476e+00,  6.9811e-02,\n",
      "        -3.7386e+00,  5.5296e+00,  3.3477e+01, -3.8541e+00, -8.5194e-01,\n",
      "        -1.5454e+00, -3.1890e+00, -3.0531e-01,  4.1710e+00,  2.2907e+01,\n",
      "         1.4618e+01, -2.4672e+00, -2.2389e+00, -3.1607e+00, -2.5239e+00,\n",
      "         7.6040e-01, -3.3918e+00, -1.8922e+00, -2.9295e+00, -4.4320e+00,\n",
      "         5.4650e+00, -4.8655e-02, -3.1607e+00, -2.4984e+00,  4.2044e+00,\n",
      "         1.5596e+01,  4.8616e+00,  3.6043e+01,  8.3233e+00]) Cost: 197.046143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  600/10000 hypothesis: tensor([ 3.0660e+01,  5.1674e+00,  4.8863e+01,  4.8726e+01,  1.4103e+01,\n",
      "         5.0176e+01,  6.0418e+01,  5.9340e+00,  4.3856e+01,  3.9183e+01,\n",
      "         3.5894e+01,  4.7386e+01,  1.5750e+01,  1.6292e+01,  4.9169e+01,\n",
      "         2.6409e+01,  2.6852e+01,  5.0793e+01,  1.4194e+01,  5.8371e+01,\n",
      "         4.5529e+01,  3.6443e+01,  3.7212e+01,  2.7970e+01,  3.8295e+01,\n",
      "         3.4187e+01, -2.8249e+00,  1.3370e+00, -5.0310e+00, -4.4491e+00,\n",
      "        -5.0310e+00, -6.1869e-01, -5.3802e+00, -1.7091e+00, -4.7983e+00,\n",
      "        -4.4972e+00, -2.1266e+00,  5.0687e+00, -1.6661e+00, -5.4966e+00,\n",
      "        -3.4498e+00, -4.5655e+00, -6.0785e+00,  3.3281e+00,  4.3922e+01,\n",
      "         3.5011e+01,  3.1024e+01,  5.3425e+01,  2.0041e+01,  3.1457e+01,\n",
      "         3.0240e+01,  1.4060e+01,  4.3246e+01,  3.9768e+01, -4.6819e+00,\n",
      "         4.0947e+00, -9.6785e-01, -4.3327e+00, -4.6819e+00, -3.1740e+00,\n",
      "        -5.4966e+00,  3.2851e+00, -2.6954e-01, -2.8249e+00, -2.6832e+00,\n",
      "        -1.5498e+00, -4.5655e+00, -5.7293e+00, -4.4972e+00,  1.8354e+01,\n",
      "         1.0108e+01,  1.4711e+00,  3.1206e+00,  7.9276e+00, -1.5316e-01,\n",
      "        -3.6773e-02, -3.4017e+00,  4.2541e+00,  1.3964e+01, -1.8685e+00,\n",
      "        -6.6168e-01,  1.8161e+01,  3.5892e+01,  2.0443e+01,  3.4068e+01,\n",
      "         6.7866e+00,  1.4422e+01,  2.7148e+01,  2.6781e+01,  9.9668e+00,\n",
      "        -4.2891e-01,  2.5708e+01, -2.9412e+00, -8.9444e-01,  3.4951e+00,\n",
      "         6.5538e+00,  3.7455e+00,  1.2224e+01,  2.9790e+00, -1.4283e+00,\n",
      "        -2.4706e+00, -2.7034e+00, -2.6351e+00,  8.9043e+00, -7.3508e-01,\n",
      "         1.0410e+01,  5.4862e+00, -4.7983e+00,  7.3255e+00,  7.9611e-02,\n",
      "        -3.7508e+00,  5.5166e+00,  3.3402e+01, -3.8672e+00, -8.4634e-01,\n",
      "        -1.5446e+00, -3.2170e+00, -3.1765e-01,  4.1681e+00,  2.2882e+01,\n",
      "         1.4637e+01, -2.4706e+00, -2.2429e+00, -3.1689e+00, -2.5668e+00,\n",
      "         7.7279e-01, -3.4017e+00, -1.8938e+00, -2.9361e+00, -4.4491e+00,\n",
      "         5.4862e+00, -4.1899e-02, -3.1689e+00, -2.5238e+00,  4.1453e+00,\n",
      "         1.5659e+01,  4.8613e+00,  3.6000e+01,  8.3425e+00]) Cost: 197.000641\n",
      "Epochs  700/10000 hypothesis: tensor([ 3.0667e+01,  5.1571e+00,  4.8903e+01,  4.8797e+01,  1.4132e+01,\n",
      "         5.0111e+01,  6.0366e+01,  5.9112e+00,  4.3826e+01,  3.9244e+01,\n",
      "         3.5845e+01,  4.7387e+01,  1.5834e+01,  1.6283e+01,  4.9194e+01,\n",
      "         2.6492e+01,  2.6890e+01,  5.0826e+01,  1.4256e+01,  5.8326e+01,\n",
      "         4.5522e+01,  3.6507e+01,  3.7185e+01,  2.7918e+01,  3.8368e+01,\n",
      "         3.4304e+01, -2.8228e+00,  1.3098e+00, -5.0386e+00, -4.4542e+00,\n",
      "        -5.0386e+00, -6.0696e-01, -5.3893e+00, -1.7180e+00, -4.8049e+00,\n",
      "        -4.5182e+00, -2.1215e+00,  5.1055e+00, -1.6589e+00, -5.5062e+00,\n",
      "        -3.4663e+00, -4.5711e+00, -6.0906e+00,  3.3572e+00,  4.3956e+01,\n",
      "         3.4974e+01,  3.1159e+01,  5.3374e+01,  2.0144e+01,  3.1420e+01,\n",
      "         3.0340e+01,  1.4073e+01,  4.3325e+01,  3.9751e+01, -4.6880e+00,\n",
      "         4.1114e+00, -9.5760e-01, -4.3374e+00, -4.6880e+00, -3.1734e+00,\n",
      "        -5.5062e+00,  3.2981e+00, -2.5632e-01, -2.8228e+00, -2.7122e+00,\n",
      "        -1.5420e+00, -4.5711e+00, -5.7399e+00, -4.5182e+00,  1.8307e+01,\n",
      "         1.0104e+01,  1.4920e+00,  3.1172e+00,  7.8822e+00, -1.3944e-01,\n",
      "        -2.2560e-02, -3.4023e+00,  4.2874e+00,  1.3945e+01, -1.8940e+00,\n",
      "        -6.6608e-01,  1.8209e+01,  3.5764e+01,  2.0406e+01,  3.4106e+01,\n",
      "         6.7836e+00,  1.4484e+01,  2.7172e+01,  2.6756e+01,  9.9936e+00,\n",
      "        -4.3232e-01,  2.5710e+01, -2.9397e+00, -8.9984e-01,  3.4616e+00,\n",
      "         6.5499e+00,  3.7607e+00,  1.2197e+01,  3.0066e+00, -1.4202e+00,\n",
      "        -2.4673e+00, -2.7011e+00, -2.6482e+00,  8.9577e+00, -7.2384e-01,\n",
      "         1.0391e+01,  5.5091e+00, -4.8049e+00,  7.3089e+00,  9.4320e-02,\n",
      "        -3.7530e+00,  5.5077e+00,  3.3327e+01, -3.8699e+00, -8.3585e-01,\n",
      "        -1.5371e+00, -3.2326e+00, -3.2031e-01,  4.1691e+00,  2.2855e+01,\n",
      "         1.4653e+01, -2.4673e+00, -2.2384e+00, -3.1686e+00, -2.5953e+00,\n",
      "         7.9073e-01, -3.4023e+00, -1.8878e+00, -2.9348e+00, -4.4542e+00,\n",
      "         5.5091e+00, -2.7431e-02, -3.1686e+00, -2.5362e+00,  4.0989e+00,\n",
      "         1.5711e+01,  4.8655e+00,  3.5952e+01,  8.3622e+00]) Cost: 196.961792\n",
      "Epochs  800/10000 hypothesis: tensor([ 3.0670e+01,  5.1491e+00,  4.8932e+01,  4.8853e+01,  1.4157e+01,\n",
      "         5.0047e+01,  6.0312e+01,  5.8923e+00,  4.3795e+01,  3.9292e+01,\n",
      "         3.5798e+01,  4.7382e+01,  1.5906e+01,  1.6274e+01,  4.9210e+01,\n",
      "         2.6563e+01,  2.6920e+01,  5.0848e+01,  1.4309e+01,  5.8279e+01,\n",
      "         4.5510e+01,  3.6559e+01,  3.7157e+01,  2.7870e+01,  3.8427e+01,\n",
      "         3.4403e+01, -2.8185e+00,  1.2877e+00, -5.0424e+00, -4.4560e+00,\n",
      "        -5.0424e+00, -5.9463e-01, -5.3943e+00, -1.7234e+00, -4.8079e+00,\n",
      "        -4.5338e+00, -2.1148e+00,  5.1388e+00, -1.6502e+00, -5.5116e+00,\n",
      "        -3.4782e+00, -4.5733e+00, -6.0980e+00,  3.3840e+00,  4.3980e+01,\n",
      "         3.4938e+01,  3.1274e+01,  5.3322e+01,  2.0232e+01,  3.1384e+01,\n",
      "         3.0424e+01,  1.4084e+01,  4.3388e+01,  3.9733e+01, -4.6906e+00,\n",
      "         4.1273e+00, -9.4649e-01, -4.3387e+00, -4.6906e+00, -3.1704e+00,\n",
      "        -5.5116e+00,  3.3108e+00, -2.4277e-01, -2.8185e+00, -2.7350e+00,\n",
      "        -1.5329e+00, -4.5733e+00, -5.7462e+00, -4.5338e+00,  1.8265e+01,\n",
      "         1.0101e+01,  1.5120e+00,  3.1157e+00,  7.8434e+00, -1.2548e-01,\n",
      "        -8.1920e-03, -3.4004e+00,  4.3178e+00,  1.3929e+01, -1.9140e+00,\n",
      "        -6.6786e-01,  1.8249e+01,  3.5648e+01,  2.0372e+01,  3.4136e+01,\n",
      "         6.7820e+00,  1.4539e+01,  2.7190e+01,  2.6731e+01,  1.0017e+01,\n",
      "        -4.3329e-01,  2.5709e+01, -2.9358e+00, -9.0244e-01,  3.4339e+00,\n",
      "         6.5475e+00,  3.7754e+00,  1.2174e+01,  3.0322e+00, -1.4111e+00,\n",
      "        -2.4621e+00, -2.6967e+00, -2.6572e+00,  9.0047e+00, -7.1191e-01,\n",
      "         1.0375e+01,  5.5302e+00, -4.8079e+00,  7.2952e+00,  1.0909e-01,\n",
      "        -3.7523e+00,  5.5010e+00,  3.3257e+01, -3.8696e+00, -8.2466e-01,\n",
      "        -1.5284e+00, -3.2436e+00, -3.2055e-01,  4.1713e+00,  2.2830e+01,\n",
      "         1.4666e+01, -2.4621e+00, -2.2321e+00, -3.1658e+00, -2.6177e+00,\n",
      "         8.0827e-01, -3.4004e+00, -1.8802e+00, -2.9313e+00, -4.4560e+00,\n",
      "         5.5302e+00, -1.2737e-02, -3.1658e+00, -2.5445e+00,  4.0598e+00,\n",
      "         1.5755e+01,  4.8705e+00,  3.5906e+01,  8.3800e+00]) Cost: 196.927689\n",
      "Epochs  900/10000 hypothesis: tensor([ 3.0672e+01,  5.1428e+00,  4.8955e+01,  4.8900e+01,  1.4179e+01,\n",
      "         4.9991e+01,  6.0264e+01,  5.8764e+00,  4.3767e+01,  3.9333e+01,\n",
      "         3.5757e+01,  4.7377e+01,  1.5970e+01,  1.6267e+01,  4.9223e+01,\n",
      "         2.6624e+01,  2.6946e+01,  5.0865e+01,  1.4355e+01,  5.8236e+01,\n",
      "         4.5499e+01,  3.6604e+01,  3.7132e+01,  2.7827e+01,  3.8477e+01,\n",
      "         3.4488e+01, -2.8141e+00,  1.2693e+00, -5.0450e+00, -4.4567e+00,\n",
      "        -5.0450e+00, -5.8319e-01, -5.3980e+00, -1.7275e+00, -4.8097e+00,\n",
      "        -4.5468e+00, -2.1081e+00,  5.1682e+00, -1.6422e+00, -5.5157e+00,\n",
      "        -3.4878e+00, -4.5744e+00, -6.1040e+00,  3.4080e+00,  4.4000e+01,\n",
      "         3.4905e+01,  3.1374e+01,  5.3276e+01,  2.0309e+01,  3.1353e+01,\n",
      "         3.0497e+01,  1.4094e+01,  4.3442e+01,  3.9715e+01, -4.6920e+00,\n",
      "         4.1416e+00, -9.3619e-01, -4.3390e+00, -4.6920e+00, -3.1671e+00,\n",
      "        -5.5157e+00,  3.3226e+00, -2.3020e-01, -2.8141e+00, -2.7542e+00,\n",
      "        -1.5245e+00, -4.5744e+00, -5.7510e+00, -4.5468e+00,  1.8228e+01,\n",
      "         1.0098e+01,  1.5301e+00,  3.1149e+00,  7.8095e+00, -1.1253e-01,\n",
      "         5.1336e-03, -3.3977e+00,  4.3446e+00,  1.3914e+01, -1.9305e+00,\n",
      "        -6.6855e-01,  1.8283e+01,  3.5546e+01,  2.0341e+01,  3.4160e+01,\n",
      "         6.7806e+00,  1.4585e+01,  2.7205e+01,  2.6708e+01,  1.0038e+01,\n",
      "        -4.3322e-01,  2.5707e+01, -2.9318e+00, -9.0388e-01,  3.4101e+00,\n",
      "         6.5453e+00,  3.7886e+00,  1.2154e+01,  3.0550e+00, -1.4021e+00,\n",
      "        -2.4564e+00, -2.6917e+00, -2.6641e+00,  9.0465e+00, -7.0086e-01,\n",
      "         1.0361e+01,  5.5488e+00, -4.8097e+00,  7.2836e+00,  1.2280e-01,\n",
      "        -3.7507e+00,  5.4958e+00,  3.3196e+01, -3.8684e+00, -8.1380e-01,\n",
      "        -1.5198e+00, -3.2525e+00, -3.2027e-01,  4.1739e+00,  2.2807e+01,\n",
      "         1.4678e+01, -2.4564e+00, -2.2258e+00, -3.1624e+00, -2.6365e+00,\n",
      "         8.2407e-01, -3.3977e+00, -1.8728e+00, -2.9270e+00, -4.4567e+00,\n",
      "         5.5488e+00,  4.1160e-04, -3.1624e+00, -2.5512e+00,  4.0260e+00,\n",
      "         1.5794e+01,  4.8751e+00,  3.5865e+01,  8.3956e+00]) Cost: 196.897232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1000/10000 hypothesis: tensor([ 3.0673e+01,  5.1377e+00,  4.8975e+01,  4.8941e+01,  1.4199e+01,\n",
      "         4.9941e+01,  6.0222e+01,  5.8628e+00,  4.3741e+01,  3.9369e+01,\n",
      "         3.5720e+01,  4.7373e+01,  1.6025e+01,  1.6261e+01,  4.9233e+01,\n",
      "         2.6677e+01,  2.6969e+01,  5.0880e+01,  1.4395e+01,  5.8198e+01,\n",
      "         4.5490e+01,  3.6643e+01,  3.7109e+01,  2.7790e+01,  3.8520e+01,\n",
      "         3.4563e+01, -2.8100e+00,  1.2537e+00, -5.0471e+00, -4.4570e+00,\n",
      "        -5.0471e+00, -5.7293e-01, -5.4012e+00, -1.7309e+00, -4.8111e+00,\n",
      "        -4.5581e+00, -2.1018e+00,  5.1941e+00, -1.6352e+00, -5.5192e+00,\n",
      "        -3.4958e+00, -4.5750e+00, -6.1094e+00,  3.4291e+00,  4.4017e+01,\n",
      "         3.4877e+01,  3.1460e+01,  5.3235e+01,  2.0376e+01,  3.1325e+01,\n",
      "         3.0561e+01,  1.4103e+01,  4.3489e+01,  3.9700e+01, -4.6930e+00,\n",
      "         4.1542e+00, -9.2702e-01, -4.3389e+00, -4.6930e+00, -3.1641e+00,\n",
      "        -5.5192e+00,  3.3335e+00, -2.1884e-01, -2.8100e+00, -2.7708e+00,\n",
      "        -1.5172e+00, -4.5750e+00, -5.7553e+00, -4.5581e+00,  1.8195e+01,\n",
      "         1.0095e+01,  1.5461e+00,  3.1143e+00,  7.7795e+00, -1.0081e-01,\n",
      "         1.7224e-02, -3.3947e+00,  4.3679e+00,  1.3901e+01, -1.9446e+00,\n",
      "        -6.6859e-01,  1.8313e+01,  3.5456e+01,  2.0314e+01,  3.4181e+01,\n",
      "         6.7791e+00,  1.4626e+01,  2.7217e+01,  2.6688e+01,  1.0056e+01,\n",
      "        -4.3253e-01,  2.5705e+01, -2.9281e+00, -9.0465e-01,  3.3896e+00,\n",
      "         6.5431e+00,  3.8001e+00,  1.2136e+01,  3.0750e+00, -1.3937e+00,\n",
      "        -2.4504e+00, -2.6865e+00, -2.6696e+00,  9.0836e+00, -6.9096e-01,\n",
      "         1.0348e+01,  5.5651e+00, -4.8111e+00,  7.2736e+00,  1.3525e-01,\n",
      "        -3.7488e+00,  5.4918e+00,  3.3141e+01, -3.8668e+00, -8.0350e-01,\n",
      "        -1.5117e+00, -3.2598e+00, -3.1999e-01,  4.1766e+00,  2.2787e+01,\n",
      "         1.4688e+01, -2.4504e+00, -2.2199e+00, -3.1586e+00, -2.6527e+00,\n",
      "         8.3795e-01, -3.3947e+00, -1.8658e+00, -2.9226e+00, -4.4570e+00,\n",
      "         5.5651e+00,  1.1732e-02, -3.1586e+00, -2.5571e+00,  3.9966e+00,\n",
      "         1.5829e+01,  4.8793e+00,  3.5827e+01,  8.4092e+00]) Cost: 196.869537\n",
      "Epochs 1100/10000 hypothesis: tensor([ 3.0674e+01,  5.1337e+00,  4.8991e+01,  4.8977e+01,  1.4216e+01,\n",
      "         4.9898e+01,  6.0185e+01,  5.8512e+00,  4.3720e+01,  3.9400e+01,\n",
      "         3.5689e+01,  4.7369e+01,  1.6075e+01,  1.6257e+01,  4.9242e+01,\n",
      "         2.6724e+01,  2.6989e+01,  5.0893e+01,  1.4431e+01,  5.8165e+01,\n",
      "         4.5481e+01,  3.6677e+01,  3.7089e+01,  2.7756e+01,  3.8558e+01,\n",
      "         3.4629e+01, -2.8064e+00,  1.2405e+00, -5.0489e+00, -4.4570e+00,\n",
      "        -5.0489e+00, -5.6380e-01, -5.4041e+00, -1.7337e+00, -4.8122e+00,\n",
      "        -4.5682e+00, -2.0960e+00,  5.2168e+00, -1.6293e+00, -5.5225e+00,\n",
      "        -3.5027e+00, -4.5754e+00, -6.1144e+00,  3.4478e+00,  4.4032e+01,\n",
      "         3.4853e+01,  3.1536e+01,  5.3199e+01,  2.0434e+01,  3.1301e+01,\n",
      "         3.0617e+01,  1.4111e+01,  4.3530e+01,  3.9687e+01, -4.6938e+00,\n",
      "         4.1653e+00, -9.1896e-01, -4.3386e+00, -4.6938e+00, -3.1615e+00,\n",
      "        -5.5225e+00,  3.3434e+00, -2.0863e-01, -2.8064e+00, -2.7851e+00,\n",
      "        -1.5109e+00, -4.5754e+00, -5.7593e+00, -4.5682e+00,  1.8166e+01,\n",
      "         1.0093e+01,  1.5604e+00,  3.1139e+00,  7.7530e+00, -9.0239e-02,\n",
      "         2.8151e-02, -3.3915e+00,  4.3881e+00,  1.3889e+01, -1.9564e+00,\n",
      "        -6.6816e-01,  1.8339e+01,  3.5377e+01,  2.0290e+01,  3.4198e+01,\n",
      "         6.7775e+00,  1.4661e+01,  2.7226e+01,  2.6670e+01,  1.0072e+01,\n",
      "        -4.3138e-01,  2.5701e+01, -2.9248e+00, -9.0494e-01,  3.3719e+00,\n",
      "         6.5407e+00,  3.8102e+00,  1.2120e+01,  3.0926e+00, -1.3857e+00,\n",
      "        -2.4444e+00, -2.6812e+00, -2.6740e+00,  9.1168e+00, -6.8218e-01,\n",
      "         1.0337e+01,  5.5792e+00, -4.8122e+00,  7.2651e+00,  1.4654e-01,\n",
      "        -3.7467e+00,  5.4889e+00,  3.3092e+01, -3.8651e+00, -7.9375e-01,\n",
      "        -1.5041e+00, -3.2659e+00, -3.1981e-01,  4.1794e+00,  2.2769e+01,\n",
      "         1.4696e+01, -2.4444e+00, -2.2144e+00, -3.1547e+00, -2.6667e+00,\n",
      "         8.5005e-01, -3.3915e+00, -1.8593e+00, -2.9179e+00, -4.4570e+00,\n",
      "         5.5792e+00,  2.1330e-02, -3.1547e+00, -2.5624e+00,  3.9710e+00,\n",
      "         1.5859e+01,  4.8829e+00,  3.5794e+01,  8.4209e+00]) Cost: 196.843979\n",
      "Epochs 1200/10000 hypothesis: tensor([ 3.0674e+01,  5.1306e+00,  4.9005e+01,  4.9009e+01,  1.4230e+01,\n",
      "         4.9860e+01,  6.0153e+01,  5.8415e+00,  4.3701e+01,  3.9428e+01,\n",
      "         3.5662e+01,  4.7366e+01,  1.6118e+01,  1.6253e+01,  4.9250e+01,\n",
      "         2.6765e+01,  2.7007e+01,  5.0904e+01,  1.4462e+01,  5.8136e+01,\n",
      "         4.5475e+01,  3.6707e+01,  3.7071e+01,  2.7727e+01,  3.8590e+01,\n",
      "         3.4686e+01, -2.8031e+00,  1.2294e+00, -5.0506e+00, -4.4569e+00,\n",
      "        -5.0506e+00, -5.5567e-01, -5.4068e+00, -1.7360e+00, -4.8131e+00,\n",
      "        -4.5772e+00, -2.0907e+00,  5.2367e+00, -1.6244e+00, -5.5255e+00,\n",
      "        -3.5085e+00, -4.5756e+00, -6.1193e+00,  3.4643e+00,  4.4046e+01,\n",
      "         3.4833e+01,  3.1602e+01,  5.3168e+01,  2.0485e+01,  3.1281e+01,\n",
      "         3.0666e+01,  1.4119e+01,  4.3567e+01,  3.9675e+01, -4.6944e+00,\n",
      "         4.1751e+00, -9.1190e-01, -4.3381e+00, -4.6944e+00, -3.1594e+00,\n",
      "        -5.5255e+00,  3.3526e+00, -1.9945e-01, -2.8031e+00, -2.7976e+00,\n",
      "        -1.5056e+00, -4.5756e+00, -5.7630e+00, -4.5772e+00,  1.8140e+01,\n",
      "         1.0090e+01,  1.5730e+00,  3.1135e+00,  7.7296e+00, -8.0706e-02,\n",
      "         3.8036e-02, -3.3882e+00,  4.4055e+00,  1.3878e+01, -1.9664e+00,\n",
      "        -6.6734e-01,  1.8361e+01,  3.5307e+01,  2.0268e+01,  3.4212e+01,\n",
      "         6.7757e+00,  1.4691e+01,  2.7234e+01,  2.6653e+01,  1.0085e+01,\n",
      "        -4.2985e-01,  2.5697e+01, -2.9219e+00, -9.0482e-01,  3.3565e+00,\n",
      "         6.5382e+00,  3.8189e+00,  1.2106e+01,  3.1080e+00, -1.3782e+00,\n",
      "        -2.4383e+00, -2.6757e+00, -2.6773e+00,  9.1466e+00, -6.7442e-01,\n",
      "         1.0326e+01,  5.5914e+00, -4.8131e+00,  7.2577e+00,  1.5678e-01,\n",
      "        -3.7444e+00,  5.4868e+00,  3.3048e+01, -3.8632e+00, -7.8451e-01,\n",
      "        -1.4970e+00, -3.2710e+00, -3.1976e-01,  4.1822e+00,  2.2753e+01,\n",
      "         1.4704e+01, -2.4383e+00, -2.2094e+00, -3.1507e+00, -2.6789e+00,\n",
      "         8.6058e-01, -3.3882e+00, -1.8532e+00, -2.9132e+00, -4.4569e+00,\n",
      "         5.5914e+00,  2.9387e-02, -3.1507e+00, -2.5672e+00,  3.9487e+00,\n",
      "         1.5886e+01,  4.8860e+00,  3.5764e+01,  8.4310e+00]) Cost: 196.820053\n",
      "Epochs 1300/10000 hypothesis: tensor([ 3.0674e+01,  5.1283e+00,  4.9017e+01,  4.9036e+01,  1.4244e+01,\n",
      "         4.9828e+01,  6.0126e+01,  5.8333e+00,  4.3684e+01,  3.9453e+01,\n",
      "         3.5639e+01,  4.7364e+01,  1.6156e+01,  1.6250e+01,  4.9257e+01,\n",
      "         2.6802e+01,  2.7022e+01,  5.0913e+01,  1.4490e+01,  5.8111e+01,\n",
      "         4.5469e+01,  3.6734e+01,  3.7056e+01,  2.7701e+01,  3.8618e+01,\n",
      "         3.4737e+01, -2.8002e+00,  1.2202e+00, -5.0520e+00, -4.4566e+00,\n",
      "        -5.0520e+00, -5.4845e-01, -5.4093e+00, -1.7380e+00, -4.8139e+00,\n",
      "        -4.5852e+00, -2.0857e+00,  5.2542e+00, -1.6203e+00, -5.5284e+00,\n",
      "        -3.5134e+00, -4.5757e+00, -6.1239e+00,  3.4788e+00,  4.4058e+01,\n",
      "         3.4815e+01,  3.1660e+01,  5.3140e+01,  2.0530e+01,  3.1263e+01,\n",
      "         3.0710e+01,  1.4126e+01,  4.3599e+01,  3.9665e+01, -4.6948e+00,\n",
      "         4.1838e+00, -9.0572e-01, -4.3375e+00, -4.6948e+00, -3.1575e+00,\n",
      "        -5.5284e+00,  3.3611e+00, -1.9118e-01, -2.8002e+00, -2.8084e+00,\n",
      "        -1.5012e+00, -4.5757e+00, -5.7666e+00, -4.5852e+00,  1.8116e+01,\n",
      "         1.0088e+01,  1.5843e+00,  3.1133e+00,  7.7087e+00, -7.2085e-02,\n",
      "         4.7005e-02, -3.3848e+00,  4.4206e+00,  1.3869e+01, -1.9748e+00,\n",
      "        -6.6617e-01,  1.8379e+01,  3.5245e+01,  2.0249e+01,  3.4224e+01,\n",
      "         6.7737e+00,  1.4717e+01,  2.7240e+01,  2.6638e+01,  1.0096e+01,\n",
      "        -4.2799e-01,  2.5693e+01, -2.9193e+00, -9.0436e-01,  3.3433e+00,\n",
      "         6.5356e+00,  3.8265e+00,  1.2093e+01,  3.1215e+00, -1.3712e+00,\n",
      "        -2.4321e+00, -2.6702e+00, -2.6798e+00,  9.1733e+00, -6.6754e-01,\n",
      "         1.0316e+01,  5.6019e+00, -4.8139e+00,  7.2515e+00,  1.6609e-01,\n",
      "        -3.7421e+00,  5.4856e+00,  3.3010e+01, -3.8611e+00, -7.7571e-01,\n",
      "        -1.4903e+00, -3.2752e+00, -3.1982e-01,  4.1851e+00,  2.2739e+01,\n",
      "         1.4710e+01, -2.4321e+00, -2.2048e+00, -3.1466e+00, -2.6893e+00,\n",
      "         8.6972e-01, -3.3848e+00, -1.8475e+00, -2.9084e+00, -4.4566e+00,\n",
      "         5.6019e+00,  3.6090e-02, -3.1466e+00, -2.5716e+00,  3.9292e+00,\n",
      "         1.5910e+01,  4.8888e+00,  3.5737e+01,  8.4396e+00]) Cost: 196.797394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1400/10000 hypothesis: tensor([ 3.0674e+01,  5.1267e+00,  4.9027e+01,  4.9061e+01,  1.4255e+01,\n",
      "         4.9800e+01,  6.0103e+01,  5.8265e+00,  4.3670e+01,  3.9475e+01,\n",
      "         3.5620e+01,  4.7362e+01,  1.6190e+01,  1.6249e+01,  4.9263e+01,\n",
      "         2.6834e+01,  2.7036e+01,  5.0921e+01,  1.4514e+01,  5.8089e+01,\n",
      "         4.5465e+01,  3.6758e+01,  3.7043e+01,  2.7678e+01,  3.8642e+01,\n",
      "         3.4782e+01, -2.7977e+00,  1.2125e+00, -5.0534e+00, -4.4562e+00,\n",
      "        -5.0534e+00, -5.4200e-01, -5.4117e+00, -1.7396e+00, -4.8145e+00,\n",
      "        -4.5925e+00, -2.0811e+00,  5.2696e+00, -1.6169e+00, -5.5311e+00,\n",
      "        -3.5176e+00, -4.5756e+00, -6.1283e+00,  3.4916e+00,  4.4069e+01,\n",
      "         3.4801e+01,  3.1710e+01,  5.3117e+01,  2.0568e+01,  3.1248e+01,\n",
      "         3.0748e+01,  1.4133e+01,  4.3628e+01,  3.9657e+01, -4.6951e+00,\n",
      "         4.1914e+00, -9.0031e-01, -4.3368e+00, -4.6951e+00, -3.1560e+00,\n",
      "        -5.5311e+00,  3.3689e+00, -1.8370e-01, -2.7977e+00, -2.8178e+00,\n",
      "        -1.4975e+00, -4.5756e+00, -5.7700e+00, -4.5925e+00,  1.8096e+01,\n",
      "         1.0085e+01,  1.5942e+00,  3.1132e+00,  7.6902e+00, -6.4266e-02,\n",
      "         5.5168e-02, -3.3813e+00,  4.4335e+00,  1.3860e+01, -1.9818e+00,\n",
      "        -6.6472e-01,  1.8395e+01,  3.5191e+01,  2.0232e+01,  3.4233e+01,\n",
      "         6.7717e+00,  1.4740e+01,  2.7244e+01,  2.6624e+01,  1.0106e+01,\n",
      "        -4.2585e-01,  2.5688e+01, -2.9171e+00, -9.0359e-01,  3.3319e+00,\n",
      "         6.5328e+00,  3.8331e+00,  1.2082e+01,  3.1333e+00, -1.3645e+00,\n",
      "        -2.4258e+00, -2.6647e+00, -2.6815e+00,  9.1973e+00, -6.6144e-01,\n",
      "         1.0307e+01,  5.6110e+00, -4.8145e+00,  7.2461e+00,  1.7460e-01,\n",
      "        -3.7396e+00,  5.4850e+00,  3.2975e+01, -3.8590e+00, -7.6731e-01,\n",
      "        -1.4839e+00, -3.2787e+00, -3.1999e-01,  4.1881e+00,  2.2726e+01,\n",
      "         1.4716e+01, -2.4258e+00, -2.2005e+00, -3.1424e+00, -2.6984e+00,\n",
      "         8.7764e-01, -3.3813e+00, -1.8422e+00, -2.9036e+00, -4.4562e+00,\n",
      "         5.6110e+00,  4.1602e-02, -3.1424e+00, -2.5757e+00,  3.9122e+00,\n",
      "         1.5931e+01,  4.8911e+00,  3.5712e+01,  8.4470e+00]) Cost: 196.775742\n",
      "Epochs 1500/10000 hypothesis: tensor([ 3.0674e+01,  5.1257e+00,  4.9036e+01,  4.9083e+01,  1.4266e+01,\n",
      "         4.9776e+01,  6.0083e+01,  5.8208e+00,  4.3658e+01,  3.9494e+01,\n",
      "         3.5603e+01,  4.7361e+01,  1.6220e+01,  1.6248e+01,  4.9268e+01,\n",
      "         2.6862e+01,  2.7048e+01,  5.0929e+01,  1.4536e+01,  5.8070e+01,\n",
      "         4.5462e+01,  3.6780e+01,  3.7031e+01,  2.7658e+01,  3.8663e+01,\n",
      "         3.4821e+01, -2.7954e+00,  1.2063e+00, -5.0546e+00, -4.4557e+00,\n",
      "        -5.0546e+00, -5.3625e-01, -5.4139e+00, -1.7410e+00, -4.8150e+00,\n",
      "        -4.5990e+00, -2.0768e+00,  5.2831e+00, -1.6142e+00, -5.5337e+00,\n",
      "        -3.5211e+00, -4.5755e+00, -6.1325e+00,  3.5030e+00,  4.4078e+01,\n",
      "         3.4788e+01,  3.1754e+01,  5.3096e+01,  2.0602e+01,  3.1235e+01,\n",
      "         3.0782e+01,  1.4139e+01,  4.3653e+01,  3.9649e+01, -4.6953e+00,\n",
      "         4.1981e+00, -8.9557e-01, -4.3359e+00, -4.6953e+00, -3.1547e+00,\n",
      "        -5.5337e+00,  3.3762e+00, -1.7692e-01, -2.7954e+00, -2.8260e+00,\n",
      "        -1.4944e+00, -4.5755e+00, -5.7732e+00, -4.5990e+00,  1.8077e+01,\n",
      "         1.0083e+01,  1.6031e+00,  3.1131e+00,  7.6736e+00, -5.7147e-02,\n",
      "         6.2627e-02, -3.3777e+00,  4.4446e+00,  1.3852e+01, -1.9875e+00,\n",
      "        -6.6301e-01,  1.8408e+01,  3.5143e+01,  2.0216e+01,  3.4241e+01,\n",
      "         6.7695e+00,  1.4759e+01,  2.7247e+01,  2.6611e+01,  1.0114e+01,\n",
      "        -4.2347e-01,  2.5683e+01, -2.9152e+00, -9.0256e-01,  3.3221e+00,\n",
      "         6.5299e+00,  3.8388e+00,  1.2072e+01,  3.1437e+00, -1.3581e+00,\n",
      "        -2.4195e+00, -2.6591e+00, -2.6826e+00,  9.2191e+00, -6.5602e-01,\n",
      "         1.0299e+01,  5.6188e+00, -4.8150e+00,  7.2416e+00,  1.8240e-01,\n",
      "        -3.7371e+00,  5.4851e+00,  3.2944e+01, -3.8568e+00, -7.5924e-01,\n",
      "        -1.4779e+00, -3.2815e+00, -3.2024e-01,  4.1911e+00,  2.2715e+01,\n",
      "         1.4721e+01, -2.4195e+00, -2.1965e+00, -3.1382e+00, -2.7062e+00,\n",
      "         8.8450e-01, -3.3777e+00, -1.8372e+00, -2.8986e+00, -4.4557e+00,\n",
      "         5.6188e+00,  4.6076e-02, -3.1382e+00, -2.5794e+00,  3.8975e+00,\n",
      "         1.5949e+01,  4.8932e+00,  3.5690e+01,  8.4533e+00]) Cost: 196.754837\n",
      "Epochs 1600/10000 hypothesis: tensor([ 3.0673e+01,  5.1253e+00,  4.9043e+01,  4.9102e+01,  1.4275e+01,\n",
      "         4.9755e+01,  6.0066e+01,  5.8163e+00,  4.3648e+01,  3.9512e+01,\n",
      "         3.5589e+01,  4.7361e+01,  1.6246e+01,  1.6247e+01,  4.9273e+01,\n",
      "         2.6888e+01,  2.7059e+01,  5.0935e+01,  1.4555e+01,  5.8054e+01,\n",
      "         4.5459e+01,  3.6799e+01,  3.7020e+01,  2.7641e+01,  3.8681e+01,\n",
      "         3.4856e+01, -2.7934e+00,  1.2013e+00, -5.0557e+00, -4.4551e+00,\n",
      "        -5.0557e+00, -5.3109e-01, -5.4160e+00, -1.7421e+00, -4.8155e+00,\n",
      "        -4.6049e+00, -2.0727e+00,  5.2949e+00, -1.6121e+00, -5.5361e+00,\n",
      "        -3.5239e+00, -4.5752e+00, -6.1367e+00,  3.5130e+00,  4.4087e+01,\n",
      "         3.4778e+01,  3.1792e+01,  5.3078e+01,  2.0631e+01,  3.1224e+01,\n",
      "         3.0812e+01,  1.4145e+01,  4.3676e+01,  3.9643e+01, -4.6953e+00,\n",
      "         4.2040e+00, -8.9143e-01, -4.3350e+00, -4.6953e+00, -3.1537e+00,\n",
      "        -5.5361e+00,  3.3831e+00, -1.7076e-01, -2.7934e+00, -2.8330e+00,\n",
      "        -1.4920e+00, -4.5752e+00, -5.7764e+00, -4.6049e+00,  1.8060e+01,\n",
      "         1.0081e+01,  1.6111e+00,  3.1131e+00,  7.6588e+00, -5.0645e-02,\n",
      "         6.9467e-02, -3.3741e+00,  4.4541e+00,  1.3845e+01, -1.9922e+00,\n",
      "        -6.6108e-01,  1.8419e+01,  3.5100e+01,  2.0202e+01,  3.4247e+01,\n",
      "         6.7672e+00,  1.4775e+01,  2.7249e+01,  2.6599e+01,  1.0120e+01,\n",
      "        -4.2086e-01,  2.5678e+01, -2.9135e+00, -9.0131e-01,  3.3138e+00,\n",
      "         6.5270e+00,  3.8437e+00,  1.2063e+01,  3.1527e+00, -1.3520e+00,\n",
      "        -2.4132e+00, -2.6534e+00, -2.6832e+00,  9.2388e+00, -6.5120e-01,\n",
      "         1.0291e+01,  5.6255e+00, -4.8155e+00,  7.2378e+00,  1.8958e-01,\n",
      "        -3.7344e+00,  5.4856e+00,  3.2917e+01, -3.8546e+00, -7.5148e-01,\n",
      "        -1.4722e+00, -3.2837e+00, -3.2058e-01,  4.1941e+00,  2.2705e+01,\n",
      "         1.4726e+01, -2.4132e+00, -2.1928e+00, -3.1339e+00, -2.7129e+00,\n",
      "         8.9042e-01, -3.3741e+00, -1.8325e+00, -2.8937e+00, -4.4551e+00,\n",
      "         5.6255e+00,  4.9636e-02, -3.1339e+00, -2.5829e+00,  3.8846e+00,\n",
      "         1.5966e+01,  4.8950e+00,  3.5669e+01,  8.4587e+00]) Cost: 196.734512\n",
      "Epochs 1700/10000 hypothesis: tensor([ 3.0672e+01,  5.1253e+00,  4.9048e+01,  4.9119e+01,  1.4283e+01,\n",
      "         4.9737e+01,  6.0051e+01,  5.8126e+00,  4.3639e+01,  3.9527e+01,\n",
      "         3.5577e+01,  4.7361e+01,  1.6270e+01,  1.6248e+01,  4.9277e+01,\n",
      "         2.6910e+01,  2.7068e+01,  5.0940e+01,  1.4571e+01,  5.8039e+01,\n",
      "         4.5457e+01,  3.6816e+01,  3.7011e+01,  2.7625e+01,  3.8696e+01,\n",
      "         3.4886e+01, -2.7916e+00,  1.1974e+00, -5.0567e+00, -4.4545e+00,\n",
      "        -5.0567e+00, -5.2646e-01, -5.4180e+00, -1.7430e+00, -4.8158e+00,\n",
      "        -4.6103e+00, -2.0689e+00,  5.3053e+00, -1.6105e+00, -5.5385e+00,\n",
      "        -3.5263e+00, -4.5749e+00, -6.1407e+00,  3.5220e+00,  4.4095e+01,\n",
      "         3.4770e+01,  3.1826e+01,  5.3063e+01,  2.0656e+01,  3.1215e+01,\n",
      "         3.0838e+01,  1.4150e+01,  4.3696e+01,  3.9638e+01, -4.6953e+00,\n",
      "         4.2092e+00, -8.8780e-01, -4.3340e+00, -4.6953e+00, -3.1529e+00,\n",
      "        -5.5385e+00,  3.3895e+00, -1.6512e-01, -2.7916e+00, -2.8390e+00,\n",
      "        -1.4900e+00, -4.5749e+00, -5.7794e+00, -4.6103e+00,  1.8045e+01,\n",
      "         1.0079e+01,  1.6182e+00,  3.1132e+00,  7.6455e+00, -4.4678e-02,\n",
      "         7.5769e-02, -3.3704e+00,  4.4622e+00,  1.3839e+01, -1.9959e+00,\n",
      "        -6.5896e-01,  1.8428e+01,  3.5062e+01,  2.0190e+01,  3.4251e+01,\n",
      "         6.7649e+00,  1.4789e+01,  2.7250e+01,  2.6588e+01,  1.0126e+01,\n",
      "        -4.1807e-01,  2.5672e+01, -2.9120e+00, -8.9985e-01,  3.3066e+00,\n",
      "         6.5240e+00,  3.8479e+00,  1.2055e+01,  3.1606e+00, -1.3462e+00,\n",
      "        -2.4069e+00, -2.6478e+00, -2.6832e+00,  9.2567e+00, -6.4691e-01,\n",
      "         1.0284e+01,  5.6312e+00, -4.8158e+00,  7.2346e+00,  1.9622e-01,\n",
      "        -3.7318e+00,  5.4867e+00,  3.2892e+01, -3.8522e+00, -7.4399e-01,\n",
      "        -1.4667e+00, -3.2854e+00, -3.2099e-01,  4.1972e+00,  2.2696e+01,\n",
      "         1.4729e+01, -2.4069e+00, -2.1893e+00, -3.1295e+00, -2.7186e+00,\n",
      "         8.9553e-01, -3.3704e+00, -1.8280e+00, -2.8887e+00, -4.4545e+00,\n",
      "         5.6312e+00,  5.2401e-02, -3.1295e+00, -2.5861e+00,  3.8734e+00,\n",
      "         1.5981e+01,  4.8965e+00,  3.5651e+01,  8.4632e+00]) Cost: 196.714691\n",
      "Epochs 1800/10000 hypothesis: tensor([ 3.0671e+01,  5.1258e+00,  4.9053e+01,  4.9134e+01,  1.4290e+01,\n",
      "         4.9722e+01,  6.0039e+01,  5.8097e+00,  4.3631e+01,  3.9541e+01,\n",
      "         3.5567e+01,  4.7362e+01,  1.6290e+01,  1.6248e+01,  4.9281e+01,\n",
      "         2.6930e+01,  2.7076e+01,  5.0944e+01,  1.4586e+01,  5.8027e+01,\n",
      "         4.5456e+01,  3.6831e+01,  3.7003e+01,  2.7611e+01,  3.8709e+01,\n",
      "         3.4913e+01, -2.7900e+00,  1.1944e+00, -5.0576e+00, -4.4537e+00,\n",
      "        -5.0576e+00, -5.2230e-01, -5.4200e+00, -1.7437e+00, -4.8161e+00,\n",
      "        -4.6152e+00, -2.0653e+00,  5.3145e+00, -1.6093e+00, -5.5407e+00,\n",
      "        -3.5282e+00, -4.5745e+00, -6.1446e+00,  3.5299e+00,  4.4102e+01,\n",
      "         3.4763e+01,  3.1855e+01,  5.3049e+01,  2.0678e+01,  3.1207e+01,\n",
      "         3.0861e+01,  1.4156e+01,  4.3714e+01,  3.9633e+01, -4.6953e+00,\n",
      "         4.2139e+00, -8.8463e-01, -4.3329e+00, -4.6953e+00, -3.1523e+00,\n",
      "        -5.5407e+00,  3.3955e+00, -1.5996e-01, -2.7900e+00, -2.8443e+00,\n",
      "        -1.4885e+00, -4.5745e+00, -5.7823e+00, -4.6152e+00,  1.8031e+01,\n",
      "         1.0076e+01,  1.6246e+00,  3.1133e+00,  7.6336e+00, -3.9185e-02,\n",
      "         8.1594e-02, -3.3667e+00,  4.4690e+00,  1.3833e+01, -1.9988e+00,\n",
      "        -6.5666e-01,  1.8436e+01,  3.5029e+01,  2.0178e+01,  3.4254e+01,\n",
      "         6.7624e+00,  1.4800e+01,  2.7250e+01,  2.6578e+01,  1.0131e+01,\n",
      "        -4.1511e-01,  2.5666e+01, -2.9107e+00, -8.9822e-01,  3.3005e+00,\n",
      "         6.5209e+00,  3.8515e+00,  1.2048e+01,  3.1676e+00, -1.3406e+00,\n",
      "        -2.4005e+00, -2.6421e+00, -2.6828e+00,  9.2730e+00, -6.4308e-01,\n",
      "         1.0277e+01,  5.6361e+00, -4.8161e+00,  7.2320e+00,  2.0237e-01,\n",
      "        -3.7291e+00,  5.4881e+00,  3.2870e+01, -3.8498e+00, -7.3673e-01,\n",
      "        -1.4614e+00, -3.2867e+00, -3.2146e-01,  4.2003e+00,  2.2688e+01,\n",
      "         1.4732e+01, -2.4005e+00, -2.1861e+00, -3.1252e+00, -2.7235e+00,\n",
      "         8.9991e-01, -3.3667e+00, -1.8237e+00, -2.8836e+00, -4.4537e+00,\n",
      "         5.6361e+00,  5.4466e-02, -3.1252e+00, -2.5891e+00,  3.8637e+00,\n",
      "         1.5995e+01,  4.8978e+00,  3.5634e+01,  8.4669e+00]) Cost: 196.695190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1900/10000 hypothesis: tensor([ 3.0670e+01,  5.1266e+00,  4.9056e+01,  4.9147e+01,  1.4296e+01,\n",
      "         4.9709e+01,  6.0029e+01,  5.8076e+00,  4.3625e+01,  3.9553e+01,\n",
      "         3.5559e+01,  4.7363e+01,  1.6309e+01,  1.6249e+01,  4.9284e+01,\n",
      "         2.6947e+01,  2.7084e+01,  5.0948e+01,  1.4599e+01,  5.8016e+01,\n",
      "         4.5456e+01,  3.6845e+01,  3.6996e+01,  2.7599e+01,  3.8720e+01,\n",
      "         3.4937e+01, -2.7885e+00,  1.1922e+00, -5.0585e+00, -4.4529e+00,\n",
      "        -5.0585e+00, -5.1854e-01, -5.4218e+00, -1.7442e+00, -4.8163e+00,\n",
      "        -4.6197e+00, -2.0619e+00,  5.3225e+00, -1.6085e+00, -5.5429e+00,\n",
      "        -3.5297e+00, -4.5740e+00, -6.1484e+00,  3.5370e+00,  4.4109e+01,\n",
      "         3.4757e+01,  3.1880e+01,  5.3038e+01,  2.0697e+01,  3.1201e+01,\n",
      "         3.0882e+01,  1.4161e+01,  4.3730e+01,  3.9629e+01, -4.6952e+00,\n",
      "         4.2180e+00, -8.8186e-01, -4.3318e+00, -4.6952e+00, -3.1518e+00,\n",
      "        -5.5429e+00,  3.4013e+00, -1.5521e-01, -2.7885e+00, -2.8487e+00,\n",
      "        -1.4874e+00, -4.5740e+00, -5.7851e+00, -4.6197e+00,  1.8019e+01,\n",
      "         1.0074e+01,  1.6303e+00,  3.1134e+00,  7.6229e+00, -3.4104e-02,\n",
      "         8.7005e-02, -3.3630e+00,  4.4748e+00,  1.3827e+01, -2.0010e+00,\n",
      "        -6.5422e-01,  1.8442e+01,  3.4999e+01,  2.0168e+01,  3.4256e+01,\n",
      "         6.7599e+00,  1.4810e+01,  2.7249e+01,  2.6569e+01,  1.0134e+01,\n",
      "        -4.1200e-01,  2.5660e+01, -2.9096e+00, -8.9644e-01,  3.2954e+00,\n",
      "         6.5177e+00,  3.8546e+00,  1.2042e+01,  3.1736e+00, -1.3352e+00,\n",
      "        -2.3941e+00, -2.6363e+00, -2.6820e+00,  9.2880e+00, -6.3964e-01,\n",
      "         1.0271e+01,  5.6402e+00, -4.8163e+00,  7.2298e+00,  2.0811e-01,\n",
      "        -3.7263e+00,  5.4899e+00,  3.2849e+01, -3.8474e+00, -7.2967e-01,\n",
      "        -1.4563e+00, -3.2875e+00, -3.2198e-01,  4.2034e+00,  2.2680e+01,\n",
      "         1.4735e+01, -2.3941e+00, -2.1830e+00, -3.1207e+00, -2.7276e+00,\n",
      "         9.0368e-01, -3.3630e+00, -1.8196e+00, -2.8785e+00, -4.4529e+00,\n",
      "         5.6402e+00,  5.5921e-02, -3.1207e+00, -2.5919e+00,  3.8553e+00,\n",
      "         1.6007e+01,  4.8990e+00,  3.5618e+01,  8.4700e+00]) Cost: 196.675949\n",
      "Epochs 2000/10000 hypothesis: tensor([ 3.0669e+01,  5.1277e+00,  4.9059e+01,  4.9159e+01,  1.4302e+01,\n",
      "         4.9698e+01,  6.0021e+01,  5.8060e+00,  4.3619e+01,  3.9565e+01,\n",
      "         3.5553e+01,  4.7364e+01,  1.6326e+01,  1.6251e+01,  4.9287e+01,\n",
      "         2.6963e+01,  2.7090e+01,  5.0951e+01,  1.4610e+01,  5.8007e+01,\n",
      "         4.5456e+01,  3.6857e+01,  3.6990e+01,  2.7588e+01,  3.8730e+01,\n",
      "         3.4959e+01, -2.7872e+00,  1.1907e+00, -5.0593e+00, -4.4521e+00,\n",
      "        -5.0593e+00, -5.1513e-01, -5.4236e+00, -1.7446e+00, -4.8164e+00,\n",
      "        -4.6238e+00, -2.0586e+00,  5.3296e+00, -1.6081e+00, -5.5450e+00,\n",
      "        -3.5309e+00, -4.5735e+00, -6.1522e+00,  3.5433e+00,  4.4114e+01,\n",
      "         3.4753e+01,  3.1902e+01,  5.3027e+01,  2.0713e+01,  3.1196e+01,\n",
      "         3.0900e+01,  1.4166e+01,  4.3744e+01,  3.9626e+01, -4.6950e+00,\n",
      "         4.2216e+00, -8.7944e-01, -4.3307e+00, -4.6950e+00, -3.1515e+00,\n",
      "        -5.5450e+00,  3.4068e+00, -1.5082e-01, -2.7872e+00, -2.8526e+00,\n",
      "        -1.4866e+00, -4.5735e+00, -5.7879e+00, -4.6238e+00,  1.8008e+01,\n",
      "         1.0072e+01,  1.6355e+00,  3.1136e+00,  7.6132e+00, -2.9385e-02,\n",
      "         9.2051e-02, -3.3592e+00,  4.4796e+00,  1.3822e+01, -2.0025e+00,\n",
      "        -6.5165e-01,  1.8447e+01,  3.4972e+01,  2.0158e+01,  3.4257e+01,\n",
      "         6.7574e+00,  1.4818e+01,  2.7248e+01,  2.6560e+01,  1.0137e+01,\n",
      "        -4.0878e-01,  2.5654e+01, -2.9086e+00, -8.9452e-01,  3.2911e+00,\n",
      "         6.5145e+00,  3.8573e+00,  1.2036e+01,  3.1790e+00, -1.3300e+00,\n",
      "        -2.3877e+00, -2.6306e+00, -2.6808e+00,  9.3018e+00, -6.3656e-01,\n",
      "         1.0265e+01,  5.6436e+00, -4.8164e+00,  7.2281e+00,  2.1349e-01,\n",
      "        -3.7235e+00,  5.4920e+00,  3.2831e+01, -3.8449e+00, -7.2279e-01,\n",
      "        -1.4514e+00, -3.2880e+00, -3.2255e-01,  4.2065e+00,  2.2673e+01,\n",
      "         1.4738e+01, -2.3877e+00, -2.1800e+00, -3.1163e+00, -2.7311e+00,\n",
      "         9.0689e-01, -3.3592e+00, -1.8157e+00, -2.8734e+00, -4.4521e+00,\n",
      "         5.6436e+00,  5.6842e-02, -3.1163e+00, -2.5946e+00,  3.8480e+00,\n",
      "         1.6017e+01,  4.8999e+00,  3.5604e+01,  8.4726e+00]) Cost: 196.656952\n",
      "Epochs 2100/10000 hypothesis: tensor([ 3.0667e+01,  5.1291e+00,  4.9061e+01,  4.9170e+01,  1.4307e+01,\n",
      "         4.9688e+01,  6.0014e+01,  5.8050e+00,  4.3615e+01,  3.9575e+01,\n",
      "         3.5548e+01,  4.7365e+01,  1.6341e+01,  1.6253e+01,  4.9289e+01,\n",
      "         2.6977e+01,  2.7096e+01,  5.0954e+01,  1.4621e+01,  5.7999e+01,\n",
      "         4.5456e+01,  3.6868e+01,  3.6984e+01,  2.7578e+01,  3.8737e+01,\n",
      "         3.4977e+01, -2.7860e+00,  1.1899e+00, -5.0600e+00, -4.4512e+00,\n",
      "        -5.0600e+00, -5.1203e-01, -5.4253e+00, -1.7448e+00, -4.8165e+00,\n",
      "        -4.6276e+00, -2.0555e+00,  5.3359e+00, -1.6079e+00, -5.5471e+00,\n",
      "        -3.5318e+00, -4.5730e+00, -6.1559e+00,  3.5489e+00,  4.4120e+01,\n",
      "         3.4750e+01,  3.1921e+01,  5.3019e+01,  2.0727e+01,  3.1191e+01,\n",
      "         3.0916e+01,  1.4170e+01,  4.3757e+01,  3.9624e+01, -4.6947e+00,\n",
      "         4.2248e+00, -8.7732e-01, -4.3294e+00, -4.6947e+00, -3.1513e+00,\n",
      "        -5.5471e+00,  3.4120e+00, -1.4675e-01, -2.7860e+00, -2.8558e+00,\n",
      "        -1.4861e+00, -4.5730e+00, -5.7906e+00, -4.6276e+00,  1.7998e+01,\n",
      "         1.0070e+01,  1.6402e+00,  3.1138e+00,  7.6044e+00, -2.4984e-02,\n",
      "         9.6778e-02, -3.3554e+00,  4.4835e+00,  1.3818e+01, -2.0035e+00,\n",
      "        -6.4896e-01,  1.8451e+01,  3.4949e+01,  2.0150e+01,  3.4257e+01,\n",
      "         6.7548e+00,  1.4825e+01,  2.7246e+01,  2.6552e+01,  1.0140e+01,\n",
      "        -4.0544e-01,  2.5648e+01, -2.9078e+00, -8.9249e-01,  3.2875e+00,\n",
      "         6.5113e+00,  3.8595e+00,  1.2031e+01,  3.1836e+00, -1.3249e+00,\n",
      "        -2.3813e+00, -2.6248e+00, -2.6794e+00,  9.3145e+00, -6.3379e-01,\n",
      "         1.0259e+01,  5.6465e+00, -4.8165e+00,  7.2267e+00,  2.1854e-01,\n",
      "        -3.7206e+00,  5.4944e+00,  3.2814e+01, -3.8424e+00, -7.1607e-01,\n",
      "        -1.4466e+00, -3.2882e+00, -3.2316e-01,  4.2097e+00,  2.2667e+01,\n",
      "         1.4740e+01, -2.3813e+00, -2.1772e+00, -3.1118e+00, -2.7341e+00,\n",
      "         9.0963e-01, -3.3554e+00, -1.8119e+00, -2.8683e+00, -4.4512e+00,\n",
      "         5.6465e+00,  5.7294e-02, -3.1118e+00, -2.5972e+00,  3.8417e+00,\n",
      "         1.6027e+01,  4.9007e+00,  3.5590e+01,  8.4746e+00]) Cost: 196.638199\n",
      "Epochs 2200/10000 hypothesis: tensor([ 3.0666e+01,  5.1307e+00,  4.9062e+01,  4.9179e+01,  1.4312e+01,\n",
      "         4.9681e+01,  6.0009e+01,  5.8045e+00,  4.3611e+01,  3.9584e+01,\n",
      "         3.5544e+01,  4.7367e+01,  1.6354e+01,  1.6255e+01,  4.9291e+01,\n",
      "         2.6990e+01,  2.7102e+01,  5.0957e+01,  1.4630e+01,  5.7992e+01,\n",
      "         4.5457e+01,  3.6878e+01,  3.6980e+01,  2.7569e+01,  3.8744e+01,\n",
      "         3.4994e+01, -2.7850e+00,  1.1897e+00, -5.0607e+00, -4.4503e+00,\n",
      "        -5.0607e+00, -5.0920e-01, -5.4270e+00, -1.7450e+00, -4.8165e+00,\n",
      "        -4.6311e+00, -2.0524e+00,  5.3414e+00, -1.6080e+00, -5.5491e+00,\n",
      "        -3.5324e+00, -4.5724e+00, -6.1595e+00,  3.5540e+00,  4.4125e+01,\n",
      "         3.4748e+01,  3.1937e+01,  5.3011e+01,  2.0739e+01,  3.1188e+01,\n",
      "         3.0931e+01,  1.4175e+01,  4.3769e+01,  3.9622e+01, -4.6945e+00,\n",
      "         4.2277e+00, -8.7546e-01, -4.3282e+00, -4.6945e+00, -3.1512e+00,\n",
      "        -5.5491e+00,  3.4170e+00, -1.4295e-01, -2.7850e+00, -2.8586e+00,\n",
      "        -1.4859e+00, -4.5724e+00, -5.7932e+00, -4.6311e+00,  1.7988e+01,\n",
      "         1.0068e+01,  1.6445e+00,  3.1140e+00,  7.5964e+00, -2.0859e-02,\n",
      "         1.0123e-01, -3.3515e+00,  4.4868e+00,  1.3813e+01, -2.0040e+00,\n",
      "        -6.4618e-01,  1.8453e+01,  3.4927e+01,  2.0142e+01,  3.4256e+01,\n",
      "         6.7522e+00,  1.4830e+01,  2.7243e+01,  2.6544e+01,  1.0142e+01,\n",
      "        -4.0201e-01,  2.5641e+01, -2.9070e+00, -8.9035e-01,  3.2845e+00,\n",
      "         6.5080e+00,  3.8614e+00,  1.2026e+01,  3.1877e+00, -1.3199e+00,\n",
      "        -2.3748e+00, -2.6190e+00, -2.6778e+00,  9.3263e+00, -6.3129e-01,\n",
      "         1.0253e+01,  5.6488e+00, -4.8165e+00,  7.2256e+00,  2.2331e-01,\n",
      "        -3.7178e+00,  5.4970e+00,  3.2799e+01, -3.8398e+00, -7.0949e-01,\n",
      "        -1.4420e+00, -3.2882e+00, -3.2381e-01,  4.2128e+00,  2.2662e+01,\n",
      "         1.4742e+01, -2.3748e+00, -2.1745e+00, -3.1073e+00, -2.7365e+00,\n",
      "         9.1194e-01, -3.3515e+00, -1.8083e+00, -2.8632e+00, -4.4503e+00,\n",
      "         5.6488e+00,  5.7339e-02, -3.1073e+00, -2.5996e+00,  3.8362e+00,\n",
      "         1.6036e+01,  4.9014e+00,  3.5578e+01,  8.4763e+00]) Cost: 196.619507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 2300/10000 hypothesis: tensor([ 3.0664e+01,  5.1326e+00,  4.9063e+01,  4.9188e+01,  1.4316e+01,\n",
      "         4.9674e+01,  6.0005e+01,  5.8043e+00,  4.3608e+01,  3.9592e+01,\n",
      "         3.5541e+01,  4.7369e+01,  1.6366e+01,  1.6257e+01,  4.9293e+01,\n",
      "         2.7001e+01,  2.7106e+01,  5.0958e+01,  1.4638e+01,  5.7987e+01,\n",
      "         4.5459e+01,  3.6887e+01,  3.6975e+01,  2.7561e+01,  3.8749e+01,\n",
      "         3.5009e+01, -2.7840e+00,  1.1899e+00, -5.0614e+00, -4.4493e+00,\n",
      "        -5.0614e+00, -5.0662e-01, -5.4286e+00, -1.7450e+00, -4.8165e+00,\n",
      "        -4.6344e+00, -2.0495e+00,  5.3462e+00, -1.6083e+00, -5.5510e+00,\n",
      "        -3.5327e+00, -4.5717e+00, -6.1631e+00,  3.5585e+00,  4.4129e+01,\n",
      "         3.4746e+01,  3.1952e+01,  5.3005e+01,  2.0750e+01,  3.1185e+01,\n",
      "         3.0944e+01,  1.4179e+01,  4.3779e+01,  3.9620e+01, -4.6941e+00,\n",
      "         4.2303e+00, -8.7384e-01, -4.3269e+00, -4.6941e+00, -3.1512e+00,\n",
      "        -5.5510e+00,  3.4218e+00, -1.3939e-01, -2.7840e+00, -2.8610e+00,\n",
      "        -1.4859e+00, -4.5717e+00, -5.7958e+00, -4.6344e+00,  1.7979e+01,\n",
      "         1.0066e+01,  1.6483e+00,  3.1143e+00,  7.5891e+00, -1.6978e-02,\n",
      "         1.0543e-01, -3.3476e+00,  4.4894e+00,  1.3809e+01, -2.0041e+00,\n",
      "        -6.4331e-01,  1.8455e+01,  3.4908e+01,  2.0134e+01,  3.4254e+01,\n",
      "         6.7495e+00,  1.4834e+01,  2.7240e+01,  2.6537e+01,  1.0143e+01,\n",
      "        -3.9849e-01,  2.5634e+01, -2.9064e+00, -8.8813e-01,  3.2821e+00,\n",
      "         6.5047e+00,  3.8630e+00,  1.2021e+01,  3.1913e+00, -1.3151e+00,\n",
      "        -2.3684e+00, -2.6132e+00, -2.6759e+00,  9.3373e+00, -6.2903e-01,\n",
      "         1.0248e+01,  5.6508e+00, -4.8165e+00,  7.2249e+00,  2.2784e-01,\n",
      "        -3.7149e+00,  5.4998e+00,  3.2785e+01, -3.8373e+00, -7.0303e-01,\n",
      "        -1.4375e+00, -3.2879e+00, -3.2448e-01,  4.2160e+00,  2.2657e+01,\n",
      "         1.4743e+01, -2.3684e+00, -2.1719e+00, -3.1028e+00, -2.7386e+00,\n",
      "         9.1389e-01, -3.3476e+00, -1.8047e+00, -2.8580e+00, -4.4493e+00,\n",
      "         5.6508e+00,  5.7027e-02, -3.1028e+00, -2.6019e+00,  3.8315e+00,\n",
      "         1.6044e+01,  4.9020e+00,  3.5566e+01,  8.4775e+00]) Cost: 196.600967\n",
      "Epochs 2400/10000 hypothesis: tensor([ 3.0663e+01,  5.1346e+00,  4.9063e+01,  4.9196e+01,  1.4320e+01,\n",
      "         4.9669e+01,  6.0002e+01,  5.8046e+00,  4.3606e+01,  3.9599e+01,\n",
      "         3.5538e+01,  4.7371e+01,  1.6377e+01,  1.6260e+01,  4.9295e+01,\n",
      "         2.7011e+01,  2.7110e+01,  5.0960e+01,  1.4645e+01,  5.7982e+01,\n",
      "         4.5460e+01,  3.6896e+01,  3.6972e+01,  2.7554e+01,  3.8754e+01,\n",
      "         3.5022e+01, -2.7831e+00,  1.1905e+00, -5.0620e+00, -4.4483e+00,\n",
      "        -5.0620e+00, -5.0423e-01, -5.4302e+00, -1.7449e+00, -4.8165e+00,\n",
      "        -4.6375e+00, -2.0467e+00,  5.3505e+00, -1.6088e+00, -5.5529e+00,\n",
      "        -3.5329e+00, -4.5711e+00, -6.1666e+00,  3.5626e+00,  4.4134e+01,\n",
      "         3.4746e+01,  3.1964e+01,  5.2999e+01,  2.0759e+01,  3.1183e+01,\n",
      "         3.0955e+01,  1.4184e+01,  4.3789e+01,  3.9619e+01, -4.6938e+00,\n",
      "         4.2326e+00, -8.7243e-01, -4.3256e+00, -4.6938e+00, -3.1513e+00,\n",
      "        -5.5529e+00,  3.4265e+00, -1.3604e-01, -2.7831e+00, -2.8629e+00,\n",
      "        -1.4861e+00, -4.5711e+00, -5.7984e+00, -4.6375e+00,  1.7971e+01,\n",
      "         1.0064e+01,  1.6519e+00,  3.1146e+00,  7.5824e+00, -1.3310e-02,\n",
      "         1.0942e-01, -3.3437e+00,  4.4914e+00,  1.3805e+01, -2.0038e+00,\n",
      "        -6.4036e-01,  1.8456e+01,  3.4891e+01,  2.0128e+01,  3.4252e+01,\n",
      "         6.7468e+00,  1.4838e+01,  2.7236e+01,  2.6530e+01,  1.0144e+01,\n",
      "        -3.9490e-01,  2.5628e+01, -2.9058e+00, -8.8583e-01,  3.2802e+00,\n",
      "         6.5013e+00,  3.8644e+00,  1.2017e+01,  3.1944e+00, -1.3103e+00,\n",
      "        -2.3619e+00, -2.6074e+00, -2.6738e+00,  9.3476e+00, -6.2697e-01,\n",
      "         1.0243e+01,  5.6523e+00, -4.8165e+00,  7.2243e+00,  2.3215e-01,\n",
      "        -3.7119e+00,  5.5028e+00,  3.2772e+01, -3.8347e+00, -6.9668e-01,\n",
      "        -1.4331e+00, -3.2874e+00, -3.2519e-01,  4.2192e+00,  2.2652e+01,\n",
      "         1.4744e+01, -2.3619e+00, -2.1695e+00, -3.0983e+00, -2.7402e+00,\n",
      "         9.1552e-01, -3.3437e+00, -1.8013e+00, -2.8528e+00, -4.4483e+00,\n",
      "         5.6523e+00,  5.6402e-02, -3.0983e+00, -2.6041e+00,  3.8275e+00,\n",
      "         1.6051e+01,  4.9025e+00,  3.5555e+01,  8.4784e+00]) Cost: 196.582520\n",
      "Epochs 2500/10000 hypothesis: tensor([ 3.0661e+01,  5.1368e+00,  4.9062e+01,  4.9202e+01,  1.4323e+01,\n",
      "         4.9665e+01,  6.0000e+01,  5.8051e+00,  4.3604e+01,  3.9606e+01,\n",
      "         3.5537e+01,  4.7373e+01,  1.6387e+01,  1.6263e+01,  4.9296e+01,\n",
      "         2.7020e+01,  2.7114e+01,  5.0961e+01,  1.4652e+01,  5.7978e+01,\n",
      "         4.5462e+01,  3.6904e+01,  3.6968e+01,  2.7548e+01,  3.8757e+01,\n",
      "         3.5034e+01, -2.7823e+00,  1.1915e+00, -5.0626e+00, -4.4473e+00,\n",
      "        -5.0626e+00, -5.0204e-01, -5.4317e+00, -1.7448e+00, -4.8165e+00,\n",
      "        -4.6403e+00, -2.0440e+00,  5.3543e+00, -1.6095e+00, -5.5548e+00,\n",
      "        -3.5329e+00, -4.5704e+00, -6.1700e+00,  3.5663e+00,  4.4137e+01,\n",
      "         3.4746e+01,  3.1975e+01,  5.2995e+01,  2.0766e+01,  3.1182e+01,\n",
      "         3.0966e+01,  1.4188e+01,  4.3797e+01,  3.9618e+01, -4.6934e+00,\n",
      "         4.2346e+00, -8.7119e-01, -4.3243e+00, -4.6934e+00, -3.1515e+00,\n",
      "        -5.5548e+00,  3.4310e+00, -1.3288e-01, -2.7823e+00, -2.8646e+00,\n",
      "        -1.4865e+00, -4.5704e+00, -5.8009e+00, -4.6403e+00,  1.7964e+01,\n",
      "         1.0062e+01,  1.6552e+00,  3.1149e+00,  7.5762e+00, -9.8296e-03,\n",
      "         1.1322e-01, -3.3398e+00,  4.4930e+00,  1.3802e+01, -2.0032e+00,\n",
      "        -6.3735e-01,  1.8457e+01,  3.4876e+01,  2.0121e+01,  3.4250e+01,\n",
      "         6.7441e+00,  1.4840e+01,  2.7233e+01,  2.6523e+01,  1.0144e+01,\n",
      "        -3.9125e-01,  2.5621e+01, -2.9054e+00, -8.8346e-01,  3.2787e+00,\n",
      "         6.4980e+00,  3.8655e+00,  1.2014e+01,  3.1971e+00, -1.3057e+00,\n",
      "        -2.3554e+00, -2.6015e+00, -2.6715e+00,  9.3573e+00, -6.2509e-01,\n",
      "         1.0238e+01,  5.6535e+00, -4.8165e+00,  7.2240e+00,  2.3627e-01,\n",
      "        -3.7090e+00,  5.5059e+00,  3.2760e+01, -3.8320e+00, -6.9042e-01,\n",
      "        -1.4287e+00, -3.2868e+00, -3.2592e-01,  4.2223e+00,  2.2648e+01,\n",
      "         1.4745e+01, -2.3554e+00, -2.1670e+00, -3.0937e+00, -2.7415e+00,\n",
      "         9.1687e-01, -3.3398e+00, -1.7979e+00, -2.8476e+00, -4.4473e+00,\n",
      "         5.6535e+00,  5.5503e-02, -3.0937e+00, -2.6062e+00,  3.8240e+00,\n",
      "         1.6058e+01,  4.9029e+00,  3.5545e+01,  8.4791e+00]) Cost: 196.564178\n",
      "Epochs 2600/10000 hypothesis: tensor([ 3.0659e+01,  5.1391e+00,  4.9062e+01,  4.9209e+01,  1.4326e+01,\n",
      "         4.9662e+01,  5.9998e+01,  5.8059e+00,  4.3602e+01,  3.9612e+01,\n",
      "         3.5536e+01,  4.7375e+01,  1.6395e+01,  1.6266e+01,  4.9298e+01,\n",
      "         2.7029e+01,  2.7118e+01,  5.0962e+01,  1.4657e+01,  5.7974e+01,\n",
      "         4.5464e+01,  3.6911e+01,  3.6965e+01,  2.7542e+01,  3.8760e+01,\n",
      "         3.5045e+01, -2.7816e+00,  1.1928e+00, -5.0631e+00, -4.4463e+00,\n",
      "        -5.0631e+00, -5.0000e-01, -5.4332e+00, -1.7446e+00, -4.8164e+00,\n",
      "        -4.6430e+00, -2.0413e+00,  5.3577e+00, -1.6103e+00, -5.5566e+00,\n",
      "        -3.5327e+00, -4.5696e+00, -6.1735e+00,  3.5696e+00,  4.4141e+01,\n",
      "         3.4746e+01,  3.1984e+01,  5.2991e+01,  2.0773e+01,  3.1181e+01,\n",
      "         3.0975e+01,  1.4192e+01,  4.3805e+01,  3.9617e+01, -4.6930e+00,\n",
      "         4.2365e+00, -8.7011e-01, -4.3229e+00, -4.6930e+00, -3.1517e+00,\n",
      "        -5.5566e+00,  3.4354e+00, -1.2988e-01, -2.7816e+00, -2.8659e+00,\n",
      "        -1.4870e+00, -4.5696e+00, -5.8034e+00, -4.6430e+00,  1.7957e+01,\n",
      "         1.0060e+01,  1.6582e+00,  3.1152e+00,  7.5705e+00, -6.5117e-03,\n",
      "         1.1686e-01, -3.3359e+00,  4.4941e+00,  1.3798e+01, -2.0023e+00,\n",
      "        -6.3429e-01,  1.8457e+01,  3.4862e+01,  2.0115e+01,  3.4247e+01,\n",
      "         6.7413e+00,  1.4842e+01,  2.7228e+01,  2.6516e+01,  1.0144e+01,\n",
      "        -3.8754e-01,  2.5614e+01, -2.9049e+00, -8.8103e-01,  3.2776e+00,\n",
      "         6.4946e+00,  3.8663e+00,  1.2010e+01,  3.1995e+00, -1.3011e+00,\n",
      "        -2.3490e+00, -2.5957e+00, -2.6691e+00,  9.3665e+00, -6.2337e-01,\n",
      "         1.0233e+01,  5.6544e+00, -4.8164e+00,  7.2239e+00,  2.4023e-01,\n",
      "        -3.7060e+00,  5.5092e+00,  3.2749e+01, -3.8294e+00, -6.8425e-01,\n",
      "        -1.4245e+00, -3.2860e+00, -3.2667e-01,  4.2255e+00,  2.2644e+01,\n",
      "         1.4746e+01, -2.3490e+00, -2.1647e+00, -3.0892e+00, -2.7425e+00,\n",
      "         9.1797e-01, -3.3359e+00, -1.7946e+00, -2.8424e+00, -4.4463e+00,\n",
      "         5.6544e+00,  5.4366e-02, -3.0892e+00, -2.6082e+00,  3.8211e+00,\n",
      "         1.6064e+01,  4.9033e+00,  3.5535e+01,  8.4794e+00]) Cost: 196.545898\n",
      "Epochs 2700/10000 hypothesis: tensor([ 3.0658e+01,  5.1415e+00,  4.9061e+01,  4.9214e+01,  1.4329e+01,\n",
      "         4.9659e+01,  5.9997e+01,  5.8070e+00,  4.3601e+01,  3.9618e+01,\n",
      "         3.5536e+01,  4.7378e+01,  1.6404e+01,  1.6269e+01,  4.9299e+01,\n",
      "         2.7036e+01,  2.7121e+01,  5.0963e+01,  1.4663e+01,  5.7971e+01,\n",
      "         4.5466e+01,  3.6917e+01,  3.6963e+01,  2.7537e+01,  3.8762e+01,\n",
      "         3.5054e+01, -2.7809e+00,  1.1944e+00, -5.0637e+00, -4.4452e+00,\n",
      "        -5.0637e+00, -4.9810e-01, -5.4347e+00, -1.7444e+00, -4.8163e+00,\n",
      "        -4.6456e+00, -2.0387e+00,  5.3607e+00, -1.6113e+00, -5.5584e+00,\n",
      "        -3.5324e+00, -4.5689e+00, -6.1769e+00,  3.5727e+00,  4.4145e+01,\n",
      "         3.4747e+01,  3.1992e+01,  5.2988e+01,  2.0778e+01,  3.1181e+01,\n",
      "         3.0983e+01,  1.4196e+01,  4.3813e+01,  3.9617e+01, -4.6926e+00,\n",
      "         4.2381e+00, -8.6917e-01, -4.3215e+00, -4.6926e+00, -3.1519e+00,\n",
      "        -5.5584e+00,  3.4396e+00, -1.2703e-01, -2.7809e+00, -2.8670e+00,\n",
      "        -1.4876e+00, -4.5689e+00, -5.8058e+00, -4.6456e+00,  1.7951e+01,\n",
      "         1.0058e+01,  1.6610e+00,  3.1155e+00,  7.5653e+00, -3.3376e-03,\n",
      "         1.2035e-01, -3.3320e+00,  4.4949e+00,  1.3795e+01, -2.0011e+00,\n",
      "        -6.3117e-01,  1.8456e+01,  3.4849e+01,  2.0110e+01,  3.4243e+01,\n",
      "         6.7385e+00,  1.4843e+01,  2.7224e+01,  2.6510e+01,  1.0144e+01,\n",
      "        -3.8379e-01,  2.5607e+01, -2.9046e+00, -8.7855e-01,  3.2768e+00,\n",
      "         6.4912e+00,  3.8671e+00,  1.2007e+01,  3.2016e+00, -1.2966e+00,\n",
      "        -2.3425e+00, -2.5899e+00, -2.6666e+00,  9.3752e+00, -6.2179e-01,\n",
      "         1.0228e+01,  5.6551e+00, -4.8163e+00,  7.2239e+00,  2.4404e-01,\n",
      "        -3.7031e+00,  5.5126e+00,  3.2739e+01, -3.8268e+00, -6.7815e-01,\n",
      "        -1.4203e+00, -3.2850e+00, -3.2743e-01,  4.2287e+00,  2.2640e+01,\n",
      "         1.4747e+01, -2.3425e+00, -2.1624e+00, -3.0846e+00, -2.7433e+00,\n",
      "         9.1885e-01, -3.3320e+00, -1.7914e+00, -2.8372e+00, -4.4452e+00,\n",
      "         5.6551e+00,  5.3022e-02, -3.0846e+00, -2.6102e+00,  3.8186e+00,\n",
      "         1.6070e+01,  4.9036e+00,  3.5525e+01,  8.4796e+00]) Cost: 196.527664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 2800/10000 hypothesis: tensor([ 3.0656e+01,  5.1441e+00,  4.9060e+01,  4.9219e+01,  1.4332e+01,\n",
      "         4.9657e+01,  5.9997e+01,  5.8082e+00,  4.3601e+01,  3.9623e+01,\n",
      "         3.5537e+01,  4.7380e+01,  1.6411e+01,  1.6272e+01,  4.9300e+01,\n",
      "         2.7043e+01,  2.7124e+01,  5.0964e+01,  1.4667e+01,  5.7969e+01,\n",
      "         4.5468e+01,  3.6923e+01,  3.6960e+01,  2.7533e+01,  3.8763e+01,\n",
      "         3.5063e+01, -2.7802e+00,  1.1963e+00, -5.0642e+00, -4.4441e+00,\n",
      "        -5.0642e+00, -4.9632e-01, -5.4362e+00, -1.7441e+00, -4.8162e+00,\n",
      "        -4.6480e+00, -2.0362e+00,  5.3634e+00, -1.6124e+00, -5.5602e+00,\n",
      "        -3.5320e+00, -4.5681e+00, -6.1802e+00,  3.5755e+00,  4.4148e+01,\n",
      "         3.4749e+01,  3.1998e+01,  5.2985e+01,  2.0783e+01,  3.1181e+01,\n",
      "         3.0991e+01,  1.4200e+01,  4.3819e+01,  3.9616e+01, -4.6921e+00,\n",
      "         4.2396e+00, -8.6834e-01, -4.3201e+00, -4.6921e+00, -3.1523e+00,\n",
      "        -5.5602e+00,  3.4438e+00, -1.2430e-01, -2.7802e+00, -2.8678e+00,\n",
      "        -1.4884e+00, -4.5681e+00, -5.8082e+00, -4.6480e+00,  1.7944e+01,\n",
      "         1.0056e+01,  1.6636e+00,  3.1159e+00,  7.5603e+00, -2.8965e-04,\n",
      "         1.2372e-01, -3.3281e+00,  4.4953e+00,  1.3792e+01, -1.9998e+00,\n",
      "        -6.2801e-01,  1.8455e+01,  3.4838e+01,  2.0104e+01,  3.4239e+01,\n",
      "         6.7358e+00,  1.4843e+01,  2.7219e+01,  2.6504e+01,  1.0143e+01,\n",
      "        -3.8000e-01,  2.5600e+01, -2.9043e+00, -8.7603e-01,  3.2763e+00,\n",
      "         6.4877e+00,  3.8676e+00,  1.2004e+01,  3.2035e+00, -1.2922e+00,\n",
      "        -2.3360e+00, -2.5840e+00, -2.6639e+00,  9.3834e+00, -6.2033e-01,\n",
      "         1.0224e+01,  5.6555e+00, -4.8162e+00,  7.2241e+00,  2.4773e-01,\n",
      "        -3.7001e+00,  5.5161e+00,  3.2729e+01, -3.8241e+00, -6.7211e-01,\n",
      "        -1.4162e+00, -3.2840e+00, -3.2821e-01,  4.2319e+00,  2.2636e+01,\n",
      "         1.4748e+01, -2.3360e+00, -2.1602e+00, -3.0800e+00, -2.7438e+00,\n",
      "         9.1955e-01, -3.3281e+00, -1.7882e+00, -2.8320e+00, -4.4441e+00,\n",
      "         5.6555e+00,  5.1494e-02, -3.0800e+00, -2.6121e+00,  3.8164e+00,\n",
      "         1.6075e+01,  4.9038e+00,  3.5516e+01,  8.4796e+00]) Cost: 196.509476\n",
      "Epochs 2900/10000 hypothesis: tensor([ 3.0654e+01,  5.1467e+00,  4.9058e+01,  4.9224e+01,  1.4334e+01,\n",
      "         4.9656e+01,  5.9997e+01,  5.8097e+00,  4.3600e+01,  3.9628e+01,\n",
      "         3.5538e+01,  4.7383e+01,  1.6418e+01,  1.6276e+01,  4.9301e+01,\n",
      "         2.7049e+01,  2.7126e+01,  5.0964e+01,  1.4671e+01,  5.7967e+01,\n",
      "         4.5471e+01,  3.6929e+01,  3.6958e+01,  2.7528e+01,  3.8764e+01,\n",
      "         3.5070e+01, -2.7797e+00,  1.1984e+00, -5.0647e+00, -4.4430e+00,\n",
      "        -5.0647e+00, -4.9465e-01, -5.4376e+00, -1.7437e+00, -4.8160e+00,\n",
      "        -4.6504e+00, -2.0337e+00,  5.3658e+00, -1.6136e+00, -5.5620e+00,\n",
      "        -3.5314e+00, -4.5674e+00, -6.1836e+00,  3.5781e+00,  4.4151e+01,\n",
      "         3.4751e+01,  3.2004e+01,  5.2983e+01,  2.0786e+01,  3.1181e+01,\n",
      "         3.0998e+01,  1.4204e+01,  4.3825e+01,  3.9616e+01, -4.6917e+00,\n",
      "         4.2410e+00, -8.6762e-01, -4.3187e+00, -4.6917e+00, -3.1526e+00,\n",
      "        -5.5620e+00,  3.4479e+00, -1.2168e-01, -2.7797e+00, -2.8685e+00,\n",
      "        -1.4892e+00, -4.5674e+00, -5.8106e+00, -4.6504e+00,  1.7939e+01,\n",
      "         1.0054e+01,  1.6660e+00,  3.1162e+00,  7.5557e+00,  2.6483e-03,\n",
      "         1.2697e-01, -3.3241e+00,  4.4955e+00,  1.3789e+01, -1.9982e+00,\n",
      "        -6.2482e-01,  1.8454e+01,  3.4827e+01,  2.0099e+01,  3.4235e+01,\n",
      "         6.7330e+00,  1.4843e+01,  2.7215e+01,  2.6498e+01,  1.0143e+01,\n",
      "        -3.7617e-01,  2.5593e+01, -2.9040e+00, -8.7347e-01,  3.2760e+00,\n",
      "         6.4843e+00,  3.8680e+00,  1.2001e+01,  3.2051e+00, -1.2878e+00,\n",
      "        -2.3295e+00, -2.5782e+00, -2.6612e+00,  9.3913e+00, -6.1898e-01,\n",
      "         1.0220e+01,  5.6557e+00, -4.8160e+00,  7.2244e+00,  2.5130e-01,\n",
      "        -3.6971e+00,  5.5197e+00,  3.2720e+01, -3.8214e+00, -6.6613e-01,\n",
      "        -1.4121e+00, -3.2828e+00, -3.2901e-01,  4.2352e+00,  2.2633e+01,\n",
      "         1.4748e+01, -2.3295e+00, -2.1580e+00, -3.0755e+00, -2.7442e+00,\n",
      "         9.2008e-01, -3.3241e+00, -1.7851e+00, -2.8268e+00, -4.4430e+00,\n",
      "         5.6557e+00,  4.9807e-02, -3.0755e+00, -2.6140e+00,  3.8146e+00,\n",
      "         1.6080e+01,  4.9039e+00,  3.5508e+01,  8.4793e+00]) Cost: 196.491364\n",
      "Epochs 3000/10000 hypothesis: tensor([ 3.0652e+01,  5.1495e+00,  4.9056e+01,  4.9228e+01,  1.4336e+01,\n",
      "         4.9655e+01,  5.9998e+01,  5.8113e+00,  4.3600e+01,  3.9633e+01,\n",
      "         3.5539e+01,  4.7386e+01,  1.6424e+01,  1.6279e+01,  4.9302e+01,\n",
      "         2.7055e+01,  2.7128e+01,  5.0964e+01,  1.4675e+01,  5.7965e+01,\n",
      "         4.5474e+01,  3.6934e+01,  3.6956e+01,  2.7524e+01,  3.8764e+01,\n",
      "         3.5077e+01, -2.7791e+00,  1.2006e+00, -5.0651e+00, -4.4419e+00,\n",
      "        -5.0651e+00, -4.9308e-01, -5.4391e+00, -1.7434e+00, -4.8159e+00,\n",
      "        -4.6526e+00, -2.0313e+00,  5.3679e+00, -1.6148e+00, -5.5637e+00,\n",
      "        -3.5308e+00, -4.5666e+00, -6.1869e+00,  3.5804e+00,  4.4154e+01,\n",
      "         3.4753e+01,  3.2009e+01,  5.2981e+01,  2.0789e+01,  3.1182e+01,\n",
      "         3.1004e+01,  1.4208e+01,  4.3831e+01,  3.9616e+01, -4.6912e+00,\n",
      "         4.2422e+00, -8.6700e-01, -4.3173e+00, -4.6912e+00, -3.1530e+00,\n",
      "        -5.5637e+00,  3.4519e+00, -1.1915e-01, -2.7791e+00, -2.8690e+00,\n",
      "        -1.4902e+00, -4.5666e+00, -5.8130e+00, -4.6526e+00,  1.7933e+01,\n",
      "         1.0052e+01,  1.6683e+00,  3.1166e+00,  7.5513e+00,  5.4883e-03,\n",
      "         1.3013e-01, -3.3202e+00,  4.4954e+00,  1.3786e+01, -1.9965e+00,\n",
      "        -6.2159e-01,  1.8452e+01,  3.4817e+01,  2.0094e+01,  3.4231e+01,\n",
      "         6.7301e+00,  1.4842e+01,  2.7210e+01,  2.6493e+01,  1.0142e+01,\n",
      "        -3.7231e-01,  2.5585e+01, -2.9037e+00, -8.7087e-01,  3.2760e+00,\n",
      "         6.4809e+00,  3.8683e+00,  1.1999e+01,  3.2065e+00, -1.2834e+00,\n",
      "        -2.3230e+00, -2.5723e+00, -2.6583e+00,  9.3989e+00, -6.1772e-01,\n",
      "         1.0215e+01,  5.6558e+00, -4.8159e+00,  7.2248e+00,  2.5477e-01,\n",
      "        -3.6941e+00,  5.5234e+00,  3.2711e+01, -3.8187e+00, -6.6021e-01,\n",
      "        -1.4081e+00, -3.2815e+00, -3.2982e-01,  4.2384e+00,  2.2630e+01,\n",
      "         1.4749e+01, -2.3230e+00, -2.1559e+00, -3.0709e+00, -2.7444e+00,\n",
      "         9.2047e-01, -3.3202e+00, -1.7820e+00, -2.8216e+00, -4.4419e+00,\n",
      "         5.6558e+00,  4.7980e-02, -3.0709e+00, -2.6158e+00,  3.8132e+00,\n",
      "         1.6085e+01,  4.9041e+00,  3.5499e+01,  8.4790e+00]) Cost: 196.473282\n",
      "Epochs 3100/10000 hypothesis: tensor([ 3.0650e+01,  5.1523e+00,  4.9054e+01,  4.9232e+01,  1.4338e+01,\n",
      "         4.9655e+01,  5.9999e+01,  5.8130e+00,  4.3600e+01,  3.9637e+01,\n",
      "         3.5541e+01,  4.7388e+01,  1.6430e+01,  1.6283e+01,  4.9302e+01,\n",
      "         2.7060e+01,  2.7131e+01,  5.0965e+01,  1.4679e+01,  5.7964e+01,\n",
      "         4.5476e+01,  3.6939e+01,  3.6955e+01,  2.7521e+01,  3.8764e+01,\n",
      "         3.5084e+01, -2.7786e+00,  1.2030e+00, -5.0656e+00, -4.4408e+00,\n",
      "        -5.0656e+00, -4.9158e-01, -5.4405e+00, -1.7429e+00, -4.8157e+00,\n",
      "        -4.6547e+00, -2.0288e+00,  5.3698e+00, -1.6162e+00, -5.5654e+00,\n",
      "        -3.5301e+00, -4.5658e+00, -6.1902e+00,  3.5826e+00,  4.4157e+01,\n",
      "         3.4755e+01,  3.2013e+01,  5.2979e+01,  2.0792e+01,  3.1182e+01,\n",
      "         3.1010e+01,  1.4211e+01,  4.3836e+01,  3.9617e+01, -4.6907e+00,\n",
      "         4.2434e+00, -8.6645e-01, -4.3159e+00, -4.6907e+00, -3.1535e+00,\n",
      "        -5.5654e+00,  3.4558e+00, -1.1671e-01, -2.7786e+00, -2.8694e+00,\n",
      "        -1.4912e+00, -4.5658e+00, -5.8153e+00, -4.6547e+00,  1.7928e+01,\n",
      "         1.0050e+01,  1.6705e+00,  3.1170e+00,  7.5472e+00,  8.2437e-03,\n",
      "         1.3320e-01, -3.3162e+00,  4.4951e+00,  1.3783e+01, -1.9947e+00,\n",
      "        -6.1834e-01,  1.8450e+01,  3.4808e+01,  2.0090e+01,  3.4226e+01,\n",
      "         6.7273e+00,  1.4842e+01,  2.7204e+01,  2.6487e+01,  1.0141e+01,\n",
      "        -3.6842e-01,  2.5578e+01, -2.9035e+00, -8.6825e-01,  3.2761e+00,\n",
      "         6.4774e+00,  3.8685e+00,  1.1996e+01,  3.2077e+00, -1.2791e+00,\n",
      "        -2.3166e+00, -2.5665e+00, -2.6554e+00,  9.4062e+00, -6.1654e-01,\n",
      "         1.0211e+01,  5.6557e+00, -4.8157e+00,  7.2253e+00,  2.5816e-01,\n",
      "        -3.6911e+00,  5.5271e+00,  3.2703e+01, -3.8160e+00, -6.5433e-01,\n",
      "        -1.4041e+00, -3.2802e+00, -3.3064e-01,  4.2416e+00,  2.2627e+01,\n",
      "         1.4749e+01, -2.3166e+00, -2.1538e+00, -3.0663e+00, -2.7444e+00,\n",
      "         9.2073e-01, -3.3162e+00, -1.7789e+00, -2.8164e+00, -4.4408e+00,\n",
      "         5.6557e+00,  4.6032e-02, -3.0663e+00, -2.6176e+00,  3.8119e+00,\n",
      "         1.6089e+01,  4.9041e+00,  3.5491e+01,  8.4785e+00]) Cost: 196.455261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 3200/10000 hypothesis: tensor([ 3.0648e+01,  5.1551e+00,  4.9052e+01,  4.9236e+01,  1.4340e+01,\n",
      "         4.9655e+01,  6.0001e+01,  5.8149e+00,  4.3600e+01,  3.9641e+01,\n",
      "         3.5543e+01,  4.7391e+01,  1.6435e+01,  1.6286e+01,  4.9303e+01,\n",
      "         2.7065e+01,  2.7133e+01,  5.0965e+01,  1.4682e+01,  5.7963e+01,\n",
      "         4.5479e+01,  3.6944e+01,  3.6953e+01,  2.7518e+01,  3.8764e+01,\n",
      "         3.5090e+01, -2.7781e+00,  1.2056e+00, -5.0660e+00, -4.4397e+00,\n",
      "        -5.0660e+00, -4.9016e-01, -5.4419e+00, -1.7425e+00, -4.8155e+00,\n",
      "        -4.6568e+00, -2.0265e+00,  5.3715e+00, -1.6176e+00, -5.5671e+00,\n",
      "        -3.5294e+00, -4.5650e+00, -6.1935e+00,  3.5846e+00,  4.4159e+01,\n",
      "         3.4758e+01,  3.2016e+01,  5.2978e+01,  2.0794e+01,  3.1184e+01,\n",
      "         3.1015e+01,  1.4215e+01,  4.3841e+01,  3.9617e+01, -4.6902e+00,\n",
      "         4.2444e+00, -8.6598e-01, -4.3144e+00, -4.6902e+00, -3.1539e+00,\n",
      "        -5.5671e+00,  3.4597e+00, -1.1435e-01, -2.7781e+00, -2.8696e+00,\n",
      "        -1.4923e+00, -4.5650e+00, -5.8177e+00, -4.6568e+00,  1.7923e+01,\n",
      "         1.0048e+01,  1.6725e+00,  3.1173e+00,  7.5433e+00,  1.0925e-02,\n",
      "         1.3620e-01, -3.3122e+00,  4.4946e+00,  1.3781e+01, -1.9927e+00,\n",
      "        -6.1506e-01,  1.8448e+01,  3.4800e+01,  2.0086e+01,  3.4222e+01,\n",
      "         6.7245e+00,  1.4840e+01,  2.7199e+01,  2.6482e+01,  1.0139e+01,\n",
      "        -3.6452e-01,  2.5571e+01, -2.9034e+00, -8.6560e-01,  3.2764e+00,\n",
      "         6.4739e+00,  3.8686e+00,  1.1994e+01,  3.2088e+00, -1.2748e+00,\n",
      "        -2.3101e+00, -2.5606e+00, -2.6525e+00,  9.4132e+00, -6.1543e-01,\n",
      "         1.0207e+01,  5.6555e+00, -4.8155e+00,  7.2259e+00,  2.6147e-01,\n",
      "        -3.6881e+00,  5.5309e+00,  3.2695e+01, -3.8133e+00, -6.4849e-01,\n",
      "        -1.4001e+00, -3.2788e+00, -3.3146e-01,  4.2448e+00,  2.2624e+01,\n",
      "         1.4749e+01, -2.3101e+00, -2.1517e+00, -3.0617e+00, -2.7443e+00,\n",
      "         9.2088e-01, -3.3122e+00, -1.7759e+00, -2.8112e+00, -4.4397e+00,\n",
      "         5.6555e+00,  4.3979e-02, -3.0617e+00, -2.6194e+00,  3.8109e+00,\n",
      "         1.6093e+01,  4.9042e+00,  3.5484e+01,  8.4779e+00]) Cost: 196.437271\n",
      "Epochs 3300/10000 hypothesis: tensor([ 3.0646e+01,  5.1580e+00,  4.9050e+01,  4.9239e+01,  1.4342e+01,\n",
      "         4.9655e+01,  6.0003e+01,  5.8169e+00,  4.3601e+01,  3.9645e+01,\n",
      "         3.5545e+01,  4.7394e+01,  1.6440e+01,  1.6290e+01,  4.9304e+01,\n",
      "         2.7070e+01,  2.7134e+01,  5.0965e+01,  1.4685e+01,  5.7963e+01,\n",
      "         4.5482e+01,  3.6949e+01,  3.6952e+01,  2.7515e+01,  3.8763e+01,\n",
      "         3.5095e+01, -2.7776e+00,  1.2083e+00, -5.0665e+00, -4.4385e+00,\n",
      "        -5.0665e+00, -4.8880e-01, -5.4432e+00, -1.7420e+00, -4.8153e+00,\n",
      "        -4.6588e+00, -2.0241e+00,  5.3730e+00, -1.6191e+00, -5.5688e+00,\n",
      "        -3.5285e+00, -4.5641e+00, -6.1968e+00,  3.5865e+00,  4.4162e+01,\n",
      "         3.4760e+01,  3.2019e+01,  5.2977e+01,  2.0795e+01,  3.1185e+01,\n",
      "         3.1020e+01,  1.4219e+01,  4.3846e+01,  3.9618e+01, -4.6897e+00,\n",
      "         4.2454e+00, -8.6556e-01, -4.3130e+00, -4.6897e+00, -3.1544e+00,\n",
      "        -5.5688e+00,  3.4636e+00, -1.1205e-01, -2.7776e+00, -2.8697e+00,\n",
      "        -1.4935e+00, -4.5641e+00, -5.8200e+00, -4.6588e+00,  1.7918e+01,\n",
      "         1.0046e+01,  1.6744e+00,  3.1177e+00,  7.5396e+00,  1.3540e-02,\n",
      "         1.3913e-01, -3.3083e+00,  4.4939e+00,  1.3778e+01, -1.9906e+00,\n",
      "        -6.1176e-01,  1.8445e+01,  3.4792e+01,  2.0081e+01,  3.4217e+01,\n",
      "         6.7216e+00,  1.4839e+01,  2.7194e+01,  2.6476e+01,  1.0138e+01,\n",
      "        -3.6059e-01,  2.5564e+01, -2.9032e+00, -8.6293e-01,  3.2769e+00,\n",
      "         6.4705e+00,  3.8686e+00,  1.1992e+01,  3.2098e+00, -1.2706e+00,\n",
      "        -2.3036e+00, -2.5548e+00, -2.6494e+00,  9.4201e+00, -6.1439e-01,\n",
      "         1.0203e+01,  5.6551e+00, -4.8153e+00,  7.2266e+00,  2.6471e-01,\n",
      "        -3.6850e+00,  5.5348e+00,  3.2687e+01, -3.8106e+00, -6.4268e-01,\n",
      "        -1.3962e+00, -3.2774e+00, -3.3230e-01,  4.2480e+00,  2.2621e+01,\n",
      "         1.4749e+01, -2.3036e+00, -2.1497e+00, -3.0571e+00, -2.7441e+00,\n",
      "         9.2093e-01, -3.3083e+00, -1.7730e+00, -2.8059e+00, -4.4385e+00,\n",
      "         5.6551e+00,  4.1833e-02, -3.0571e+00, -2.6211e+00,  3.8101e+00,\n",
      "         1.6097e+01,  4.9042e+00,  3.5476e+01,  8.4772e+00]) Cost: 196.419312\n",
      "Epochs 3400/10000 hypothesis: tensor([ 3.0644e+01,  5.1610e+00,  4.9047e+01,  4.9242e+01,  1.4343e+01,\n",
      "         4.9656e+01,  6.0005e+01,  5.8189e+00,  4.3602e+01,  3.9649e+01,\n",
      "         3.5547e+01,  4.7397e+01,  1.6445e+01,  1.6294e+01,  4.9304e+01,\n",
      "         2.7074e+01,  2.7136e+01,  5.0964e+01,  1.4688e+01,  5.7962e+01,\n",
      "         4.5485e+01,  3.6953e+01,  3.6951e+01,  2.7512e+01,  3.8763e+01,\n",
      "         3.5100e+01, -2.7772e+00,  1.2111e+00, -5.0669e+00, -4.4374e+00,\n",
      "        -5.0669e+00, -4.8750e-01, -5.4446e+00, -1.7415e+00, -4.8151e+00,\n",
      "        -4.6607e+00, -2.0218e+00,  5.3744e+00, -1.6206e+00, -5.5705e+00,\n",
      "        -3.5276e+00, -4.5633e+00, -6.2000e+00,  3.5883e+00,  4.4164e+01,\n",
      "         3.4764e+01,  3.2022e+01,  5.2977e+01,  2.0796e+01,  3.1186e+01,\n",
      "         3.1024e+01,  1.4222e+01,  4.3851e+01,  3.9618e+01, -4.6892e+00,\n",
      "         4.2463e+00, -8.6520e-01, -4.3115e+00, -4.6892e+00, -3.1549e+00,\n",
      "        -5.5705e+00,  3.4674e+00, -1.0980e-01, -2.7772e+00, -2.8697e+00,\n",
      "        -1.4947e+00, -4.5633e+00, -5.8223e+00, -4.6607e+00,  1.7913e+01,\n",
      "         1.0044e+01,  1.6763e+00,  3.1181e+00,  7.5361e+00,  1.6096e-02,\n",
      "         1.4200e-01, -3.3043e+00,  4.4931e+00,  1.3776e+01, -1.9884e+00,\n",
      "        -6.0845e-01,  1.8443e+01,  3.4785e+01,  2.0077e+01,  3.4212e+01,\n",
      "         6.7188e+00,  1.4837e+01,  2.7188e+01,  2.6471e+01,  1.0137e+01,\n",
      "        -3.5665e-01,  2.5556e+01, -2.9031e+00, -8.6025e-01,  3.2774e+00,\n",
      "         6.4670e+00,  3.8686e+00,  1.1990e+01,  3.2106e+00, -1.2664e+00,\n",
      "        -2.2971e+00, -2.5489e+00, -2.6463e+00,  9.4267e+00, -6.1340e-01,\n",
      "         1.0199e+01,  5.6547e+00, -4.8151e+00,  7.2274e+00,  2.6790e-01,\n",
      "        -3.6820e+00,  5.5387e+00,  3.2680e+01, -3.8079e+00, -6.3691e-01,\n",
      "        -1.3923e+00, -3.2758e+00, -3.3314e-01,  4.2512e+00,  2.2619e+01,\n",
      "         1.4749e+01, -2.2971e+00, -2.1477e+00, -3.0525e+00, -2.7438e+00,\n",
      "         9.2090e-01, -3.3043e+00, -1.7700e+00, -2.8007e+00, -4.4374e+00,\n",
      "         5.6547e+00,  3.9604e-02, -3.0525e+00, -2.6228e+00,  3.8095e+00,\n",
      "         1.6101e+01,  4.9042e+00,  3.5469e+01,  8.4764e+00]) Cost: 196.401398\n",
      "Epochs 3500/10000 hypothesis: tensor([ 3.0642e+01,  5.1640e+00,  4.9045e+01,  4.9245e+01,  1.4345e+01,\n",
      "         4.9657e+01,  6.0007e+01,  5.8211e+00,  4.3602e+01,  3.9652e+01,\n",
      "         3.5550e+01,  4.7400e+01,  1.6450e+01,  1.6297e+01,  4.9305e+01,\n",
      "         2.7078e+01,  2.7138e+01,  5.0964e+01,  1.4690e+01,  5.7962e+01,\n",
      "         4.5488e+01,  3.6957e+01,  3.6950e+01,  2.7509e+01,  3.8761e+01,\n",
      "         3.5105e+01, -2.7768e+00,  1.2140e+00, -5.0673e+00, -4.4363e+00,\n",
      "        -5.0673e+00, -4.8625e-01, -5.4460e+00, -1.7410e+00, -4.8149e+00,\n",
      "        -4.6626e+00, -2.0195e+00,  5.3757e+00, -1.6222e+00, -5.5722e+00,\n",
      "        -3.5267e+00, -4.5625e+00, -6.2032e+00,  3.5900e+00,  4.4167e+01,\n",
      "         3.4767e+01,  3.2023e+01,  5.2976e+01,  2.0797e+01,  3.1188e+01,\n",
      "         3.1028e+01,  1.4226e+01,  4.3855e+01,  3.9619e+01, -4.6887e+00,\n",
      "         4.2471e+00, -8.6489e-01, -4.3100e+00, -4.6887e+00, -3.1554e+00,\n",
      "        -5.5722e+00,  3.4711e+00, -1.0761e-01, -2.7768e+00, -2.8696e+00,\n",
      "        -1.4960e+00, -4.5625e+00, -5.8246e+00, -4.6626e+00,  1.7909e+01,\n",
      "         1.0042e+01,  1.6781e+00,  3.1185e+00,  7.5327e+00,  1.8603e-02,\n",
      "         1.4482e-01, -3.3003e+00,  4.4922e+00,  1.3773e+01, -1.9861e+00,\n",
      "        -6.0512e-01,  1.8440e+01,  3.4778e+01,  2.0073e+01,  3.4206e+01,\n",
      "         6.7159e+00,  1.4835e+01,  2.7183e+01,  2.6466e+01,  1.0135e+01,\n",
      "        -3.5269e-01,  2.5549e+01, -2.9030e+00, -8.5754e-01,  3.2781e+00,\n",
      "         6.4635e+00,  3.8685e+00,  1.1988e+01,  3.2113e+00, -1.2622e+00,\n",
      "        -2.2906e+00, -2.5431e+00, -2.6432e+00,  9.4332e+00, -6.1246e-01,\n",
      "         1.0195e+01,  5.6541e+00, -4.8149e+00,  7.2281e+00,  2.7103e-01,\n",
      "        -3.6790e+00,  5.5426e+00,  3.2673e+01, -3.8052e+00, -6.3117e-01,\n",
      "        -1.3884e+00, -3.2743e+00, -3.3398e-01,  4.2544e+00,  2.2616e+01,\n",
      "         1.4750e+01, -2.2906e+00, -2.1457e+00, -3.0479e+00, -2.7434e+00,\n",
      "         9.2080e-01, -3.3003e+00, -1.7671e+00, -2.7955e+00, -4.4363e+00,\n",
      "         5.6541e+00,  3.7308e-02, -3.0479e+00, -2.6245e+00,  3.8090e+00,\n",
      "         1.6104e+01,  4.9042e+00,  3.5461e+01,  8.4756e+00]) Cost: 196.383514\n",
      "Epochs 3600/10000 hypothesis: tensor([ 3.0640e+01,  5.1670e+00,  4.9042e+01,  4.9248e+01,  1.4346e+01,\n",
      "         4.9659e+01,  6.0010e+01,  5.8233e+00,  4.3603e+01,  3.9656e+01,\n",
      "         3.5553e+01,  4.7403e+01,  1.6454e+01,  1.6301e+01,  4.9305e+01,\n",
      "         2.7082e+01,  2.7139e+01,  5.0964e+01,  1.4692e+01,  5.7962e+01,\n",
      "         4.5491e+01,  3.6961e+01,  3.6949e+01,  2.7507e+01,  3.8760e+01,\n",
      "         3.5109e+01, -2.7764e+00,  1.2169e+00, -5.0677e+00, -4.4351e+00,\n",
      "        -5.0677e+00, -4.8504e-01, -5.4473e+00, -1.7405e+00, -4.8147e+00,\n",
      "        -4.6645e+00, -2.0172e+00,  5.3768e+00, -1.6238e+00, -5.5738e+00,\n",
      "        -3.5258e+00, -4.5616e+00, -6.2065e+00,  3.5916e+00,  4.4169e+01,\n",
      "         3.4770e+01,  3.2025e+01,  5.2976e+01,  2.0797e+01,  3.1190e+01,\n",
      "         3.1032e+01,  1.4230e+01,  4.3859e+01,  3.9620e+01, -4.6882e+00,\n",
      "         4.2479e+00, -8.6462e-01, -4.3086e+00, -4.6882e+00, -3.1560e+00,\n",
      "        -5.5738e+00,  3.4748e+00, -1.0546e-01, -2.7764e+00, -2.8694e+00,\n",
      "        -1.4972e+00, -4.5616e+00, -5.8269e+00, -4.6645e+00,  1.7905e+01,\n",
      "         1.0040e+01,  1.6798e+00,  3.1189e+00,  7.5294e+00,  2.1063e-02,\n",
      "         1.4759e-01, -3.2964e+00,  4.4911e+00,  1.3771e+01, -1.9838e+00,\n",
      "        -6.0177e-01,  1.8437e+01,  3.4772e+01,  2.0069e+01,  3.4201e+01,\n",
      "         6.7131e+00,  1.4833e+01,  2.7177e+01,  2.6461e+01,  1.0133e+01,\n",
      "        -3.4872e-01,  2.5542e+01, -2.9029e+00, -8.5483e-01,  3.2789e+00,\n",
      "         6.4600e+00,  3.8683e+00,  1.1986e+01,  3.2120e+00, -1.2581e+00,\n",
      "        -2.2842e+00, -2.5372e+00, -2.6401e+00,  9.4395e+00, -6.1157e-01,\n",
      "         1.0191e+01,  5.6535e+00, -4.8147e+00,  7.2290e+00,  2.7411e-01,\n",
      "        -3.6760e+00,  5.5466e+00,  3.2666e+01, -3.8025e+00, -6.2545e-01,\n",
      "        -1.3846e+00, -3.2727e+00, -3.3484e-01,  4.2577e+00,  2.2614e+01,\n",
      "         1.4750e+01, -2.2842e+00, -2.1438e+00, -3.0433e+00, -2.7429e+00,\n",
      "         9.2063e-01, -3.2964e+00, -1.7642e+00, -2.7903e+00, -4.4351e+00,\n",
      "         5.6535e+00,  3.4947e-02, -3.0433e+00, -2.6262e+00,  3.8087e+00,\n",
      "         1.6108e+01,  4.9042e+00,  3.5454e+01,  8.4747e+00]) Cost: 196.365677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 3700/10000 hypothesis: tensor([ 3.0638e+01,  5.1701e+00,  4.9040e+01,  4.9251e+01,  1.4348e+01,\n",
      "         4.9660e+01,  6.0013e+01,  5.8256e+00,  4.3604e+01,  3.9659e+01,\n",
      "         3.5556e+01,  4.7406e+01,  1.6458e+01,  1.6305e+01,  4.9305e+01,\n",
      "         2.7086e+01,  2.7141e+01,  5.0963e+01,  1.4695e+01,  5.7962e+01,\n",
      "         4.5495e+01,  3.6965e+01,  3.6948e+01,  2.7504e+01,  3.8759e+01,\n",
      "         3.5113e+01, -2.7760e+00,  1.2200e+00, -5.0681e+00, -4.4339e+00,\n",
      "        -5.0681e+00, -4.8386e-01, -5.4487e+00, -1.7400e+00, -4.8145e+00,\n",
      "        -4.6663e+00, -2.0150e+00,  5.3778e+00, -1.6254e+00, -5.5755e+00,\n",
      "        -3.5247e+00, -4.5608e+00, -6.2097e+00,  3.5931e+00,  4.4171e+01,\n",
      "         3.4774e+01,  3.2026e+01,  5.2976e+01,  2.0798e+01,  3.1192e+01,\n",
      "         3.1036e+01,  1.4233e+01,  4.3863e+01,  3.9621e+01, -4.6876e+00,\n",
      "         4.2486e+00, -8.6438e-01, -4.3071e+00, -4.6876e+00, -3.1565e+00,\n",
      "        -5.5755e+00,  3.4785e+00, -1.0335e-01, -2.7760e+00, -2.8692e+00,\n",
      "        -1.4986e+00, -4.5608e+00, -5.8292e+00, -4.6663e+00,  1.7900e+01,\n",
      "         1.0038e+01,  1.6814e+00,  3.1193e+00,  7.5262e+00,  2.3488e-02,\n",
      "         1.5033e-01, -3.2924e+00,  4.4900e+00,  1.3768e+01, -1.9814e+00,\n",
      "        -5.9842e-01,  1.8434e+01,  3.4766e+01,  2.0066e+01,  3.4196e+01,\n",
      "         6.7102e+00,  1.4830e+01,  2.7171e+01,  2.6456e+01,  1.0132e+01,\n",
      "        -3.4474e-01,  2.5535e+01, -2.9028e+00, -8.5209e-01,  3.2798e+00,\n",
      "         6.4566e+00,  3.8681e+00,  1.1984e+01,  3.2125e+00, -1.2539e+00,\n",
      "        -2.2777e+00, -2.5314e+00, -2.6369e+00,  9.4457e+00, -6.1070e-01,\n",
      "         1.0187e+01,  5.6529e+00, -4.8145e+00,  7.2299e+00,  2.7716e-01,\n",
      "        -3.6729e+00,  5.5506e+00,  3.2660e+01, -3.7998e+00, -6.1975e-01,\n",
      "        -1.3808e+00, -3.2711e+00, -3.3569e-01,  4.2609e+00,  2.2611e+01,\n",
      "         1.4750e+01, -2.2777e+00, -2.1418e+00, -3.0387e+00, -2.7424e+00,\n",
      "         9.2041e-01, -3.2924e+00, -1.7613e+00, -2.7851e+00, -4.4339e+00,\n",
      "         5.6529e+00,  3.2540e-02, -3.0387e+00, -2.6278e+00,  3.8085e+00,\n",
      "         1.6111e+01,  4.9041e+00,  3.5447e+01,  8.4737e+00]) Cost: 196.347885\n",
      "Epochs 3800/10000 hypothesis: tensor([ 3.0636e+01,  5.1732e+00,  4.9037e+01,  4.9253e+01,  1.4349e+01,\n",
      "         4.9662e+01,  6.0016e+01,  5.8279e+00,  4.3605e+01,  3.9662e+01,\n",
      "         3.5559e+01,  4.7409e+01,  1.6462e+01,  1.6309e+01,  4.9306e+01,\n",
      "         2.7089e+01,  2.7142e+01,  5.0963e+01,  1.4697e+01,  5.7962e+01,\n",
      "         4.5498e+01,  3.6968e+01,  3.6947e+01,  2.7502e+01,  3.8757e+01,\n",
      "         3.5116e+01, -2.7756e+00,  1.2231e+00, -5.0685e+00, -4.4328e+00,\n",
      "        -5.0685e+00, -4.8272e-01, -5.4500e+00, -1.7394e+00, -4.8142e+00,\n",
      "        -4.6681e+00, -2.0127e+00,  5.3788e+00, -1.6271e+00, -5.5771e+00,\n",
      "        -3.5237e+00, -4.5599e+00, -6.2129e+00,  3.5945e+00,  4.4173e+01,\n",
      "         3.4777e+01,  3.2027e+01,  5.2976e+01,  2.0798e+01,  3.1194e+01,\n",
      "         3.1039e+01,  1.4237e+01,  4.3866e+01,  3.9621e+01, -4.6871e+00,\n",
      "         4.2493e+00, -8.6418e-01, -4.3056e+00, -4.6871e+00, -3.1571e+00,\n",
      "        -5.5771e+00,  3.4822e+00, -1.0127e-01, -2.7756e+00, -2.8689e+00,\n",
      "        -1.4999e+00, -4.5599e+00, -5.8314e+00, -4.6681e+00,  1.7896e+01,\n",
      "         1.0036e+01,  1.6830e+00,  3.1197e+00,  7.5231e+00,  2.5875e-02,\n",
      "         1.5303e-01, -3.2884e+00,  4.4887e+00,  1.3766e+01, -1.9789e+00,\n",
      "        -5.9506e-01,  1.8430e+01,  3.4760e+01,  2.0062e+01,  3.4190e+01,\n",
      "         6.7074e+00,  1.4828e+01,  2.7165e+01,  2.6451e+01,  1.0130e+01,\n",
      "        -3.4076e-01,  2.5527e+01, -2.9028e+00, -8.4936e-01,  3.2807e+00,\n",
      "         6.4531e+00,  3.8678e+00,  1.1982e+01,  3.2130e+00, -1.2498e+00,\n",
      "        -2.2712e+00, -2.5255e+00, -2.6337e+00,  9.4518e+00, -6.0987e-01,\n",
      "         1.0183e+01,  5.6521e+00, -4.8142e+00,  7.2308e+00,  2.8018e-01,\n",
      "        -3.6699e+00,  5.5546e+00,  3.2654e+01, -3.7970e+00, -6.1408e-01,\n",
      "        -1.3770e+00, -3.2694e+00, -3.3655e-01,  4.2641e+00,  2.2609e+01,\n",
      "         1.4749e+01, -2.2712e+00, -2.1399e+00, -3.0341e+00, -2.7418e+00,\n",
      "         9.2013e-01, -3.2884e+00, -1.7584e+00, -2.7798e+00, -4.4328e+00,\n",
      "         5.6521e+00,  3.0080e-02, -3.0341e+00, -2.6295e+00,  3.8083e+00,\n",
      "         1.6114e+01,  4.9040e+00,  3.5440e+01,  8.4726e+00]) Cost: 196.330063\n",
      "Epochs 3900/10000 hypothesis: tensor([ 3.0634e+01,  5.1763e+00,  4.9034e+01,  4.9255e+01,  1.4350e+01,\n",
      "         4.9663e+01,  6.0019e+01,  5.8303e+00,  4.3606e+01,  3.9665e+01,\n",
      "         3.5562e+01,  4.7412e+01,  1.6466e+01,  1.6313e+01,  4.9306e+01,\n",
      "         2.7092e+01,  2.7143e+01,  5.0963e+01,  1.4698e+01,  5.7963e+01,\n",
      "         4.5501e+01,  3.6972e+01,  3.6946e+01,  2.7500e+01,  3.8755e+01,\n",
      "         3.5120e+01, -2.7753e+00,  1.2263e+00, -5.0689e+00, -4.4316e+00,\n",
      "        -5.0689e+00, -4.8161e-01, -5.4513e+00, -1.7388e+00, -4.8140e+00,\n",
      "        -4.6698e+00, -2.0105e+00,  5.3797e+00, -1.6288e+00, -5.5788e+00,\n",
      "        -3.5226e+00, -4.5591e+00, -6.2161e+00,  3.5959e+00,  4.4176e+01,\n",
      "         3.4781e+01,  3.2027e+01,  5.2976e+01,  2.0797e+01,  3.1196e+01,\n",
      "         3.1042e+01,  1.4240e+01,  4.3870e+01,  3.9622e+01, -4.6865e+00,\n",
      "         4.2499e+00, -8.6400e-01, -4.3042e+00, -4.6865e+00, -3.1577e+00,\n",
      "        -5.5788e+00,  3.4858e+00, -9.9228e-02, -2.7753e+00, -2.8686e+00,\n",
      "        -1.5013e+00, -4.5591e+00, -5.8337e+00, -4.6698e+00,  1.7892e+01,\n",
      "         1.0035e+01,  1.6846e+00,  3.1201e+00,  7.5201e+00,  2.8233e-02,\n",
      "         1.5569e-01, -3.2845e+00,  4.4874e+00,  1.3764e+01, -1.9764e+00,\n",
      "        -5.9168e-01,  1.8427e+01,  3.4754e+01,  2.0058e+01,  3.4185e+01,\n",
      "         6.7045e+00,  1.4825e+01,  2.7159e+01,  2.6446e+01,  1.0128e+01,\n",
      "        -3.3676e-01,  2.5520e+01, -2.9027e+00, -8.4661e-01,  3.2817e+00,\n",
      "         6.4496e+00,  3.8675e+00,  1.1980e+01,  3.2135e+00, -1.2457e+00,\n",
      "        -2.2648e+00, -2.5197e+00, -2.6304e+00,  9.4578e+00, -6.0907e-01,\n",
      "         1.0179e+01,  5.6513e+00, -4.8140e+00,  7.2317e+00,  2.8316e-01,\n",
      "        -3.6668e+00,  5.5586e+00,  3.2647e+01, -3.7943e+00, -6.0842e-01,\n",
      "        -1.3732e+00, -3.2677e+00, -3.3741e-01,  4.2673e+00,  2.2607e+01,\n",
      "         1.4749e+01, -2.2648e+00, -2.1380e+00, -3.0295e+00, -2.7411e+00,\n",
      "         9.1981e-01, -3.2845e+00, -1.7556e+00, -2.7746e+00, -4.4316e+00,\n",
      "         5.6513e+00,  2.7584e-02, -3.0295e+00, -2.6311e+00,  3.8083e+00,\n",
      "         1.6117e+01,  4.9040e+00,  3.5434e+01,  8.4716e+00]) Cost: 196.312347\n",
      "Epochs 4000/10000 hypothesis: tensor([ 3.0632e+01,  5.1794e+00,  4.9031e+01,  4.9258e+01,  1.4351e+01,\n",
      "         4.9665e+01,  6.0022e+01,  5.8327e+00,  4.3608e+01,  3.9668e+01,\n",
      "         3.5566e+01,  4.7415e+01,  1.6469e+01,  1.6317e+01,  4.9306e+01,\n",
      "         2.7096e+01,  2.7145e+01,  5.0962e+01,  1.4700e+01,  5.7963e+01,\n",
      "         4.5504e+01,  3.6975e+01,  3.6946e+01,  2.7498e+01,  3.8753e+01,\n",
      "         3.5123e+01, -2.7749e+00,  1.2295e+00, -5.0693e+00, -4.4305e+00,\n",
      "        -5.0693e+00, -4.8053e-01, -5.4526e+00, -1.7383e+00, -4.8138e+00,\n",
      "        -4.6715e+00, -2.0083e+00,  5.3805e+00, -1.6305e+00, -5.5804e+00,\n",
      "        -3.5216e+00, -4.5582e+00, -6.2193e+00,  3.5972e+00,  4.4178e+01,\n",
      "         3.4785e+01,  3.2028e+01,  5.2977e+01,  2.0797e+01,  3.1198e+01,\n",
      "         3.1046e+01,  1.4244e+01,  4.3873e+01,  3.9623e+01, -4.6860e+00,\n",
      "         4.2505e+00, -8.6385e-01, -4.3027e+00, -4.6860e+00, -3.1582e+00,\n",
      "        -5.5804e+00,  3.4894e+00, -9.7210e-02, -2.7749e+00, -2.8682e+00,\n",
      "        -1.5027e+00, -4.5582e+00, -5.8359e+00, -4.6715e+00,  1.7888e+01,\n",
      "         1.0033e+01,  1.6861e+00,  3.1206e+00,  7.5172e+00,  3.0563e-02,\n",
      "         1.5834e-01, -3.2805e+00,  4.4861e+00,  1.3762e+01, -1.9738e+00,\n",
      "        -5.8831e-01,  1.8424e+01,  3.4749e+01,  2.0055e+01,  3.4179e+01,\n",
      "         6.7016e+00,  1.4823e+01,  2.7154e+01,  2.6441e+01,  1.0126e+01,\n",
      "        -3.3276e-01,  2.5512e+01, -2.9027e+00, -8.4385e-01,  3.2828e+00,\n",
      "         6.4461e+00,  3.8672e+00,  1.1978e+01,  3.2139e+00, -1.2416e+00,\n",
      "        -2.2583e+00, -2.5139e+00, -2.6272e+00,  9.4637e+00, -6.0830e-01,\n",
      "         1.0175e+01,  5.6505e+00, -4.8138e+00,  7.2327e+00,  2.8611e-01,\n",
      "        -3.6638e+00,  5.5627e+00,  3.2641e+01, -3.7916e+00, -6.0279e-01,\n",
      "        -1.3694e+00, -3.2660e+00, -3.3828e-01,  4.2705e+00,  2.2605e+01,\n",
      "         1.4749e+01, -2.2583e+00, -2.1361e+00, -3.0250e+00, -2.7404e+00,\n",
      "         9.1946e-01, -3.2805e+00, -1.7527e+00, -2.7694e+00, -4.4305e+00,\n",
      "         5.6505e+00,  2.5049e-02, -3.0250e+00, -2.6327e+00,  3.8084e+00,\n",
      "         1.6120e+01,  4.9039e+00,  3.5427e+01,  8.4705e+00]) Cost: 196.294647\n",
      "Epochs 4100/10000 hypothesis: tensor([ 3.0630e+01,  5.1825e+00,  4.9028e+01,  4.9260e+01,  1.4353e+01,\n",
      "         4.9668e+01,  6.0025e+01,  5.8352e+00,  4.3609e+01,  3.9670e+01,\n",
      "         3.5569e+01,  4.7419e+01,  1.6473e+01,  1.6321e+01,  4.9307e+01,\n",
      "         2.7099e+01,  2.7146e+01,  5.0961e+01,  1.4702e+01,  5.7964e+01,\n",
      "         4.5508e+01,  3.6979e+01,  3.6945e+01,  2.7496e+01,  3.8751e+01,\n",
      "         3.5126e+01, -2.7746e+00,  1.2327e+00, -5.0697e+00, -4.4293e+00,\n",
      "        -5.0697e+00, -4.7946e-01, -5.4539e+00, -1.7377e+00, -4.8135e+00,\n",
      "        -4.6732e+00, -2.0061e+00,  5.3812e+00, -1.6322e+00, -5.5820e+00,\n",
      "        -3.5205e+00, -4.5574e+00, -6.2224e+00,  3.5984e+00,  4.4180e+01,\n",
      "         3.4788e+01,  3.2028e+01,  5.2977e+01,  2.0796e+01,  3.1200e+01,\n",
      "         3.1048e+01,  1.4247e+01,  4.3876e+01,  3.9624e+01, -4.6854e+00,\n",
      "         4.2511e+00, -8.6371e-01, -4.3012e+00, -4.6854e+00, -3.1588e+00,\n",
      "        -5.5820e+00,  3.4930e+00, -9.5213e-02, -2.7746e+00, -2.8678e+00,\n",
      "        -1.5041e+00, -4.5574e+00, -5.8382e+00, -4.6732e+00,  1.7884e+01,\n",
      "         1.0031e+01,  1.6876e+00,  3.1210e+00,  7.5144e+00,  3.2870e-02,\n",
      "         1.6095e-01, -3.2765e+00,  4.4846e+00,  1.3759e+01, -1.9712e+00,\n",
      "        -5.8493e-01,  1.8420e+01,  3.4744e+01,  2.0051e+01,  3.4173e+01,\n",
      "         6.6988e+00,  1.4820e+01,  2.7148e+01,  2.6437e+01,  1.0124e+01,\n",
      "        -3.2876e-01,  2.5505e+01, -2.9027e+00, -8.4109e-01,  3.2839e+00,\n",
      "         6.4426e+00,  3.8668e+00,  1.1977e+01,  3.2142e+00, -1.2376e+00,\n",
      "        -2.2519e+00, -2.5080e+00, -2.6239e+00,  9.4695e+00, -6.0755e-01,\n",
      "         1.0171e+01,  5.6496e+00, -4.8135e+00,  7.2337e+00,  2.8904e-01,\n",
      "        -3.6608e+00,  5.5668e+00,  3.2635e+01, -3.7889e+00, -5.9716e-01,\n",
      "        -1.3657e+00, -3.2643e+00, -3.3914e-01,  4.2737e+00,  2.2603e+01,\n",
      "         1.4749e+01, -2.2519e+00, -2.1342e+00, -3.0204e+00, -2.7397e+00,\n",
      "         9.1907e-01, -3.2765e+00, -1.7499e+00, -2.7642e+00, -4.4293e+00,\n",
      "         5.6496e+00,  2.2487e-02, -3.0204e+00, -2.6343e+00,  3.8085e+00,\n",
      "         1.6123e+01,  4.9037e+00,  3.5420e+01,  8.4693e+00]) Cost: 196.276978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 4200/10000 hypothesis: tensor([ 3.0628e+01,  5.1857e+00,  4.9025e+01,  4.9262e+01,  1.4354e+01,\n",
      "         4.9670e+01,  6.0029e+01,  5.8377e+00,  4.3610e+01,  3.9673e+01,\n",
      "         3.5573e+01,  4.7422e+01,  1.6476e+01,  1.6325e+01,  4.9307e+01,\n",
      "         2.7102e+01,  2.7147e+01,  5.0961e+01,  1.4704e+01,  5.7964e+01,\n",
      "         4.5511e+01,  3.6982e+01,  3.6944e+01,  2.7494e+01,  3.8749e+01,\n",
      "         3.5129e+01, -2.7742e+00,  1.2360e+00, -5.0701e+00, -4.4281e+00,\n",
      "        -5.0701e+00, -4.7842e-01, -5.4553e+00, -1.7371e+00, -4.8133e+00,\n",
      "        -4.6749e+00, -2.0039e+00,  5.3819e+00, -1.6340e+00, -5.5836e+00,\n",
      "        -3.5193e+00, -4.5565e+00, -6.2256e+00,  3.5997e+00,  4.4182e+01,\n",
      "         3.4792e+01,  3.2028e+01,  5.2977e+01,  2.0795e+01,  3.1202e+01,\n",
      "         3.1051e+01,  1.4251e+01,  4.3880e+01,  3.9625e+01, -4.6849e+00,\n",
      "         4.2516e+00, -8.6360e-01, -4.2997e+00, -4.6849e+00, -3.1594e+00,\n",
      "        -5.5836e+00,  3.4965e+00, -9.3238e-02, -2.7742e+00, -2.8674e+00,\n",
      "        -1.5056e+00, -4.5565e+00, -5.8404e+00, -4.6749e+00,  1.7880e+01,\n",
      "         1.0029e+01,  1.6890e+00,  3.1214e+00,  7.5116e+00,  3.5156e-02,\n",
      "         1.6355e-01, -3.2726e+00,  4.4832e+00,  1.3757e+01, -1.9686e+00,\n",
      "        -5.8154e-01,  1.8417e+01,  3.4739e+01,  2.0048e+01,  3.4168e+01,\n",
      "         6.6959e+00,  1.4817e+01,  2.7142e+01,  2.6432e+01,  1.0122e+01,\n",
      "        -3.2475e-01,  2.5498e+01, -2.9026e+00, -8.3833e-01,  3.2851e+00,\n",
      "         6.4391e+00,  3.8665e+00,  1.1975e+01,  3.2145e+00, -1.2335e+00,\n",
      "        -2.2454e+00, -2.5022e+00, -2.6206e+00,  9.4753e+00, -6.0681e-01,\n",
      "         1.0167e+01,  5.6487e+00, -4.8133e+00,  7.2348e+00,  2.9194e-01,\n",
      "        -3.6577e+00,  5.5709e+00,  3.2630e+01, -3.7861e+00, -5.9156e-01,\n",
      "        -1.3619e+00, -3.2625e+00, -3.4001e-01,  4.2769e+00,  2.2601e+01,\n",
      "         1.4749e+01, -2.2454e+00, -2.1323e+00, -3.0158e+00, -2.7390e+00,\n",
      "         9.1865e-01, -3.2726e+00, -1.7471e+00, -2.7590e+00, -4.4281e+00,\n",
      "         5.6487e+00,  1.9900e-02, -3.0158e+00, -2.6358e+00,  3.8087e+00,\n",
      "         1.6126e+01,  4.9036e+00,  3.5414e+01,  8.4681e+00]) Cost: 196.259323\n",
      "Epochs 4300/10000 hypothesis: tensor([ 3.0626e+01,  5.1889e+00,  4.9022e+01,  4.9264e+01,  1.4355e+01,\n",
      "         4.9672e+01,  6.0032e+01,  5.8402e+00,  4.3612e+01,  3.9676e+01,\n",
      "         3.5576e+01,  4.7425e+01,  1.6479e+01,  1.6329e+01,  4.9307e+01,\n",
      "         2.7104e+01,  2.7148e+01,  5.0960e+01,  1.4705e+01,  5.7965e+01,\n",
      "         4.5514e+01,  3.6985e+01,  3.6944e+01,  2.7493e+01,  3.8747e+01,\n",
      "         3.5132e+01, -2.7739e+00,  1.2393e+00, -5.0705e+00, -4.4269e+00,\n",
      "        -5.0705e+00, -4.7740e-01, -5.4566e+00, -1.7365e+00, -4.8131e+00,\n",
      "        -4.6765e+00, -2.0017e+00,  5.3826e+00, -1.6357e+00, -5.5853e+00,\n",
      "        -3.5182e+00, -4.5556e+00, -6.2288e+00,  3.6009e+00,  4.4184e+01,\n",
      "         3.4796e+01,  3.2028e+01,  5.2978e+01,  2.0795e+01,  3.1205e+01,\n",
      "         3.1054e+01,  1.4254e+01,  4.3883e+01,  3.9626e+01, -4.6844e+00,\n",
      "         4.2522e+00, -8.6351e-01, -4.2982e+00, -4.6844e+00, -3.1600e+00,\n",
      "        -5.5853e+00,  3.5001e+00, -9.1286e-02, -2.7739e+00, -2.8669e+00,\n",
      "        -1.5070e+00, -4.5556e+00, -5.8427e+00, -4.6765e+00,  1.7877e+01,\n",
      "         1.0027e+01,  1.6904e+00,  3.1218e+00,  7.5088e+00,  3.7418e-02,\n",
      "         1.6612e-01, -3.2686e+00,  4.4816e+00,  1.3755e+01, -1.9660e+00,\n",
      "        -5.7816e-01,  1.8413e+01,  3.4734e+01,  2.0045e+01,  3.4162e+01,\n",
      "         6.6930e+00,  1.4814e+01,  2.7136e+01,  2.6427e+01,  1.0120e+01,\n",
      "        -3.2075e-01,  2.5490e+01, -2.9026e+00, -8.3556e-01,  3.2862e+00,\n",
      "         6.4356e+00,  3.8661e+00,  1.1973e+01,  3.2147e+00, -1.2295e+00,\n",
      "        -2.2390e+00, -2.4964e+00, -2.6173e+00,  9.4810e+00, -6.0610e-01,\n",
      "         1.0164e+01,  5.6478e+00, -4.8131e+00,  7.2358e+00,  2.9483e-01,\n",
      "        -3.6547e+00,  5.5750e+00,  3.2624e+01, -3.7834e+00, -5.8596e-01,\n",
      "        -1.3582e+00, -3.2608e+00, -3.4089e-01,  4.2801e+00,  2.2598e+01,\n",
      "         1.4749e+01, -2.2390e+00, -2.1304e+00, -3.0112e+00, -2.7382e+00,\n",
      "         9.1821e-01, -3.2686e+00, -1.7443e+00, -2.7538e+00, -4.4269e+00,\n",
      "         5.6478e+00,  1.7281e-02, -3.0112e+00, -2.6374e+00,  3.8089e+00,\n",
      "         1.6129e+01,  4.9035e+00,  3.5407e+01,  8.4669e+00]) Cost: 196.241699\n",
      "Epochs 4400/10000 hypothesis: tensor([ 3.0624e+01,  5.1920e+00,  4.9019e+01,  4.9266e+01,  1.4356e+01,\n",
      "         4.9674e+01,  6.0036e+01,  5.8427e+00,  4.3613e+01,  3.9678e+01,\n",
      "         3.5580e+01,  4.7428e+01,  1.6482e+01,  1.6333e+01,  4.9308e+01,\n",
      "         2.7107e+01,  2.7149e+01,  5.0960e+01,  1.4707e+01,  5.7966e+01,\n",
      "         4.5518e+01,  3.6989e+01,  3.6943e+01,  2.7491e+01,  3.8745e+01,\n",
      "         3.5135e+01, -2.7736e+00,  1.2427e+00, -5.0708e+00, -4.4258e+00,\n",
      "        -5.0708e+00, -4.7638e-01, -5.4579e+00, -1.7359e+00, -4.8128e+00,\n",
      "        -4.6782e+00, -1.9995e+00,  5.3832e+00, -1.6375e+00, -5.5869e+00,\n",
      "        -3.5170e+00, -4.5548e+00, -6.2319e+00,  3.6020e+00,  4.4186e+01,\n",
      "         3.4800e+01,  3.2027e+01,  5.2979e+01,  2.0794e+01,  3.1207e+01,\n",
      "         3.1057e+01,  1.4258e+01,  4.3886e+01,  3.9628e+01, -4.6838e+00,\n",
      "         4.2527e+00, -8.6342e-01, -4.2967e+00, -4.6838e+00, -3.1606e+00,\n",
      "        -5.5869e+00,  3.5036e+00, -8.9340e-02, -2.7736e+00, -2.8664e+00,\n",
      "        -1.5085e+00, -4.5548e+00, -5.8449e+00, -4.6782e+00,  1.7873e+01,\n",
      "         1.0025e+01,  1.6918e+00,  3.1222e+00,  7.5061e+00,  3.9673e-02,\n",
      "         1.6869e-01, -3.2646e+00,  4.4801e+00,  1.3753e+01, -1.9633e+00,\n",
      "        -5.7476e-01,  1.8409e+01,  3.4730e+01,  2.0041e+01,  3.4156e+01,\n",
      "         6.6902e+00,  1.4811e+01,  2.7130e+01,  2.6422e+01,  1.0118e+01,\n",
      "        -3.1673e-01,  2.5483e+01, -2.9026e+00, -8.3279e-01,  3.2875e+00,\n",
      "         6.4321e+00,  3.8657e+00,  1.1972e+01,  3.2150e+00, -1.2254e+00,\n",
      "        -2.2325e+00, -2.4906e+00, -2.6140e+00,  9.4866e+00, -6.0539e-01,\n",
      "         1.0160e+01,  5.6468e+00, -4.8128e+00,  7.2369e+00,  2.9770e-01,\n",
      "        -3.6517e+00,  5.5791e+00,  3.2618e+01, -3.7807e+00, -5.8038e-01,\n",
      "        -1.3545e+00, -3.2590e+00, -3.4175e-01,  4.2833e+00,  2.2596e+01,\n",
      "         1.4749e+01, -2.2325e+00, -2.1285e+00, -3.0066e+00, -2.7373e+00,\n",
      "         9.1775e-01, -3.2646e+00, -1.7415e+00, -2.7486e+00, -4.4258e+00,\n",
      "         5.6468e+00,  1.4658e-02, -3.0066e+00, -2.6390e+00,  3.8091e+00,\n",
      "         1.6131e+01,  4.9034e+00,  3.5401e+01,  8.4657e+00]) Cost: 196.224121\n",
      "Epochs 4500/10000 hypothesis: tensor([ 3.0622e+01,  5.1952e+00,  4.9016e+01,  4.9268e+01,  1.4357e+01,\n",
      "         4.9677e+01,  6.0039e+01,  5.8453e+00,  4.3615e+01,  3.9681e+01,\n",
      "         3.5584e+01,  4.7431e+01,  1.6485e+01,  1.6337e+01,  4.9308e+01,\n",
      "         2.7110e+01,  2.7150e+01,  5.0959e+01,  1.4708e+01,  5.7967e+01,\n",
      "         4.5521e+01,  3.6992e+01,  3.6943e+01,  2.7489e+01,  3.8742e+01,\n",
      "         3.5138e+01, -2.7733e+00,  1.2460e+00, -5.0712e+00, -4.4246e+00,\n",
      "        -5.0712e+00, -4.7539e-01, -5.4592e+00, -1.7353e+00, -4.8126e+00,\n",
      "        -4.6798e+00, -1.9974e+00,  5.3838e+00, -1.6393e+00, -5.5885e+00,\n",
      "        -3.5159e+00, -4.5539e+00, -6.2351e+00,  3.6031e+00,  4.4188e+01,\n",
      "         3.4804e+01,  3.2027e+01,  5.2979e+01,  2.0793e+01,  3.1210e+01,\n",
      "         3.1059e+01,  1.4261e+01,  4.3889e+01,  3.9629e+01, -4.6832e+00,\n",
      "         4.2532e+00, -8.6335e-01, -4.2953e+00, -4.6832e+00, -3.1613e+00,\n",
      "        -5.5885e+00,  3.5072e+00, -8.7419e-02, -2.7733e+00, -2.8658e+00,\n",
      "        -1.5100e+00, -4.5539e+00, -5.8471e+00, -4.6798e+00,  1.7869e+01,\n",
      "         1.0023e+01,  1.6932e+00,  3.1226e+00,  7.5035e+00,  4.1904e-02,\n",
      "         1.7123e-01, -3.2607e+00,  4.4785e+00,  1.3751e+01, -1.9606e+00,\n",
      "        -5.7137e-01,  1.8406e+01,  3.4725e+01,  2.0038e+01,  3.4150e+01,\n",
      "         6.6873e+00,  1.4808e+01,  2.7124e+01,  2.6418e+01,  1.0116e+01,\n",
      "        -3.1272e-01,  2.5476e+01, -2.9026e+00, -8.3001e-01,  3.2887e+00,\n",
      "         6.4287e+00,  3.8652e+00,  1.1970e+01,  3.2152e+00, -1.2214e+00,\n",
      "        -2.2261e+00, -2.4847e+00, -2.6106e+00,  9.4922e+00, -6.0471e-01,\n",
      "         1.0156e+01,  5.6458e+00, -4.8126e+00,  7.2379e+00,  3.0055e-01,\n",
      "        -3.6487e+00,  5.5832e+00,  3.2613e+01, -3.7780e+00, -5.7481e-01,\n",
      "        -1.3507e+00, -3.2572e+00, -3.4262e-01,  4.2865e+00,  2.2594e+01,\n",
      "         1.4748e+01, -2.2261e+00, -2.1267e+00, -3.0020e+00, -2.7365e+00,\n",
      "         9.1726e-01, -3.2607e+00, -1.7387e+00, -2.7434e+00, -4.4246e+00,\n",
      "         5.6458e+00,  1.2004e-02, -3.0020e+00, -2.6405e+00,  3.8095e+00,\n",
      "         1.6134e+01,  4.9032e+00,  3.5394e+01,  8.4645e+00]) Cost: 196.206558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 4600/10000 hypothesis: tensor([ 3.0620e+01,  5.1984e+00,  4.9013e+01,  4.9269e+01,  1.4358e+01,\n",
      "         4.9679e+01,  6.0043e+01,  5.8479e+00,  4.3616e+01,  3.9684e+01,\n",
      "         3.5587e+01,  4.7434e+01,  1.6488e+01,  1.6341e+01,  4.9308e+01,\n",
      "         2.7112e+01,  2.7151e+01,  5.0958e+01,  1.4710e+01,  5.7967e+01,\n",
      "         4.5525e+01,  3.6995e+01,  3.6942e+01,  2.7488e+01,  3.8740e+01,\n",
      "         3.5140e+01, -2.7730e+00,  1.2494e+00, -5.0716e+00, -4.4234e+00,\n",
      "        -5.0716e+00, -4.7440e-01, -5.4605e+00, -1.7347e+00, -4.8123e+00,\n",
      "        -4.6814e+00, -1.9952e+00,  5.3843e+00, -1.6411e+00, -5.5901e+00,\n",
      "        -3.5147e+00, -4.5530e+00, -6.2383e+00,  3.6042e+00,  4.4190e+01,\n",
      "         3.4808e+01,  3.2026e+01,  5.2980e+01,  2.0791e+01,  3.1212e+01,\n",
      "         3.1061e+01,  1.4264e+01,  4.3892e+01,  3.9630e+01, -4.6827e+00,\n",
      "         4.2537e+00, -8.6330e-01, -4.2938e+00, -4.6827e+00, -3.1619e+00,\n",
      "        -5.5901e+00,  3.5107e+00, -8.5508e-02, -2.7730e+00, -2.8653e+00,\n",
      "        -1.5115e+00, -4.5530e+00, -5.8494e+00, -4.6814e+00,  1.7866e+01,\n",
      "         1.0021e+01,  1.6946e+00,  3.1230e+00,  7.5008e+00,  4.4124e-02,\n",
      "         1.7376e-01, -3.2567e+00,  4.4769e+00,  1.3748e+01, -1.9579e+00,\n",
      "        -5.6797e-01,  1.8402e+01,  3.4721e+01,  2.0035e+01,  3.4144e+01,\n",
      "         6.6844e+00,  1.4804e+01,  2.7118e+01,  2.6413e+01,  1.0114e+01,\n",
      "        -3.0871e-01,  2.5468e+01, -2.9026e+00, -8.2724e-01,  3.2900e+00,\n",
      "         6.4252e+00,  3.8648e+00,  1.1968e+01,  3.2153e+00, -1.2174e+00,\n",
      "        -2.2197e+00, -2.4789e+00, -2.6073e+00,  9.4977e+00, -6.0403e-01,\n",
      "         1.0152e+01,  5.6448e+00, -4.8123e+00,  7.2390e+00,  3.0339e-01,\n",
      "        -3.6456e+00,  5.5873e+00,  3.2607e+01, -3.7753e+00, -5.6925e-01,\n",
      "        -1.3470e+00, -3.2555e+00, -3.4350e-01,  4.2897e+00,  2.2592e+01,\n",
      "         1.4748e+01, -2.2197e+00, -2.1248e+00, -2.9975e+00, -2.7357e+00,\n",
      "         9.1676e-01, -3.2567e+00, -1.7359e+00, -2.7382e+00, -4.4234e+00,\n",
      "         5.6448e+00,  9.3391e-03, -2.9975e+00, -2.6421e+00,  3.8098e+00,\n",
      "         1.6137e+01,  4.9031e+00,  3.5388e+01,  8.4632e+00]) Cost: 196.189026\n",
      "Epochs 4700/10000 hypothesis: tensor([ 3.0618e+01,  5.2016e+00,  4.9009e+01,  4.9271e+01,  1.4359e+01,\n",
      "         4.9682e+01,  6.0046e+01,  5.8504e+00,  4.3618e+01,  3.9686e+01,\n",
      "         3.5591e+01,  4.7438e+01,  1.6491e+01,  1.6345e+01,  4.9308e+01,\n",
      "         2.7115e+01,  2.7152e+01,  5.0958e+01,  1.4711e+01,  5.7968e+01,\n",
      "         4.5528e+01,  3.6998e+01,  3.6942e+01,  2.7486e+01,  3.8738e+01,\n",
      "         3.5143e+01, -2.7727e+00,  1.2528e+00, -5.0719e+00, -4.4222e+00,\n",
      "        -5.0719e+00, -4.7343e-01, -5.4618e+00, -1.7340e+00, -4.8121e+00,\n",
      "        -4.6830e+00, -1.9930e+00,  5.3848e+00, -1.6429e+00, -5.5917e+00,\n",
      "        -3.5135e+00, -4.5522e+00, -6.2414e+00,  3.6053e+00,  4.4192e+01,\n",
      "         3.4812e+01,  3.2026e+01,  5.2981e+01,  2.0790e+01,  3.1215e+01,\n",
      "         3.1064e+01,  1.4268e+01,  4.3895e+01,  3.9631e+01, -4.6821e+00,\n",
      "         4.2541e+00, -8.6325e-01, -4.2923e+00, -4.6821e+00, -3.1625e+00,\n",
      "        -5.5917e+00,  3.5142e+00, -8.3607e-02, -2.7727e+00, -2.8647e+00,\n",
      "        -1.5130e+00, -4.5522e+00, -5.8516e+00, -4.6830e+00,  1.7862e+01,\n",
      "         1.0019e+01,  1.6959e+00,  3.1235e+00,  7.4982e+00,  4.6333e-02,\n",
      "         1.7627e-01, -3.2528e+00,  4.4752e+00,  1.3746e+01, -1.9551e+00,\n",
      "        -5.6459e-01,  1.8398e+01,  3.4717e+01,  2.0031e+01,  3.4138e+01,\n",
      "         6.6816e+00,  1.4801e+01,  2.7111e+01,  2.6409e+01,  1.0112e+01,\n",
      "        -3.0470e-01,  2.5461e+01, -2.9026e+00, -8.2447e-01,  3.2913e+00,\n",
      "         6.4217e+00,  3.8643e+00,  1.1967e+01,  3.2155e+00, -1.2134e+00,\n",
      "        -2.2133e+00, -2.4731e+00, -2.6040e+00,  9.5032e+00, -6.0337e-01,\n",
      "         1.0149e+01,  5.6438e+00, -4.8121e+00,  7.2401e+00,  3.0621e-01,\n",
      "        -3.6426e+00,  5.5914e+00,  3.2602e+01, -3.7725e+00, -5.6370e-01,\n",
      "        -1.3433e+00, -3.2537e+00, -3.4437e-01,  4.2929e+00,  2.2591e+01,\n",
      "         1.4748e+01, -2.2133e+00, -2.1230e+00, -2.9929e+00, -2.7348e+00,\n",
      "         9.1625e-01, -3.2528e+00, -1.7332e+00, -2.7330e+00, -4.4222e+00,\n",
      "         5.6438e+00,  6.6634e-03, -2.9929e+00, -2.6436e+00,  3.8102e+00,\n",
      "         1.6139e+01,  4.9030e+00,  3.5382e+01,  8.4620e+00]) Cost: 196.171570\n",
      "Epochs 4800/10000 hypothesis: tensor([ 3.0616e+01,  5.2048e+00,  4.9006e+01,  4.9273e+01,  1.4360e+01,\n",
      "         4.9684e+01,  6.0050e+01,  5.8530e+00,  4.3619e+01,  3.9688e+01,\n",
      "         3.5595e+01,  4.7441e+01,  1.6494e+01,  1.6349e+01,  4.9308e+01,\n",
      "         2.7117e+01,  2.7153e+01,  5.0957e+01,  1.4712e+01,  5.7969e+01,\n",
      "         4.5531e+01,  3.7001e+01,  3.6942e+01,  2.7484e+01,  3.8735e+01,\n",
      "         3.5145e+01, -2.7724e+00,  1.2562e+00, -5.0723e+00, -4.4211e+00,\n",
      "        -5.0723e+00, -4.7246e-01, -5.4630e+00, -1.7334e+00, -4.8118e+00,\n",
      "        -4.6846e+00, -1.9909e+00,  5.3853e+00, -1.6447e+00, -5.5933e+00,\n",
      "        -3.5123e+00, -4.5513e+00, -6.2445e+00,  3.6064e+00,  4.4194e+01,\n",
      "         3.4816e+01,  3.2025e+01,  5.2982e+01,  2.0789e+01,  3.1217e+01,\n",
      "         3.1066e+01,  1.4271e+01,  4.3898e+01,  3.9632e+01, -4.6816e+00,\n",
      "         4.2546e+00, -8.6321e-01, -4.2908e+00, -4.6816e+00, -3.1631e+00,\n",
      "        -5.5933e+00,  3.5177e+00, -8.1715e-02, -2.7724e+00, -2.8641e+00,\n",
      "        -1.5144e+00, -4.5513e+00, -5.8538e+00, -4.6846e+00,  1.7858e+01,\n",
      "         1.0018e+01,  1.6972e+00,  3.1239e+00,  7.4957e+00,  4.8534e-02,\n",
      "         1.7878e-01, -3.2488e+00,  4.4736e+00,  1.3744e+01, -1.9524e+00,\n",
      "        -5.6119e-01,  1.8394e+01,  3.4713e+01,  2.0028e+01,  3.4132e+01,\n",
      "         6.6787e+00,  1.4798e+01,  2.7105e+01,  2.6404e+01,  1.0109e+01,\n",
      "        -3.0069e-01,  2.5454e+01, -2.9026e+00, -8.2168e-01,  3.2926e+00,\n",
      "         6.4182e+00,  3.8639e+00,  1.1965e+01,  3.2156e+00, -1.2094e+00,\n",
      "        -2.2068e+00, -2.4673e+00, -2.6006e+00,  9.5087e+00, -6.0271e-01,\n",
      "         1.0145e+01,  5.6428e+00, -4.8118e+00,  7.2412e+00,  3.0903e-01,\n",
      "        -3.6396e+00,  5.5956e+00,  3.2596e+01, -3.7698e+00, -5.5816e-01,\n",
      "        -1.3396e+00, -3.2519e+00, -3.4524e-01,  4.2961e+00,  2.2589e+01,\n",
      "         1.4748e+01, -2.2068e+00, -2.1211e+00, -2.9883e+00, -2.7339e+00,\n",
      "         9.1572e-01, -3.2488e+00, -1.7304e+00, -2.7278e+00, -4.4211e+00,\n",
      "         5.6428e+00,  3.9805e-03, -2.9883e+00, -2.6452e+00,  3.8106e+00,\n",
      "         1.6142e+01,  4.9028e+00,  3.5376e+01,  8.4607e+00]) Cost: 196.154114\n",
      "Epochs 4900/10000 hypothesis: tensor([ 3.0614e+01,  5.2080e+00,  4.9003e+01,  4.9275e+01,  1.4361e+01,\n",
      "         4.9687e+01,  6.0054e+01,  5.8557e+00,  4.3621e+01,  3.9691e+01,\n",
      "         3.5599e+01,  4.7444e+01,  1.6497e+01,  1.6353e+01,  4.9308e+01,\n",
      "         2.7120e+01,  2.7154e+01,  5.0956e+01,  1.4714e+01,  5.7970e+01,\n",
      "         4.5535e+01,  3.7004e+01,  3.6941e+01,  2.7483e+01,  3.8733e+01,\n",
      "         3.5147e+01, -2.7721e+00,  1.2597e+00, -5.0727e+00, -4.4199e+00,\n",
      "        -5.0727e+00, -4.7150e-01, -5.4643e+00, -1.7328e+00, -4.8115e+00,\n",
      "        -4.6862e+00, -1.9887e+00,  5.3858e+00, -1.6465e+00, -5.5949e+00,\n",
      "        -3.5112e+00, -4.5504e+00, -6.2477e+00,  3.6074e+00,  4.4195e+01,\n",
      "         3.4821e+01,  3.2024e+01,  5.2982e+01,  2.0788e+01,  3.1220e+01,\n",
      "         3.1068e+01,  1.4275e+01,  4.3900e+01,  3.9633e+01, -4.6810e+00,\n",
      "         4.2551e+00, -8.6317e-01, -4.2893e+00, -4.6810e+00, -3.1637e+00,\n",
      "        -5.5949e+00,  3.5211e+00, -7.9827e-02, -2.7721e+00, -2.8635e+00,\n",
      "        -1.5159e+00, -4.5504e+00, -5.8560e+00, -4.6862e+00,  1.7855e+01,\n",
      "         1.0016e+01,  1.6985e+00,  3.1243e+00,  7.4931e+00,  5.0730e-02,\n",
      "         1.8129e-01, -3.2449e+00,  4.4719e+00,  1.3742e+01, -1.9496e+00,\n",
      "        -5.5779e-01,  1.8390e+01,  3.4708e+01,  2.0025e+01,  3.4126e+01,\n",
      "         6.6759e+00,  1.4795e+01,  2.7099e+01,  2.6399e+01,  1.0107e+01,\n",
      "        -2.9668e-01,  2.5446e+01, -2.9026e+00, -8.1890e-01,  3.2940e+00,\n",
      "         6.4147e+00,  3.8634e+00,  1.1964e+01,  3.2158e+00, -1.2054e+00,\n",
      "        -2.2004e+00, -2.4615e+00, -2.5973e+00,  9.5142e+00, -6.0205e-01,\n",
      "         1.0141e+01,  5.6417e+00, -4.8115e+00,  7.2423e+00,  3.1184e-01,\n",
      "        -3.6365e+00,  5.5997e+00,  3.2591e+01, -3.7671e+00, -5.5262e-01,\n",
      "        -1.3360e+00, -3.2500e+00, -3.4611e-01,  4.2993e+00,  2.2587e+01,\n",
      "         1.4747e+01, -2.2004e+00, -2.1193e+00, -2.9838e+00, -2.7330e+00,\n",
      "         9.1519e-01, -3.2449e+00, -1.7276e+00, -2.7226e+00, -4.4199e+00,\n",
      "         5.6417e+00,  1.2953e-03, -2.9838e+00, -2.6467e+00,  3.8110e+00,\n",
      "         1.6144e+01,  4.9027e+00,  3.5369e+01,  8.4594e+00]) Cost: 196.136688\n",
      "Epochs 5000/10000 hypothesis: tensor([ 3.0612e+01,  5.2113e+00,  4.9000e+01,  4.9276e+01,  1.4362e+01,\n",
      "         4.9690e+01,  6.0058e+01,  5.8583e+00,  4.3622e+01,  3.9693e+01,\n",
      "         3.5603e+01,  4.7447e+01,  1.6500e+01,  1.6357e+01,  4.9309e+01,\n",
      "         2.7122e+01,  2.7155e+01,  5.0956e+01,  1.4715e+01,  5.7971e+01,\n",
      "         4.5538e+01,  3.7007e+01,  3.6941e+01,  2.7481e+01,  3.8730e+01,\n",
      "         3.5150e+01, -2.7718e+00,  1.2631e+00, -5.0730e+00, -4.4187e+00,\n",
      "        -5.0730e+00, -4.7056e-01, -5.4656e+00, -1.7322e+00, -4.8113e+00,\n",
      "        -4.6878e+00, -1.9866e+00,  5.3862e+00, -1.6483e+00, -5.5965e+00,\n",
      "        -3.5100e+00, -4.5496e+00, -6.2508e+00,  3.6085e+00,  4.4197e+01,\n",
      "         3.4825e+01,  3.2023e+01,  5.2983e+01,  2.0786e+01,  3.1222e+01,\n",
      "         3.1071e+01,  1.4278e+01,  4.3903e+01,  3.9635e+01, -4.6804e+00,\n",
      "         4.2555e+00, -8.6316e-01, -4.2879e+00, -4.6804e+00, -3.1644e+00,\n",
      "        -5.5965e+00,  3.5246e+00, -7.7969e-02, -2.7718e+00, -2.8629e+00,\n",
      "        -1.5175e+00, -4.5496e+00, -5.8582e+00, -4.6878e+00,  1.7851e+01,\n",
      "         1.0014e+01,  1.6998e+00,  3.1247e+00,  7.4906e+00,  5.2896e-02,\n",
      "         1.8376e-01, -3.2409e+00,  4.4702e+00,  1.3740e+01, -1.9469e+00,\n",
      "        -5.5441e-01,  1.8387e+01,  3.4704e+01,  2.0022e+01,  3.4120e+01,\n",
      "         6.6730e+00,  1.4791e+01,  2.7093e+01,  2.6395e+01,  1.0105e+01,\n",
      "        -2.9268e-01,  2.5439e+01, -2.9027e+00, -8.1614e-01,  3.2953e+00,\n",
      "         6.4113e+00,  3.8629e+00,  1.1962e+01,  3.2159e+00, -1.2014e+00,\n",
      "        -2.1940e+00, -2.4558e+00, -2.5939e+00,  9.5196e+00, -6.0143e-01,\n",
      "         1.0137e+01,  5.6407e+00, -4.8113e+00,  7.2435e+00,  3.1463e-01,\n",
      "        -3.6335e+00,  5.6038e+00,  3.2585e+01, -3.7644e+00, -5.4710e-01,\n",
      "        -1.3323e+00, -3.2482e+00, -3.4700e-01,  4.3025e+00,  2.2585e+01,\n",
      "         1.4747e+01, -2.1940e+00, -2.1175e+00, -2.9792e+00, -2.7321e+00,\n",
      "         9.1463e-01, -3.2409e+00, -1.7249e+00, -2.7175e+00, -4.4187e+00,\n",
      "         5.6407e+00, -1.4274e-03, -2.9792e+00, -2.6482e+00,  3.8115e+00,\n",
      "         1.6147e+01,  4.9025e+00,  3.5363e+01,  8.4581e+00]) Cost: 196.119308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 5100/10000 hypothesis: tensor([ 3.0610e+01,  5.2145e+00,  4.8997e+01,  4.9278e+01,  1.4363e+01,\n",
      "         4.9692e+01,  6.0061e+01,  5.8609e+00,  4.3624e+01,  3.9696e+01,\n",
      "         3.5606e+01,  4.7450e+01,  1.6503e+01,  1.6361e+01,  4.9309e+01,\n",
      "         2.7125e+01,  2.7156e+01,  5.0955e+01,  1.4716e+01,  5.7972e+01,\n",
      "         4.5542e+01,  3.7010e+01,  3.6940e+01,  2.7480e+01,  3.8728e+01,\n",
      "         3.5152e+01, -2.7715e+00,  1.2666e+00, -5.0734e+00, -4.4175e+00,\n",
      "        -5.0734e+00, -4.6961e-01, -5.4669e+00, -1.7315e+00, -4.8110e+00,\n",
      "        -4.6893e+00, -1.9845e+00,  5.3867e+00, -1.6502e+00, -5.5981e+00,\n",
      "        -3.5088e+00, -4.5487e+00, -6.2539e+00,  3.6095e+00,  4.4199e+01,\n",
      "         3.4829e+01,  3.2023e+01,  5.2984e+01,  2.0785e+01,  3.1225e+01,\n",
      "         3.1073e+01,  1.4281e+01,  4.3906e+01,  3.9636e+01, -4.6799e+00,\n",
      "         4.2559e+00, -8.6312e-01, -4.2864e+00, -4.6799e+00, -3.1650e+00,\n",
      "        -5.5981e+00,  3.5281e+00, -7.6093e-02, -2.7715e+00, -2.8623e+00,\n",
      "        -1.5190e+00, -4.5487e+00, -5.8604e+00, -4.6893e+00,  1.7848e+01,\n",
      "         1.0012e+01,  1.7011e+00,  3.1251e+00,  7.4881e+00,  5.5079e-02,\n",
      "         1.8625e-01, -3.2370e+00,  4.4685e+00,  1.3738e+01, -1.9441e+00,\n",
      "        -5.5100e-01,  1.8383e+01,  3.4700e+01,  2.0019e+01,  3.4115e+01,\n",
      "         6.6701e+00,  1.4788e+01,  2.7087e+01,  2.6390e+01,  1.0103e+01,\n",
      "        -2.8866e-01,  2.5432e+01, -2.9027e+00, -8.1335e-01,  3.2967e+00,\n",
      "         6.4078e+00,  3.8624e+00,  1.1961e+01,  3.2160e+00, -1.1974e+00,\n",
      "        -2.1876e+00, -2.4500e+00, -2.5905e+00,  9.5250e+00, -6.0078e-01,\n",
      "         1.0134e+01,  5.6396e+00, -4.8110e+00,  7.2446e+00,  3.1742e-01,\n",
      "        -3.6305e+00,  5.6080e+00,  3.2580e+01, -3.7617e+00, -5.4158e-01,\n",
      "        -1.3286e+00, -3.2464e+00, -3.4786e-01,  4.3057e+00,  2.2583e+01,\n",
      "         1.4747e+01, -2.1876e+00, -2.1156e+00, -2.9746e+00, -2.7311e+00,\n",
      "         9.1408e-01, -3.2370e+00, -1.7221e+00, -2.7123e+00, -4.4175e+00,\n",
      "         5.6396e+00, -4.1208e-03, -2.9746e+00, -2.6497e+00,  3.8119e+00,\n",
      "         1.6149e+01,  4.9024e+00,  3.5357e+01,  8.4568e+00]) Cost: 196.101974\n",
      "Epochs 5200/10000 hypothesis: tensor([ 3.0608e+01,  5.2177e+00,  4.8993e+01,  4.9280e+01,  1.4364e+01,\n",
      "         4.9695e+01,  6.0065e+01,  5.8635e+00,  4.3626e+01,  3.9698e+01,\n",
      "         3.5610e+01,  4.7453e+01,  1.6505e+01,  1.6365e+01,  4.9309e+01,\n",
      "         2.7127e+01,  2.7157e+01,  5.0954e+01,  1.4717e+01,  5.7973e+01,\n",
      "         4.5545e+01,  3.7013e+01,  3.6940e+01,  2.7478e+01,  3.8725e+01,\n",
      "         3.5154e+01, -2.7712e+00,  1.2700e+00, -5.0737e+00, -4.4163e+00,\n",
      "        -5.0737e+00, -4.6867e-01, -5.4682e+00, -1.7309e+00, -4.8108e+00,\n",
      "        -4.6908e+00, -1.9823e+00,  5.3871e+00, -1.6520e+00, -5.5997e+00,\n",
      "        -3.5075e+00, -4.5478e+00, -6.2570e+00,  3.6105e+00,  4.4201e+01,\n",
      "         3.4833e+01,  3.2022e+01,  5.2985e+01,  2.0783e+01,  3.1227e+01,\n",
      "         3.1075e+01,  1.4285e+01,  4.3909e+01,  3.9637e+01, -4.6793e+00,\n",
      "         4.2563e+00, -8.6310e-01, -4.2849e+00, -4.6793e+00, -3.1656e+00,\n",
      "        -5.5997e+00,  3.5316e+00, -7.4230e-02, -2.7712e+00, -2.8617e+00,\n",
      "        -1.5205e+00, -4.5478e+00, -5.8626e+00, -4.6908e+00,  1.7844e+01,\n",
      "         1.0010e+01,  1.7024e+00,  3.1256e+00,  7.4856e+00,  5.7249e-02,\n",
      "         1.8873e-01, -3.2330e+00,  4.4668e+00,  1.3736e+01, -1.9413e+00,\n",
      "        -5.4761e-01,  1.8379e+01,  3.4696e+01,  2.0015e+01,  3.4109e+01,\n",
      "         6.6673e+00,  1.4785e+01,  2.7081e+01,  2.6386e+01,  1.0101e+01,\n",
      "        -2.8465e-01,  2.5424e+01, -2.9027e+00, -8.1057e-01,  3.2980e+00,\n",
      "         6.4043e+00,  3.8619e+00,  1.1959e+01,  3.2161e+00, -1.1935e+00,\n",
      "        -2.1812e+00, -2.4442e+00, -2.5872e+00,  9.5304e+00, -6.0014e-01,\n",
      "         1.0130e+01,  5.6385e+00, -4.8108e+00,  7.2457e+00,  3.2021e-01,\n",
      "        -3.6275e+00,  5.6121e+00,  3.2575e+01, -3.7590e+00, -5.3607e-01,\n",
      "        -1.3249e+00, -3.2446e+00, -3.4873e-01,  4.3089e+00,  2.2581e+01,\n",
      "         1.4747e+01, -2.1812e+00, -2.1138e+00, -2.9701e+00, -2.7302e+00,\n",
      "         9.1352e-01, -3.2330e+00, -1.7194e+00, -2.7071e+00, -4.4163e+00,\n",
      "         5.6385e+00, -6.8285e-03, -2.9701e+00, -2.6513e+00,  3.8124e+00,\n",
      "         1.6152e+01,  4.9022e+00,  3.5351e+01,  8.4554e+00]) Cost: 196.084641\n",
      "Epochs 5300/10000 hypothesis: tensor([ 3.0606e+01,  5.2209e+00,  4.8990e+01,  4.9281e+01,  1.4365e+01,\n",
      "         4.9698e+01,  6.0069e+01,  5.8662e+00,  4.3627e+01,  3.9700e+01,\n",
      "         3.5614e+01,  4.7457e+01,  1.6508e+01,  1.6369e+01,  4.9309e+01,\n",
      "         2.7130e+01,  2.7157e+01,  5.0953e+01,  1.4718e+01,  5.7974e+01,\n",
      "         4.5549e+01,  3.7016e+01,  3.6940e+01,  2.7477e+01,  3.8723e+01,\n",
      "         3.5156e+01, -2.7709e+00,  1.2735e+00, -5.0741e+00, -4.4152e+00,\n",
      "        -5.0741e+00, -4.6775e-01, -5.4695e+00, -1.7303e+00, -4.8105e+00,\n",
      "        -4.6924e+00, -1.9802e+00,  5.3875e+00, -1.6538e+00, -5.6013e+00,\n",
      "        -3.5063e+00, -4.5470e+00, -6.2602e+00,  3.6115e+00,  4.4203e+01,\n",
      "         3.4837e+01,  3.2021e+01,  5.2986e+01,  2.0782e+01,  3.1230e+01,\n",
      "         3.1077e+01,  1.4288e+01,  4.3911e+01,  3.9638e+01, -4.6788e+00,\n",
      "         4.2568e+00, -8.6311e-01, -4.2834e+00, -4.6788e+00, -3.1663e+00,\n",
      "        -5.6013e+00,  3.5350e+00, -7.2393e-02, -2.7709e+00, -2.8611e+00,\n",
      "        -1.5220e+00, -4.5470e+00, -5.8648e+00, -4.6924e+00,  1.7841e+01,\n",
      "         1.0008e+01,  1.7036e+00,  3.1260e+00,  7.4831e+00,  5.9393e-02,\n",
      "         1.9118e-01, -3.2291e+00,  4.4650e+00,  1.3734e+01, -1.9386e+00,\n",
      "        -5.4423e-01,  1.8375e+01,  3.4693e+01,  2.0012e+01,  3.4103e+01,\n",
      "         6.6644e+00,  1.4781e+01,  2.7075e+01,  2.6381e+01,  1.0098e+01,\n",
      "        -2.8066e-01,  2.5417e+01, -2.9027e+00, -8.0780e-01,  3.2994e+00,\n",
      "         6.4008e+00,  3.8614e+00,  1.1958e+01,  3.2161e+00, -1.1895e+00,\n",
      "        -2.1748e+00, -2.4384e+00, -2.5838e+00,  9.5357e+00, -5.9954e-01,\n",
      "         1.0126e+01,  5.6374e+00, -4.8105e+00,  7.2469e+00,  3.2296e-01,\n",
      "        -3.6245e+00,  5.6163e+00,  3.2570e+01, -3.7563e+00, -5.3058e-01,\n",
      "        -1.3213e+00, -3.2428e+00, -3.4962e-01,  4.3121e+00,  2.2579e+01,\n",
      "         1.4746e+01, -2.1748e+00, -2.1120e+00, -2.9655e+00, -2.7293e+00,\n",
      "         9.1293e-01, -3.2291e+00, -1.7166e+00, -2.7020e+00, -4.4152e+00,\n",
      "         5.6374e+00, -9.5685e-03, -2.9655e+00, -2.6528e+00,  3.8129e+00,\n",
      "         1.6154e+01,  4.9020e+00,  3.5345e+01,  8.4541e+00]) Cost: 196.067307\n",
      "Epochs 5400/10000 hypothesis: tensor([ 3.0604e+01,  5.2241e+00,  4.8987e+01,  4.9283e+01,  1.4366e+01,\n",
      "         4.9700e+01,  6.0073e+01,  5.8688e+00,  4.3629e+01,  3.9703e+01,\n",
      "         3.5618e+01,  4.7460e+01,  1.6511e+01,  1.6374e+01,  4.9309e+01,\n",
      "         2.7132e+01,  2.7158e+01,  5.0953e+01,  1.4720e+01,  5.7975e+01,\n",
      "         4.5552e+01,  3.7018e+01,  3.6939e+01,  2.7476e+01,  3.8720e+01,\n",
      "         3.5158e+01, -2.7707e+00,  1.2769e+00, -5.0745e+00, -4.4140e+00,\n",
      "        -5.0745e+00, -4.6684e-01, -5.4708e+00, -1.7297e+00, -4.8103e+00,\n",
      "        -4.6940e+00, -1.9781e+00,  5.3879e+00, -1.6557e+00, -5.6029e+00,\n",
      "        -3.5052e+00, -4.5461e+00, -6.2633e+00,  3.6125e+00,  4.4205e+01,\n",
      "         3.4842e+01,  3.2020e+01,  5.2987e+01,  2.0780e+01,  3.1233e+01,\n",
      "         3.1079e+01,  1.4292e+01,  4.3914e+01,  3.9640e+01, -4.6782e+00,\n",
      "         4.2572e+00, -8.6312e-01, -4.2819e+00, -4.6782e+00, -3.1669e+00,\n",
      "        -5.6029e+00,  3.5384e+00, -7.0558e-02, -2.7707e+00, -2.8605e+00,\n",
      "        -1.5236e+00, -4.5461e+00, -5.8671e+00, -4.6940e+00,  1.7838e+01,\n",
      "         1.0006e+01,  1.7049e+00,  3.1264e+00,  7.4807e+00,  6.1534e-02,\n",
      "         1.9363e-01, -3.2252e+00,  4.4633e+00,  1.3732e+01, -1.9358e+00,\n",
      "        -5.4085e-01,  1.8371e+01,  3.4689e+01,  2.0009e+01,  3.4097e+01,\n",
      "         6.6615e+00,  1.4778e+01,  2.7069e+01,  2.6377e+01,  1.0096e+01,\n",
      "        -2.7667e-01,  2.5410e+01, -2.9028e+00, -8.0504e-01,  3.3008e+00,\n",
      "         6.3974e+00,  3.8609e+00,  1.1956e+01,  3.2162e+00, -1.1856e+00,\n",
      "        -2.1685e+00, -2.4326e+00, -2.5805e+00,  9.5410e+00, -5.9893e-01,\n",
      "         1.0123e+01,  5.6363e+00, -4.8103e+00,  7.2480e+00,  3.2572e-01,\n",
      "        -3.6215e+00,  5.6204e+00,  3.2564e+01, -3.7536e+00, -5.2509e-01,\n",
      "        -1.3176e+00, -3.2410e+00, -3.5051e-01,  4.3152e+00,  2.2577e+01,\n",
      "         1.4746e+01, -2.1685e+00, -2.1102e+00, -2.9610e+00, -2.7284e+00,\n",
      "         9.1234e-01, -3.2252e+00, -1.7139e+00, -2.6968e+00, -4.4140e+00,\n",
      "         5.6363e+00, -1.2306e-02, -2.9610e+00, -2.6543e+00,  3.8134e+00,\n",
      "         1.6157e+01,  4.9019e+00,  3.5339e+01,  8.4528e+00]) Cost: 196.050079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 5500/10000 hypothesis: tensor([ 3.0602e+01,  5.2273e+00,  4.8984e+01,  4.9284e+01,  1.4367e+01,\n",
      "         4.9703e+01,  6.0077e+01,  5.8715e+00,  4.3631e+01,  3.9705e+01,\n",
      "         3.5622e+01,  4.7463e+01,  1.6513e+01,  1.6378e+01,  4.9310e+01,\n",
      "         2.7134e+01,  2.7159e+01,  5.0952e+01,  1.4721e+01,  5.7976e+01,\n",
      "         4.5556e+01,  3.7021e+01,  3.6939e+01,  2.7474e+01,  3.8717e+01,\n",
      "         3.5160e+01, -2.7704e+00,  1.2804e+00, -5.0749e+00, -4.4129e+00,\n",
      "        -5.0749e+00, -4.6591e-01, -5.4720e+00, -1.7291e+00, -4.8101e+00,\n",
      "        -4.6955e+00, -1.9760e+00,  5.3883e+00, -1.6575e+00, -5.6044e+00,\n",
      "        -3.5039e+00, -4.5453e+00, -6.2664e+00,  3.6134e+00,  4.4207e+01,\n",
      "         3.4846e+01,  3.2019e+01,  5.2988e+01,  2.0779e+01,  3.1235e+01,\n",
      "         3.1081e+01,  1.4295e+01,  4.3917e+01,  3.9641e+01, -4.6777e+00,\n",
      "         4.2576e+00, -8.6310e-01, -4.2805e+00, -4.6777e+00, -3.1676e+00,\n",
      "        -5.6044e+00,  3.5419e+00, -6.8711e-02, -2.7704e+00, -2.8598e+00,\n",
      "        -1.5251e+00, -4.5453e+00, -5.8692e+00, -4.6955e+00,  1.7834e+01,\n",
      "         1.0004e+01,  1.7062e+00,  3.1268e+00,  7.4782e+00,  6.3688e-02,\n",
      "         1.9609e-01, -3.2213e+00,  4.4615e+00,  1.3730e+01, -1.9330e+00,\n",
      "        -5.3747e-01,  1.8367e+01,  3.4685e+01,  2.0006e+01,  3.4091e+01,\n",
      "         6.6587e+00,  1.4774e+01,  2.7063e+01,  2.6372e+01,  1.0094e+01,\n",
      "        -2.7267e-01,  2.5402e+01, -2.9028e+00, -8.0226e-01,  3.3022e+00,\n",
      "         6.3939e+00,  3.8604e+00,  1.1955e+01,  3.2162e+00, -1.1816e+00,\n",
      "        -2.1621e+00, -2.4269e+00, -2.5771e+00,  9.5464e+00, -5.9831e-01,\n",
      "         1.0119e+01,  5.6352e+00, -4.8101e+00,  7.2491e+00,  3.2849e-01,\n",
      "        -3.6185e+00,  5.6245e+00,  3.2559e+01, -3.7509e+00, -5.1960e-01,\n",
      "        -1.3140e+00, -3.2391e+00, -3.5138e-01,  4.3184e+00,  2.2575e+01,\n",
      "         1.4746e+01, -2.1621e+00, -2.1084e+00, -2.9565e+00, -2.7274e+00,\n",
      "         9.1177e-01, -3.2213e+00, -1.7112e+00, -2.6917e+00, -4.4129e+00,\n",
      "         5.6352e+00, -1.5022e-02, -2.9565e+00, -2.6558e+00,  3.8139e+00,\n",
      "         1.6159e+01,  4.9017e+00,  3.5332e+01,  8.4514e+00]) Cost: 196.032822\n",
      "Epochs 5600/10000 hypothesis: tensor([ 3.0600e+01,  5.2305e+00,  4.8981e+01,  4.9286e+01,  1.4367e+01,\n",
      "         4.9706e+01,  6.0081e+01,  5.8741e+00,  4.3632e+01,  3.9707e+01,\n",
      "         3.5626e+01,  4.7466e+01,  1.6516e+01,  1.6382e+01,  4.9310e+01,\n",
      "         2.7136e+01,  2.7160e+01,  5.0951e+01,  1.4722e+01,  5.7977e+01,\n",
      "         4.5559e+01,  3.7024e+01,  3.6939e+01,  2.7473e+01,  3.8715e+01,\n",
      "         3.5163e+01, -2.7701e+00,  1.2839e+00, -5.0752e+00, -4.4117e+00,\n",
      "        -5.0752e+00, -4.6498e-01, -5.4733e+00, -1.7284e+00, -4.8098e+00,\n",
      "        -4.6970e+00, -1.9739e+00,  5.3887e+00, -1.6593e+00, -5.6060e+00,\n",
      "        -3.5027e+00, -4.5444e+00, -6.2695e+00,  3.6144e+00,  4.4209e+01,\n",
      "         3.4850e+01,  3.2018e+01,  5.2989e+01,  2.0777e+01,  3.1238e+01,\n",
      "         3.1083e+01,  1.4298e+01,  4.3919e+01,  3.9642e+01, -4.6771e+00,\n",
      "         4.2580e+00, -8.6309e-01, -4.2790e+00, -4.6771e+00, -3.1682e+00,\n",
      "        -5.6060e+00,  3.5453e+00, -6.6864e-02, -2.7701e+00, -2.8592e+00,\n",
      "        -1.5266e+00, -4.5444e+00, -5.8714e+00, -4.6970e+00,  1.7831e+01,\n",
      "         1.0003e+01,  1.7074e+00,  3.1272e+00,  7.4758e+00,  6.5841e-02,\n",
      "         1.9855e-01, -3.2173e+00,  4.4598e+00,  1.3728e+01, -1.9302e+00,\n",
      "        -5.3408e-01,  1.8363e+01,  3.4681e+01,  2.0003e+01,  3.4085e+01,\n",
      "         6.6559e+00,  1.4771e+01,  2.7057e+01,  2.6368e+01,  1.0092e+01,\n",
      "        -2.6867e-01,  2.5395e+01, -2.9028e+00, -7.9949e-01,  3.3036e+00,\n",
      "         6.3904e+00,  3.8599e+00,  1.1953e+01,  3.2163e+00, -1.1776e+00,\n",
      "        -2.1557e+00, -2.4211e+00, -2.5738e+00,  9.5517e+00, -5.9768e-01,\n",
      "         1.0115e+01,  5.6342e+00, -4.8098e+00,  7.2503e+00,  3.3125e-01,\n",
      "        -3.6154e+00,  5.6287e+00,  3.2554e+01, -3.7481e+00, -5.1411e-01,\n",
      "        -1.3103e+00, -3.2373e+00, -3.5224e-01,  4.3216e+00,  2.2574e+01,\n",
      "         1.4746e+01, -2.1557e+00, -2.1066e+00, -2.9519e+00, -2.7264e+00,\n",
      "         9.1120e-01, -3.2173e+00, -1.7084e+00, -2.6865e+00, -4.4117e+00,\n",
      "         5.6342e+00, -1.7733e-02, -2.9519e+00, -2.6573e+00,  3.8144e+00,\n",
      "         1.6162e+01,  4.9015e+00,  3.5326e+01,  8.4501e+00]) Cost: 196.015640\n",
      "Epochs 5700/10000 hypothesis: tensor([ 3.0598e+01,  5.2338e+00,  4.8977e+01,  4.9288e+01,  1.4368e+01,\n",
      "         4.9709e+01,  6.0085e+01,  5.8767e+00,  4.3634e+01,  3.9710e+01,\n",
      "         3.5630e+01,  4.7469e+01,  1.6519e+01,  1.6386e+01,  4.9310e+01,\n",
      "         2.7139e+01,  2.7161e+01,  5.0950e+01,  1.4723e+01,  5.7979e+01,\n",
      "         4.5563e+01,  3.7027e+01,  3.6938e+01,  2.7471e+01,  3.8712e+01,\n",
      "         3.5165e+01, -2.7698e+00,  1.2873e+00, -5.0755e+00, -4.4105e+00,\n",
      "        -5.0755e+00, -4.6405e-01, -5.4746e+00, -1.7278e+00, -4.8095e+00,\n",
      "        -4.6986e+00, -1.9717e+00,  5.3891e+00, -1.6611e+00, -5.6076e+00,\n",
      "        -3.5015e+00, -4.5435e+00, -6.2726e+00,  3.6154e+00,  4.4210e+01,\n",
      "         3.4854e+01,  3.2016e+01,  5.2990e+01,  2.0776e+01,  3.1240e+01,\n",
      "         3.1085e+01,  1.4302e+01,  4.3922e+01,  3.9643e+01, -4.6765e+00,\n",
      "         4.2584e+00, -8.6308e-01, -4.2775e+00, -4.6765e+00, -3.1688e+00,\n",
      "        -5.6076e+00,  3.5488e+00, -6.5019e-02, -2.7698e+00, -2.8585e+00,\n",
      "        -1.5281e+00, -4.5435e+00, -5.8736e+00, -4.6986e+00,  1.7827e+01,\n",
      "         1.0001e+01,  1.7087e+00,  3.1277e+00,  7.4733e+00,  6.7991e-02,\n",
      "         2.0100e-01, -3.2134e+00,  4.4580e+00,  1.3726e+01, -1.9274e+00,\n",
      "        -5.3069e-01,  1.8359e+01,  3.4677e+01,  2.0000e+01,  3.4079e+01,\n",
      "         6.6530e+00,  1.4768e+01,  2.7050e+01,  2.6363e+01,  1.0089e+01,\n",
      "        -2.6467e-01,  2.5388e+01, -2.9028e+00, -7.9671e-01,  3.3050e+00,\n",
      "         6.3870e+00,  3.8594e+00,  1.1952e+01,  3.2164e+00, -1.1737e+00,\n",
      "        -2.1493e+00, -2.4153e+00, -2.5704e+00,  9.5570e+00, -5.9706e-01,\n",
      "         1.0112e+01,  5.6331e+00, -4.8095e+00,  7.2514e+00,  3.3401e-01,\n",
      "        -3.6124e+00,  5.6328e+00,  3.2549e+01, -3.7454e+00, -5.0862e-01,\n",
      "        -1.3067e+00, -3.2355e+00, -3.5310e-01,  4.3248e+00,  2.2572e+01,\n",
      "         1.4745e+01, -2.1493e+00, -2.1047e+00, -2.9474e+00, -2.7255e+00,\n",
      "         9.1063e-01, -3.2134e+00, -1.7057e+00, -2.6814e+00, -4.4105e+00,\n",
      "         5.6331e+00, -2.0443e-02, -2.9474e+00, -2.6589e+00,  3.8150e+00,\n",
      "         1.6164e+01,  4.9014e+00,  3.5320e+01,  8.4488e+00]) Cost: 195.998459\n",
      "Epochs 5800/10000 hypothesis: tensor([ 3.0596e+01,  5.2370e+00,  4.8974e+01,  4.9289e+01,  1.4369e+01,\n",
      "         4.9711e+01,  6.0089e+01,  5.8794e+00,  4.3636e+01,  3.9712e+01,\n",
      "         3.5634e+01,  4.7473e+01,  1.6521e+01,  1.6390e+01,  4.9310e+01,\n",
      "         2.7141e+01,  2.7162e+01,  5.0950e+01,  1.4724e+01,  5.7980e+01,\n",
      "         4.5566e+01,  3.7030e+01,  3.6938e+01,  2.7470e+01,  3.8710e+01,\n",
      "         3.5167e+01, -2.7695e+00,  1.2908e+00, -5.0759e+00, -4.4093e+00,\n",
      "        -5.0759e+00, -4.6314e-01, -5.4758e+00, -1.7271e+00, -4.8093e+00,\n",
      "        -4.7001e+00, -1.9696e+00,  5.3895e+00, -1.6630e+00, -5.6092e+00,\n",
      "        -3.5003e+00, -4.5426e+00, -6.2757e+00,  3.6164e+00,  4.4212e+01,\n",
      "         3.4858e+01,  3.2015e+01,  5.2991e+01,  2.0774e+01,  3.1243e+01,\n",
      "         3.1087e+01,  1.4305e+01,  4.3925e+01,  3.9644e+01, -4.6759e+00,\n",
      "         4.2588e+00, -8.6308e-01, -4.2760e+00, -4.6759e+00, -3.1695e+00,\n",
      "        -5.6092e+00,  3.5522e+00, -6.3189e-02, -2.7695e+00, -2.8578e+00,\n",
      "        -1.5297e+00, -4.5426e+00, -5.8758e+00, -4.7001e+00,  1.7824e+01,\n",
      "         9.9989e+00,  1.7099e+00,  3.1281e+00,  7.4709e+00,  7.0126e-02,\n",
      "         2.0344e-01, -3.2095e+00,  4.4563e+00,  1.3723e+01, -1.9246e+00,\n",
      "        -5.2731e-01,  1.8355e+01,  3.4673e+01,  1.9997e+01,  3.4073e+01,\n",
      "         6.6502e+00,  1.4764e+01,  2.7044e+01,  2.6359e+01,  1.0087e+01,\n",
      "        -2.6068e-01,  2.5380e+01, -2.9028e+00, -7.9394e-01,  3.3064e+00,\n",
      "         6.3835e+00,  3.8588e+00,  1.1950e+01,  3.2164e+00, -1.1697e+00,\n",
      "        -2.1430e+00, -2.4096e+00, -2.5671e+00,  9.5623e+00, -5.9645e-01,\n",
      "         1.0108e+01,  5.6320e+00, -4.8093e+00,  7.2526e+00,  3.3676e-01,\n",
      "        -3.6094e+00,  5.6369e+00,  3.2544e+01, -3.7427e+00, -5.0315e-01,\n",
      "        -1.3030e+00, -3.2336e+00, -3.5397e-01,  4.3279e+00,  2.2570e+01,\n",
      "         1.4745e+01, -2.1430e+00, -2.1029e+00, -2.9428e+00, -2.7245e+00,\n",
      "         9.1004e-01, -3.2095e+00, -1.7030e+00, -2.6762e+00, -4.4093e+00,\n",
      "         5.6320e+00, -2.3171e-02, -2.9428e+00, -2.6604e+00,  3.8155e+00,\n",
      "         1.6166e+01,  4.9012e+00,  3.5314e+01,  8.4474e+00]) Cost: 195.981308\n",
      "Epochs 5900/10000 hypothesis: tensor([ 3.0593e+01,  5.2402e+00,  4.8971e+01,  4.9291e+01,  1.4370e+01,\n",
      "         4.9714e+01,  6.0092e+01,  5.8821e+00,  4.3637e+01,  3.9714e+01,\n",
      "         3.5638e+01,  4.7476e+01,  1.6524e+01,  1.6394e+01,  4.9310e+01,\n",
      "         2.7143e+01,  2.7163e+01,  5.0949e+01,  1.4725e+01,  5.7981e+01,\n",
      "         4.5570e+01,  3.7033e+01,  3.6938e+01,  2.7469e+01,  3.8707e+01,\n",
      "         3.5169e+01, -2.7692e+00,  1.2943e+00, -5.0762e+00, -4.4081e+00,\n",
      "        -5.0762e+00, -4.6223e-01, -5.4771e+00, -1.7265e+00, -4.8090e+00,\n",
      "        -4.7016e+00, -1.9675e+00,  5.3898e+00, -1.6648e+00, -5.6107e+00,\n",
      "        -3.4990e+00, -4.5418e+00, -6.2788e+00,  3.6173e+00,  4.4214e+01,\n",
      "         3.4863e+01,  3.2014e+01,  5.2992e+01,  2.0773e+01,  3.1246e+01,\n",
      "         3.1089e+01,  1.4308e+01,  4.3927e+01,  3.9646e+01, -4.6754e+00,\n",
      "         4.2592e+00, -8.6309e-01, -4.2745e+00, -4.6754e+00, -3.1701e+00,\n",
      "        -5.6107e+00,  3.5556e+00, -6.1367e-02, -2.7692e+00, -2.8572e+00,\n",
      "        -1.5312e+00, -4.5418e+00, -5.8780e+00, -4.7016e+00,  1.7820e+01,\n",
      "         9.9971e+00,  1.7112e+00,  3.1285e+00,  7.4685e+00,  7.2254e-02,\n",
      "         2.0587e-01, -3.2056e+00,  4.4545e+00,  1.3721e+01, -1.9218e+00,\n",
      "        -5.2393e-01,  1.8351e+01,  3.4670e+01,  1.9994e+01,  3.4067e+01,\n",
      "         6.6473e+00,  1.4761e+01,  2.7038e+01,  2.6354e+01,  1.0085e+01,\n",
      "        -2.5669e-01,  2.5373e+01, -2.9029e+00, -7.9117e-01,  3.3078e+00,\n",
      "         6.3801e+00,  3.8583e+00,  1.1949e+01,  3.2164e+00, -1.1658e+00,\n",
      "        -2.1366e+00, -2.4038e+00, -2.5637e+00,  9.5675e+00, -5.9585e-01,\n",
      "         1.0104e+01,  5.6308e+00, -4.8090e+00,  7.2537e+00,  3.3949e-01,\n",
      "        -3.6064e+00,  5.6411e+00,  3.2539e+01, -3.7400e+00, -4.9769e-01,\n",
      "        -1.2994e+00, -3.2318e+00, -3.5484e-01,  4.3311e+00,  2.2568e+01,\n",
      "         1.4745e+01, -2.1366e+00, -2.1011e+00, -2.9383e+00, -2.7236e+00,\n",
      "         9.0944e-01, -3.2056e+00, -1.7003e+00, -2.6711e+00, -4.4081e+00,\n",
      "         5.6308e+00, -2.5903e-02, -2.9383e+00, -2.6619e+00,  3.8161e+00,\n",
      "         1.6169e+01,  4.9010e+00,  3.5308e+01,  8.4461e+00]) Cost: 195.964218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 6000/10000 hypothesis: tensor([ 3.0591e+01,  5.2434e+00,  4.8968e+01,  4.9292e+01,  1.4371e+01,\n",
      "         4.9717e+01,  6.0096e+01,  5.8847e+00,  4.3639e+01,  3.9716e+01,\n",
      "         3.5642e+01,  4.7479e+01,  1.6527e+01,  1.6398e+01,  4.9310e+01,\n",
      "         2.7145e+01,  2.7163e+01,  5.0948e+01,  1.4726e+01,  5.7982e+01,\n",
      "         4.5573e+01,  3.7035e+01,  3.6937e+01,  2.7467e+01,  3.8704e+01,\n",
      "         3.5171e+01, -2.7690e+00,  1.2978e+00, -5.0766e+00, -4.4070e+00,\n",
      "        -5.0766e+00, -4.6132e-01, -5.4784e+00, -1.7259e+00, -4.8087e+00,\n",
      "        -4.7031e+00, -1.9654e+00,  5.3902e+00, -1.6666e+00, -5.6123e+00,\n",
      "        -3.4978e+00, -4.5409e+00, -6.2819e+00,  3.6183e+00,  4.4216e+01,\n",
      "         3.4867e+01,  3.2013e+01,  5.2993e+01,  2.0771e+01,  3.1248e+01,\n",
      "         3.1091e+01,  1.4312e+01,  4.3930e+01,  3.9647e+01, -4.6748e+00,\n",
      "         4.2596e+00, -8.6310e-01, -4.2730e+00, -4.6748e+00, -3.1707e+00,\n",
      "        -5.6123e+00,  3.5590e+00, -5.9546e-02, -2.7690e+00, -2.8565e+00,\n",
      "        -1.5327e+00, -4.5409e+00, -5.8801e+00, -4.7031e+00,  1.7817e+01,\n",
      "         9.9952e+00,  1.7124e+00,  3.1289e+00,  7.4661e+00,  7.4379e-02,\n",
      "         2.0830e-01, -3.2016e+00,  4.4527e+00,  1.3719e+01, -1.9190e+00,\n",
      "        -5.2055e-01,  1.8348e+01,  3.4666e+01,  1.9991e+01,  3.4061e+01,\n",
      "         6.6445e+00,  1.4757e+01,  2.7032e+01,  2.6350e+01,  1.0083e+01,\n",
      "        -2.5270e-01,  2.5366e+01, -2.9029e+00, -7.8840e-01,  3.3092e+00,\n",
      "         6.3766e+00,  3.8578e+00,  1.1947e+01,  3.2165e+00, -1.1619e+00,\n",
      "        -2.1302e+00, -2.3981e+00, -2.5603e+00,  9.5728e+00, -5.9525e-01,\n",
      "         1.0101e+01,  5.6297e+00, -4.8087e+00,  7.2549e+00,  3.4223e-01,\n",
      "        -3.6034e+00,  5.6452e+00,  3.2533e+01, -3.7373e+00, -4.9223e-01,\n",
      "        -1.2958e+00, -3.2300e+00, -3.5571e-01,  4.3343e+00,  2.2566e+01,\n",
      "         1.4744e+01, -2.1302e+00, -2.0993e+00, -2.9338e+00, -2.7226e+00,\n",
      "         9.0884e-01, -3.2016e+00, -1.6976e+00, -2.6659e+00, -4.4070e+00,\n",
      "         5.6297e+00, -2.8635e-02, -2.9338e+00, -2.6633e+00,  3.8166e+00,\n",
      "         1.6171e+01,  4.9009e+00,  3.5302e+01,  8.4447e+00]) Cost: 195.947144\n",
      "Epochs 6100/10000 hypothesis: tensor([ 3.0589e+01,  5.2466e+00,  4.8964e+01,  4.9294e+01,  1.4372e+01,\n",
      "         4.9720e+01,  6.0100e+01,  5.8874e+00,  4.3641e+01,  3.9719e+01,\n",
      "         3.5646e+01,  4.7482e+01,  1.6529e+01,  1.6402e+01,  4.9310e+01,\n",
      "         2.7148e+01,  2.7164e+01,  5.0947e+01,  1.4727e+01,  5.7983e+01,\n",
      "         4.5577e+01,  3.7038e+01,  3.6937e+01,  2.7466e+01,  3.8702e+01,\n",
      "         3.5173e+01, -2.7687e+00,  1.3013e+00, -5.0769e+00, -4.4058e+00,\n",
      "        -5.0769e+00, -4.6042e-01, -5.4796e+00, -1.7252e+00, -4.8085e+00,\n",
      "        -4.7046e+00, -1.9633e+00,  5.3905e+00, -1.6685e+00, -5.6139e+00,\n",
      "        -3.4966e+00, -4.5400e+00, -6.2850e+00,  3.6192e+00,  4.4218e+01,\n",
      "         3.4871e+01,  3.2012e+01,  5.2994e+01,  2.0769e+01,  3.1251e+01,\n",
      "         3.1093e+01,  1.4315e+01,  4.3932e+01,  3.9648e+01, -4.6743e+00,\n",
      "         4.2599e+00, -8.6310e-01, -4.2716e+00, -4.6743e+00, -3.1714e+00,\n",
      "        -5.6139e+00,  3.5624e+00, -5.7727e-02, -2.7687e+00, -2.8558e+00,\n",
      "        -1.5343e+00, -4.5400e+00, -5.8823e+00, -4.7046e+00,  1.7814e+01,\n",
      "         9.9934e+00,  1.7136e+00,  3.1294e+00,  7.4637e+00,  7.6502e-02,\n",
      "         2.1073e-01, -3.1977e+00,  4.4509e+00,  1.3717e+01, -1.9162e+00,\n",
      "        -5.1717e-01,  1.8344e+01,  3.4662e+01,  1.9988e+01,  3.4055e+01,\n",
      "         6.6417e+00,  1.4754e+01,  2.7026e+01,  2.6345e+01,  1.0081e+01,\n",
      "        -2.4871e-01,  2.5358e+01, -2.9029e+00, -7.8563e-01,  3.3107e+00,\n",
      "         6.3732e+00,  3.8573e+00,  1.1946e+01,  3.2165e+00, -1.1579e+00,\n",
      "        -2.1239e+00, -2.3924e+00, -2.5570e+00,  9.5780e+00, -5.9464e-01,\n",
      "         1.0097e+01,  5.6286e+00, -4.8085e+00,  7.2560e+00,  3.4496e-01,\n",
      "        -3.6004e+00,  5.6493e+00,  3.2528e+01, -3.7346e+00, -4.8678e-01,\n",
      "        -1.2922e+00, -3.2281e+00, -3.5658e-01,  4.3374e+00,  2.2564e+01,\n",
      "         1.4744e+01, -2.1239e+00, -2.0975e+00, -2.9293e+00, -2.7216e+00,\n",
      "         9.0824e-01, -3.1977e+00, -1.6948e+00, -2.6608e+00, -4.4058e+00,\n",
      "         5.6286e+00, -3.1363e-02, -2.9293e+00, -2.6648e+00,  3.8172e+00,\n",
      "         1.6174e+01,  4.9007e+00,  3.5296e+01,  8.4434e+00]) Cost: 195.930099\n",
      "Epochs 6200/10000 hypothesis: tensor([ 3.0587e+01,  5.2498e+00,  4.8961e+01,  4.9295e+01,  1.4373e+01,\n",
      "         4.9723e+01,  6.0104e+01,  5.8900e+00,  4.3642e+01,  3.9721e+01,\n",
      "         3.5650e+01,  4.7485e+01,  1.6532e+01,  1.6406e+01,  4.9310e+01,\n",
      "         2.7150e+01,  2.7165e+01,  5.0947e+01,  1.4729e+01,  5.7984e+01,\n",
      "         4.5580e+01,  3.7041e+01,  3.6937e+01,  2.7465e+01,  3.8699e+01,\n",
      "         3.5175e+01, -2.7684e+00,  1.3047e+00, -5.0773e+00, -4.4046e+00,\n",
      "        -5.0773e+00, -4.5951e-01, -5.4809e+00, -1.7246e+00, -4.8082e+00,\n",
      "        -4.7062e+00, -1.9612e+00,  5.3909e+00, -1.6703e+00, -5.6154e+00,\n",
      "        -3.4954e+00, -4.5392e+00, -6.2881e+00,  3.6201e+00,  4.4219e+01,\n",
      "         3.4875e+01,  3.2011e+01,  5.2995e+01,  2.0768e+01,  3.1254e+01,\n",
      "         3.1095e+01,  1.4318e+01,  4.3935e+01,  3.9649e+01, -4.6737e+00,\n",
      "         4.2603e+00, -8.6311e-01, -4.2701e+00, -4.6737e+00, -3.1720e+00,\n",
      "        -5.6154e+00,  3.5658e+00, -5.5912e-02, -2.7684e+00, -2.8552e+00,\n",
      "        -1.5358e+00, -4.5392e+00, -5.8845e+00, -4.7062e+00,  1.7810e+01,\n",
      "         9.9915e+00,  1.7148e+00,  3.1298e+00,  7.4613e+00,  7.8622e-02,\n",
      "         2.1316e-01, -3.1938e+00,  4.4492e+00,  1.3715e+01, -1.9134e+00,\n",
      "        -5.1380e-01,  1.8340e+01,  3.4659e+01,  1.9985e+01,  3.4049e+01,\n",
      "         6.6388e+00,  1.4750e+01,  2.7020e+01,  2.6341e+01,  1.0078e+01,\n",
      "        -2.4473e-01,  2.5351e+01, -2.9029e+00, -7.8287e-01,  3.3121e+00,\n",
      "         6.3698e+00,  3.8567e+00,  1.1945e+01,  3.2165e+00, -1.1540e+00,\n",
      "        -2.1176e+00, -2.3866e+00, -2.5536e+00,  9.5833e+00, -5.9405e-01,\n",
      "         1.0094e+01,  5.6275e+00, -4.8082e+00,  7.2572e+00,  3.4769e-01,\n",
      "        -3.5974e+00,  5.6534e+00,  3.2523e+01, -3.7320e+00, -4.8133e-01,\n",
      "        -1.2885e+00, -3.2263e+00, -3.5745e-01,  4.3406e+00,  2.2563e+01,\n",
      "         1.4744e+01, -2.1176e+00, -2.0957e+00, -2.9248e+00, -2.7206e+00,\n",
      "         9.0764e-01, -3.1938e+00, -1.6921e+00, -2.6557e+00, -4.4046e+00,\n",
      "         5.6275e+00, -3.4092e-02, -2.9248e+00, -2.6663e+00,  3.8177e+00,\n",
      "         1.6176e+01,  4.9005e+00,  3.5290e+01,  8.4420e+00]) Cost: 195.913055\n",
      "Epochs 6300/10000 hypothesis: tensor([ 3.0585e+01,  5.2531e+00,  4.8958e+01,  4.9297e+01,  1.4374e+01,\n",
      "         4.9726e+01,  6.0108e+01,  5.8927e+00,  4.3644e+01,  3.9723e+01,\n",
      "         3.5654e+01,  4.7489e+01,  1.6534e+01,  1.6410e+01,  4.9311e+01,\n",
      "         2.7152e+01,  2.7166e+01,  5.0946e+01,  1.4730e+01,  5.7985e+01,\n",
      "         4.5584e+01,  3.7044e+01,  3.6937e+01,  2.7463e+01,  3.8696e+01,\n",
      "         3.5176e+01, -2.7681e+00,  1.3082e+00, -5.0776e+00, -4.4035e+00,\n",
      "        -5.0776e+00, -4.5861e-01, -5.4822e+00, -1.7240e+00, -4.8080e+00,\n",
      "        -4.7077e+00, -1.9591e+00,  5.3912e+00, -1.6721e+00, -5.6170e+00,\n",
      "        -3.4941e+00, -4.5383e+00, -6.2912e+00,  3.6211e+00,  4.4221e+01,\n",
      "         3.4880e+01,  3.2009e+01,  5.2996e+01,  2.0766e+01,  3.1256e+01,\n",
      "         3.1097e+01,  1.4322e+01,  4.3938e+01,  3.9651e+01, -4.6731e+00,\n",
      "         4.2607e+00, -8.6312e-01, -4.2686e+00, -4.6731e+00, -3.1726e+00,\n",
      "        -5.6170e+00,  3.5693e+00, -5.4099e-02, -2.7681e+00, -2.8545e+00,\n",
      "        -1.5373e+00, -4.5383e+00, -5.8867e+00, -4.7077e+00,  1.7807e+01,\n",
      "         9.9897e+00,  1.7161e+00,  3.1302e+00,  7.4589e+00,  8.0739e-02,\n",
      "         2.1558e-01, -3.1899e+00,  4.4474e+00,  1.3713e+01, -1.9106e+00,\n",
      "        -5.1043e-01,  1.8336e+01,  3.4655e+01,  1.9982e+01,  3.4043e+01,\n",
      "         6.6360e+00,  1.4747e+01,  2.7014e+01,  2.6336e+01,  1.0076e+01,\n",
      "        -2.4076e-01,  2.5344e+01, -2.9030e+00, -7.8011e-01,  3.3135e+00,\n",
      "         6.3663e+00,  3.8562e+00,  1.1943e+01,  3.2166e+00, -1.1501e+00,\n",
      "        -2.1112e+00, -2.3809e+00, -2.5503e+00,  9.5885e+00, -5.9345e-01,\n",
      "         1.0090e+01,  5.6264e+00, -4.8080e+00,  7.2584e+00,  3.5041e-01,\n",
      "        -3.5944e+00,  5.6576e+00,  3.2518e+01, -3.7293e+00, -4.7589e-01,\n",
      "        -1.2849e+00, -3.2245e+00, -3.5832e-01,  4.3437e+00,  2.2561e+01,\n",
      "         1.4744e+01, -2.1112e+00, -2.0939e+00, -2.9202e+00, -2.7197e+00,\n",
      "         9.0704e-01, -3.1899e+00, -1.6894e+00, -2.6506e+00, -4.4035e+00,\n",
      "         5.6264e+00, -3.6819e-02, -2.9202e+00, -2.6678e+00,  3.8183e+00,\n",
      "         1.6178e+01,  4.9004e+00,  3.5284e+01,  8.4407e+00]) Cost: 195.896042\n",
      "Epochs 6400/10000 hypothesis: tensor([ 3.0583e+01,  5.2563e+00,  4.8955e+01,  4.9298e+01,  1.4374e+01,\n",
      "         4.9728e+01,  6.0112e+01,  5.8953e+00,  4.3646e+01,  3.9725e+01,\n",
      "         3.5658e+01,  4.7492e+01,  1.6537e+01,  1.6414e+01,  4.9311e+01,\n",
      "         2.7154e+01,  2.7167e+01,  5.0945e+01,  1.4731e+01,  5.7986e+01,\n",
      "         4.5587e+01,  3.7046e+01,  3.6936e+01,  2.7462e+01,  3.8694e+01,\n",
      "         3.5178e+01, -2.7679e+00,  1.3117e+00, -5.0780e+00, -4.4023e+00,\n",
      "        -5.0780e+00, -4.5771e-01, -5.4834e+00, -1.7233e+00, -4.8077e+00,\n",
      "        -4.7092e+00, -1.9570e+00,  5.3916e+00, -1.6740e+00, -5.6186e+00,\n",
      "        -3.4929e+00, -4.5374e+00, -6.2943e+00,  3.6220e+00,  4.4223e+01,\n",
      "         3.4884e+01,  3.2008e+01,  5.2997e+01,  2.0764e+01,  3.1259e+01,\n",
      "         3.1099e+01,  1.4325e+01,  4.3940e+01,  3.9652e+01, -4.6726e+00,\n",
      "         4.2611e+00, -8.6313e-01, -4.2671e+00, -4.6726e+00, -3.1733e+00,\n",
      "        -5.6186e+00,  3.5727e+00, -5.2286e-02, -2.7679e+00, -2.8538e+00,\n",
      "        -1.5388e+00, -4.5374e+00, -5.8888e+00, -4.7092e+00,  1.7804e+01,\n",
      "         9.9878e+00,  1.7173e+00,  3.1306e+00,  7.4566e+00,  8.2855e-02,\n",
      "         2.1800e-01, -3.1860e+00,  4.4456e+00,  1.3711e+01, -1.9078e+00,\n",
      "        -5.0707e-01,  1.8332e+01,  3.4651e+01,  1.9979e+01,  3.4037e+01,\n",
      "         6.6332e+00,  1.4743e+01,  2.7008e+01,  2.6332e+01,  1.0074e+01,\n",
      "        -2.3679e-01,  2.5337e+01, -2.9030e+00, -7.7735e-01,  3.3149e+00,\n",
      "         6.3629e+00,  3.8557e+00,  1.1942e+01,  3.2166e+00, -1.1462e+00,\n",
      "        -2.1049e+00, -2.3752e+00, -2.5469e+00,  9.5937e+00, -5.9285e-01,\n",
      "         1.0086e+01,  5.6253e+00, -4.8077e+00,  7.2595e+00,  3.5314e-01,\n",
      "        -3.5914e+00,  5.6617e+00,  3.2513e+01, -3.7266e+00, -4.7045e-01,\n",
      "        -1.2813e+00, -3.2226e+00, -3.5918e-01,  4.3469e+00,  2.2559e+01,\n",
      "         1.4743e+01, -2.1049e+00, -2.0921e+00, -2.9157e+00, -2.7187e+00,\n",
      "         9.0644e-01, -3.1860e+00, -1.6867e+00, -2.6455e+00, -4.4023e+00,\n",
      "         5.6253e+00, -3.9543e-02, -2.9157e+00, -2.6693e+00,  3.8189e+00,\n",
      "         1.6181e+01,  4.9002e+00,  3.5278e+01,  8.4393e+00]) Cost: 195.879120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 6500/10000 hypothesis: tensor([ 3.0581e+01,  5.2595e+00,  4.8951e+01,  4.9300e+01,  1.4375e+01,\n",
      "         4.9731e+01,  6.0116e+01,  5.8980e+00,  4.3647e+01,  3.9728e+01,\n",
      "         3.5662e+01,  4.7495e+01,  1.6539e+01,  1.6418e+01,  4.9311e+01,\n",
      "         2.7156e+01,  2.7168e+01,  5.0944e+01,  1.4732e+01,  5.7988e+01,\n",
      "         4.5590e+01,  3.7049e+01,  3.6936e+01,  2.7461e+01,  3.8691e+01,\n",
      "         3.5180e+01, -2.7676e+00,  1.3152e+00, -5.0783e+00, -4.4011e+00,\n",
      "        -5.0783e+00, -4.5681e-01, -5.4847e+00, -1.7227e+00, -4.8075e+00,\n",
      "        -4.7107e+00, -1.9549e+00,  5.3919e+00, -1.6758e+00, -5.6201e+00,\n",
      "        -3.4917e+00, -4.5366e+00, -6.2973e+00,  3.6229e+00,  4.4225e+01,\n",
      "         3.4888e+01,  3.2007e+01,  5.2998e+01,  2.0763e+01,  3.1261e+01,\n",
      "         3.1101e+01,  1.4328e+01,  4.3943e+01,  3.9653e+01, -4.6720e+00,\n",
      "         4.2615e+00, -8.6314e-01, -4.2657e+00, -4.6720e+00, -3.1739e+00,\n",
      "        -5.6201e+00,  3.5761e+00, -5.0476e-02, -2.7676e+00, -2.8532e+00,\n",
      "        -1.5404e+00, -4.5366e+00, -5.8910e+00, -4.7107e+00,  1.7800e+01,\n",
      "         9.9860e+00,  1.7185e+00,  3.1310e+00,  7.4542e+00,  8.4969e-02,\n",
      "         2.2041e-01, -3.1821e+00,  4.4438e+00,  1.3709e+01, -1.9050e+00,\n",
      "        -5.0370e-01,  1.8328e+01,  3.4648e+01,  1.9976e+01,  3.4031e+01,\n",
      "         6.6303e+00,  1.4740e+01,  2.7002e+01,  2.6327e+01,  1.0072e+01,\n",
      "        -2.3282e-01,  2.5329e+01, -2.9030e+00, -7.7459e-01,  3.3163e+00,\n",
      "         6.3594e+00,  3.8552e+00,  1.1940e+01,  3.2166e+00, -1.1422e+00,\n",
      "        -2.0986e+00, -2.3695e+00, -2.5436e+00,  9.5989e+00, -5.9225e-01,\n",
      "         1.0083e+01,  5.6241e+00, -4.8075e+00,  7.2607e+00,  3.5586e-01,\n",
      "        -3.5885e+00,  5.6658e+00,  3.2508e+01, -3.7239e+00, -4.6502e-01,\n",
      "        -1.2777e+00, -3.2208e+00, -3.6005e-01,  4.3500e+00,  2.2557e+01,\n",
      "         1.4743e+01, -2.0986e+00, -2.0904e+00, -2.9112e+00, -2.7177e+00,\n",
      "         9.0585e-01, -3.1821e+00, -1.6840e+00, -2.6403e+00, -4.4011e+00,\n",
      "         5.6241e+00, -4.2264e-02, -2.9112e+00, -2.6708e+00,  3.8194e+00,\n",
      "         1.6183e+01,  4.9000e+00,  3.5272e+01,  8.4380e+00]) Cost: 195.862213\n",
      "Epochs 6600/10000 hypothesis: tensor([ 3.0579e+01,  5.2627e+00,  4.8948e+01,  4.9301e+01,  1.4376e+01,\n",
      "         4.9734e+01,  6.0120e+01,  5.9007e+00,  4.3649e+01,  3.9730e+01,\n",
      "         3.5666e+01,  4.7498e+01,  1.6542e+01,  1.6422e+01,  4.9311e+01,\n",
      "         2.7159e+01,  2.7168e+01,  5.0944e+01,  1.4733e+01,  5.7989e+01,\n",
      "         4.5594e+01,  3.7052e+01,  3.6936e+01,  2.7459e+01,  3.8688e+01,\n",
      "         3.5182e+01, -2.7673e+00,  1.3186e+00, -5.0787e+00, -4.4000e+00,\n",
      "        -5.0787e+00, -4.5591e-01, -5.4859e+00, -1.7221e+00, -4.8072e+00,\n",
      "        -4.7122e+00, -1.9528e+00,  5.3923e+00, -1.6776e+00, -5.6217e+00,\n",
      "        -3.4905e+00, -4.5357e+00, -6.3004e+00,  3.6239e+00,  4.4227e+01,\n",
      "         3.4892e+01,  3.2006e+01,  5.2999e+01,  2.0761e+01,  3.1264e+01,\n",
      "         3.1103e+01,  1.4332e+01,  4.3945e+01,  3.9654e+01, -4.6715e+00,\n",
      "         4.2619e+00, -8.6315e-01, -4.2642e+00, -4.6715e+00, -3.1745e+00,\n",
      "        -5.6217e+00,  3.5794e+00, -4.8669e-02, -2.7673e+00, -2.8525e+00,\n",
      "        -1.5419e+00, -4.5357e+00, -5.8932e+00, -4.7122e+00,  1.7797e+01,\n",
      "         9.9841e+00,  1.7197e+00,  3.1315e+00,  7.4518e+00,  8.7078e-02,\n",
      "         2.2283e-01, -3.1782e+00,  4.4420e+00,  1.3707e+01, -1.9023e+00,\n",
      "        -5.0035e-01,  1.8324e+01,  3.4644e+01,  1.9972e+01,  3.4025e+01,\n",
      "         6.6275e+00,  1.4737e+01,  2.6996e+01,  2.6323e+01,  1.0069e+01,\n",
      "        -2.2885e-01,  2.5322e+01, -2.9030e+00, -7.7184e-01,  3.3178e+00,\n",
      "         6.3560e+00,  3.8546e+00,  1.1939e+01,  3.2166e+00, -1.1383e+00,\n",
      "        -2.0922e+00, -2.3637e+00, -2.5402e+00,  9.6041e+00, -5.9166e-01,\n",
      "         1.0079e+01,  5.6230e+00, -4.8072e+00,  7.2618e+00,  3.5857e-01,\n",
      "        -3.5855e+00,  5.6699e+00,  3.2503e+01, -3.7212e+00, -4.5959e-01,\n",
      "        -1.2741e+00, -3.2190e+00, -3.6092e-01,  4.3532e+00,  2.2555e+01,\n",
      "         1.4743e+01, -2.0922e+00, -2.0886e+00, -2.9067e+00, -2.7167e+00,\n",
      "         9.0525e-01, -3.1782e+00, -1.6813e+00, -2.6352e+00, -4.4000e+00,\n",
      "         5.6230e+00, -4.4987e-02, -2.9067e+00, -2.6723e+00,  3.8200e+00,\n",
      "         1.6185e+01,  4.8999e+00,  3.5266e+01,  8.4367e+00]) Cost: 195.845291\n",
      "Epochs 6700/10000 hypothesis: tensor([ 3.0577e+01,  5.2659e+00,  4.8945e+01,  4.9303e+01,  1.4377e+01,\n",
      "         4.9737e+01,  6.0124e+01,  5.9033e+00,  4.3651e+01,  3.9732e+01,\n",
      "         3.5670e+01,  4.7501e+01,  1.6545e+01,  1.6426e+01,  4.9311e+01,\n",
      "         2.7161e+01,  2.7169e+01,  5.0943e+01,  1.4734e+01,  5.7990e+01,\n",
      "         4.5597e+01,  3.7055e+01,  3.6935e+01,  2.7458e+01,  3.8686e+01,\n",
      "         3.5184e+01, -2.7670e+00,  1.3221e+00, -5.0790e+00, -4.3988e+00,\n",
      "        -5.0790e+00, -4.5501e-01, -5.4872e+00, -1.7214e+00, -4.8069e+00,\n",
      "        -4.7137e+00, -1.9507e+00,  5.3926e+00, -1.6795e+00, -5.6232e+00,\n",
      "        -3.4893e+00, -4.5348e+00, -6.3035e+00,  3.6248e+00,  4.4228e+01,\n",
      "         3.4896e+01,  3.2005e+01,  5.3000e+01,  2.0760e+01,  3.1267e+01,\n",
      "         3.1104e+01,  1.4335e+01,  4.3948e+01,  3.9656e+01, -4.6709e+00,\n",
      "         4.2622e+00, -8.6317e-01, -4.2627e+00, -4.6709e+00, -3.1752e+00,\n",
      "        -5.6232e+00,  3.5828e+00, -4.6864e-02, -2.7670e+00, -2.8518e+00,\n",
      "        -1.5434e+00, -4.5348e+00, -5.8953e+00, -4.7137e+00,  1.7793e+01,\n",
      "         9.9823e+00,  1.7209e+00,  3.1319e+00,  7.4494e+00,  8.9187e-02,\n",
      "         2.2524e-01, -3.1743e+00,  4.4403e+00,  1.3705e+01, -1.8995e+00,\n",
      "        -4.9699e-01,  1.8320e+01,  3.4640e+01,  1.9969e+01,  3.4019e+01,\n",
      "         6.6247e+00,  1.4733e+01,  2.6989e+01,  2.6318e+01,  1.0067e+01,\n",
      "        -2.2489e-01,  2.5315e+01, -2.9031e+00, -7.6909e-01,  3.3192e+00,\n",
      "         6.3526e+00,  3.8541e+00,  1.1937e+01,  3.2167e+00, -1.1344e+00,\n",
      "        -2.0859e+00, -2.3580e+00, -2.5369e+00,  9.6093e+00, -5.9106e-01,\n",
      "         1.0076e+01,  5.6219e+00, -4.8069e+00,  7.2630e+00,  3.6129e-01,\n",
      "        -3.5825e+00,  5.6740e+00,  3.2498e+01, -3.7185e+00, -4.5417e-01,\n",
      "        -1.2705e+00, -3.2172e+00, -3.6178e-01,  4.3563e+00,  2.2554e+01,\n",
      "         1.4742e+01, -2.0859e+00, -2.0868e+00, -2.9022e+00, -2.7158e+00,\n",
      "         9.0465e-01, -3.1743e+00, -1.6786e+00, -2.6301e+00, -4.3988e+00,\n",
      "         5.6219e+00, -4.7705e-02, -2.9022e+00, -2.6738e+00,  3.8206e+00,\n",
      "         1.6188e+01,  4.8997e+00,  3.5260e+01,  8.4353e+00]) Cost: 195.828461\n",
      "Epochs 6800/10000 hypothesis: tensor([ 3.0575e+01,  5.2691e+00,  4.8942e+01,  4.9304e+01,  1.4378e+01,\n",
      "         4.9740e+01,  6.0128e+01,  5.9059e+00,  4.3652e+01,  3.9734e+01,\n",
      "         3.5674e+01,  4.7504e+01,  1.6547e+01,  1.6430e+01,  4.9311e+01,\n",
      "         2.7163e+01,  2.7170e+01,  5.0942e+01,  1.4735e+01,  5.7991e+01,\n",
      "         4.5601e+01,  3.7057e+01,  3.6935e+01,  2.7457e+01,  3.8683e+01,\n",
      "         3.5186e+01, -2.7668e+00,  1.3255e+00, -5.0794e+00, -4.3976e+00,\n",
      "        -5.0794e+00, -4.5412e-01, -5.4885e+00, -1.7208e+00, -4.8067e+00,\n",
      "        -4.7152e+00, -1.9486e+00,  5.3930e+00, -1.6813e+00, -5.6248e+00,\n",
      "        -3.4880e+00, -4.5340e+00, -6.3066e+00,  3.6257e+00,  4.4230e+01,\n",
      "         3.4901e+01,  3.2004e+01,  5.3001e+01,  2.0758e+01,  3.1269e+01,\n",
      "         3.1106e+01,  1.4338e+01,  4.3950e+01,  3.9657e+01, -4.6703e+00,\n",
      "         4.2626e+00, -8.6318e-01, -4.2613e+00, -4.6703e+00, -3.1758e+00,\n",
      "        -5.6248e+00,  3.5862e+00, -4.5061e-02, -2.7668e+00, -2.8511e+00,\n",
      "        -1.5449e+00, -4.5340e+00, -5.8975e+00, -4.7152e+00,  1.7790e+01,\n",
      "         9.9804e+00,  1.7222e+00,  3.1323e+00,  7.4471e+00,  9.1292e-02,\n",
      "         2.2764e-01, -3.1705e+00,  4.4385e+00,  1.3703e+01, -1.8967e+00,\n",
      "        -4.9363e-01,  1.8316e+01,  3.4637e+01,  1.9966e+01,  3.4013e+01,\n",
      "         6.6219e+00,  1.4730e+01,  2.6983e+01,  2.6314e+01,  1.0065e+01,\n",
      "        -2.2093e-01,  2.5308e+01, -2.9031e+00, -7.6634e-01,  3.3206e+00,\n",
      "         6.3492e+00,  3.8536e+00,  1.1936e+01,  3.2167e+00, -1.1305e+00,\n",
      "        -2.0796e+00, -2.3523e+00, -2.5336e+00,  9.6145e+00, -5.9047e-01,\n",
      "         1.0072e+01,  5.6208e+00, -4.8067e+00,  7.2641e+00,  3.6400e-01,\n",
      "        -3.5795e+00,  5.6781e+00,  3.2493e+01, -3.7159e+00, -4.4876e-01,\n",
      "        -1.2669e+00, -3.2153e+00, -3.6264e-01,  4.3595e+00,  2.2552e+01,\n",
      "         1.4742e+01, -2.0796e+00, -2.0850e+00, -2.8977e+00, -2.7148e+00,\n",
      "         9.0405e-01, -3.1705e+00, -1.6759e+00, -2.6250e+00, -4.3976e+00,\n",
      "         5.6208e+00, -5.0424e-02, -2.8977e+00, -2.6753e+00,  3.8211e+00,\n",
      "         1.6190e+01,  4.8995e+00,  3.5254e+01,  8.4340e+00]) Cost: 195.811600\n",
      "Epochs 6900/10000 hypothesis: tensor([ 3.0573e+01,  5.2723e+00,  4.8938e+01,  4.9306e+01,  1.4379e+01,\n",
      "         4.9743e+01,  6.0132e+01,  5.9086e+00,  4.3654e+01,  3.9736e+01,\n",
      "         3.5678e+01,  4.7508e+01,  1.6550e+01,  1.6434e+01,  4.9311e+01,\n",
      "         2.7165e+01,  2.7171e+01,  5.0941e+01,  1.4736e+01,  5.7992e+01,\n",
      "         4.5604e+01,  3.7060e+01,  3.6935e+01,  2.7456e+01,  3.8680e+01,\n",
      "         3.5188e+01, -2.7665e+00,  1.3290e+00, -5.0797e+00, -4.3965e+00,\n",
      "        -5.0797e+00, -4.5323e-01, -5.4897e+00, -1.7202e+00, -4.8064e+00,\n",
      "        -4.7167e+00, -1.9466e+00,  5.3933e+00, -1.6831e+00, -5.6264e+00,\n",
      "        -3.4868e+00, -4.5331e+00, -6.3096e+00,  3.6267e+00,  4.4232e+01,\n",
      "         3.4905e+01,  3.2002e+01,  5.3003e+01,  2.0756e+01,  3.1272e+01,\n",
      "         3.1108e+01,  1.4342e+01,  4.3953e+01,  3.9658e+01, -4.6698e+00,\n",
      "         4.2630e+00, -8.6319e-01, -4.2598e+00, -4.6698e+00, -3.1764e+00,\n",
      "        -5.6264e+00,  3.5896e+00, -4.3260e-02, -2.7665e+00, -2.8505e+00,\n",
      "        -1.5465e+00, -4.5331e+00, -5.8997e+00, -4.7167e+00,  1.7787e+01,\n",
      "         9.9786e+00,  1.7234e+00,  3.1327e+00,  7.4447e+00,  9.3395e-02,\n",
      "         2.3005e-01, -3.1666e+00,  4.4367e+00,  1.3701e+01, -1.8939e+00,\n",
      "        -4.9028e-01,  1.8312e+01,  3.4633e+01,  1.9963e+01,  3.4007e+01,\n",
      "         6.6190e+00,  1.4726e+01,  2.6977e+01,  2.6310e+01,  1.0063e+01,\n",
      "        -2.1697e-01,  2.5300e+01, -2.9031e+00, -7.6359e-01,  3.3220e+00,\n",
      "         6.3457e+00,  3.8530e+00,  1.1935e+01,  3.2167e+00, -1.1266e+00,\n",
      "        -2.0733e+00, -2.3466e+00, -2.5302e+00,  9.6197e+00, -5.8988e-01,\n",
      "         1.0068e+01,  5.6197e+00, -4.8064e+00,  7.2653e+00,  3.6671e-01,\n",
      "        -3.5765e+00,  5.6822e+00,  3.2488e+01, -3.7132e+00, -4.4335e-01,\n",
      "        -1.2633e+00, -3.2135e+00, -3.6351e-01,  4.3626e+00,  2.2550e+01,\n",
      "         1.4742e+01, -2.0733e+00, -2.0832e+00, -2.8933e+00, -2.7138e+00,\n",
      "         9.0345e-01, -3.1666e+00, -1.6732e+00, -2.6199e+00, -4.3965e+00,\n",
      "         5.6197e+00, -5.3139e-02, -2.8933e+00, -2.6768e+00,  3.8217e+00,\n",
      "         1.6192e+01,  4.8993e+00,  3.5248e+01,  8.4326e+00]) Cost: 195.794815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 7000/10000 hypothesis: tensor([ 3.0571e+01,  5.2754e+00,  4.8935e+01,  4.9307e+01,  1.4380e+01,\n",
      "         4.9745e+01,  6.0136e+01,  5.9112e+00,  4.3656e+01,  3.9739e+01,\n",
      "         3.5682e+01,  4.7511e+01,  1.6552e+01,  1.6438e+01,  4.9311e+01,\n",
      "         2.7167e+01,  2.7172e+01,  5.0940e+01,  1.4737e+01,  5.7993e+01,\n",
      "         4.5608e+01,  3.7063e+01,  3.6935e+01,  2.7454e+01,  3.8678e+01,\n",
      "         3.5190e+01, -2.7662e+00,  1.3325e+00, -5.0801e+00, -4.3953e+00,\n",
      "        -5.0801e+00, -4.5233e-01, -5.4910e+00, -1.7196e+00, -4.8062e+00,\n",
      "        -4.7182e+00, -1.9445e+00,  5.3936e+00, -1.6849e+00, -5.6279e+00,\n",
      "        -3.4856e+00, -4.5323e+00, -6.3127e+00,  3.6276e+00,  4.4234e+01,\n",
      "         3.4909e+01,  3.2001e+01,  5.3004e+01,  2.0755e+01,  3.1275e+01,\n",
      "         3.1110e+01,  1.4345e+01,  4.3956e+01,  3.9659e+01, -4.6692e+00,\n",
      "         4.2634e+00, -8.6320e-01, -4.2583e+00, -4.6692e+00, -3.1771e+00,\n",
      "        -5.6279e+00,  3.5930e+00, -4.1461e-02, -2.7662e+00, -2.8498e+00,\n",
      "        -1.5480e+00, -4.5323e+00, -5.9018e+00, -4.7182e+00,  1.7783e+01,\n",
      "         9.9768e+00,  1.7246e+00,  3.1331e+00,  7.4423e+00,  9.5496e-02,\n",
      "         2.3245e-01, -3.1627e+00,  4.4349e+00,  1.3699e+01, -1.8911e+00,\n",
      "        -4.8694e-01,  1.8308e+01,  3.4629e+01,  1.9960e+01,  3.4001e+01,\n",
      "         6.6162e+00,  1.4723e+01,  2.6971e+01,  2.6305e+01,  1.0060e+01,\n",
      "        -2.1302e-01,  2.5293e+01, -2.9032e+00, -7.6085e-01,  3.3234e+00,\n",
      "         6.3423e+00,  3.8525e+00,  1.1933e+01,  3.2167e+00, -1.1227e+00,\n",
      "        -2.0670e+00, -2.3409e+00, -2.5269e+00,  9.6249e+00, -5.8929e-01,\n",
      "         1.0065e+01,  5.6186e+00, -4.8062e+00,  7.2664e+00,  3.6941e-01,\n",
      "        -3.5736e+00,  5.6863e+00,  3.2483e+01, -3.7105e+00, -4.3794e-01,\n",
      "        -1.2597e+00, -3.2117e+00, -3.6437e-01,  4.3657e+00,  2.2548e+01,\n",
      "         1.4741e+01, -2.0670e+00, -2.0814e+00, -2.8888e+00, -2.7129e+00,\n",
      "         9.0285e-01, -3.1627e+00, -1.6706e+00, -2.6149e+00, -4.3953e+00,\n",
      "         5.6186e+00, -5.5854e-02, -2.8888e+00, -2.6783e+00,  3.8223e+00,\n",
      "         1.6195e+01,  4.8992e+00,  3.5242e+01,  8.4313e+00]) Cost: 195.778030\n",
      "Epochs 7100/10000 hypothesis: tensor([ 3.0569e+01,  5.2786e+00,  4.8932e+01,  4.9309e+01,  1.4380e+01,\n",
      "         4.9748e+01,  6.0139e+01,  5.9139e+00,  4.3657e+01,  3.9741e+01,\n",
      "         3.5686e+01,  4.7514e+01,  1.6555e+01,  1.6442e+01,  4.9312e+01,\n",
      "         2.7169e+01,  2.7172e+01,  5.0940e+01,  1.4738e+01,  5.7994e+01,\n",
      "         4.5611e+01,  3.7066e+01,  3.6934e+01,  2.7453e+01,  3.8675e+01,\n",
      "         3.5192e+01, -2.7659e+00,  1.3359e+00, -5.0804e+00, -4.3941e+00,\n",
      "        -5.0804e+00, -4.5144e-01, -5.4922e+00, -1.7189e+00, -4.8059e+00,\n",
      "        -4.7197e+00, -1.9424e+00,  5.3940e+00, -1.6868e+00, -5.6295e+00,\n",
      "        -3.4844e+00, -4.5314e+00, -6.3158e+00,  3.6285e+00,  4.4236e+01,\n",
      "         3.4913e+01,  3.2000e+01,  5.3005e+01,  2.0753e+01,  3.1277e+01,\n",
      "         3.1112e+01,  1.4348e+01,  4.3958e+01,  3.9661e+01, -4.6687e+00,\n",
      "         4.2638e+00, -8.6322e-01, -4.2569e+00, -4.6687e+00, -3.1777e+00,\n",
      "        -5.6295e+00,  3.5964e+00, -3.9664e-02, -2.7659e+00, -2.8491e+00,\n",
      "        -1.5495e+00, -4.5314e+00, -5.9040e+00, -4.7197e+00,  1.7780e+01,\n",
      "         9.9749e+00,  1.7258e+00,  3.1335e+00,  7.4400e+00,  9.7595e-02,\n",
      "         2.3485e-01, -3.1588e+00,  4.4332e+00,  1.3697e+01, -1.8883e+00,\n",
      "        -4.8359e-01,  1.8304e+01,  3.4626e+01,  1.9957e+01,  3.3995e+01,\n",
      "         6.6134e+00,  1.4719e+01,  2.6965e+01,  2.6301e+01,  1.0058e+01,\n",
      "        -2.0907e-01,  2.5286e+01, -2.9032e+00, -7.5811e-01,  3.3249e+00,\n",
      "         6.3389e+00,  3.8520e+00,  1.1932e+01,  3.2167e+00, -1.1188e+00,\n",
      "        -2.0607e+00, -2.3353e+00, -2.5236e+00,  9.6301e+00, -5.8870e-01,\n",
      "         1.0061e+01,  5.6174e+00, -4.8059e+00,  7.2676e+00,  3.7211e-01,\n",
      "        -3.5706e+00,  5.6904e+00,  3.2478e+01, -3.7078e+00, -4.3254e-01,\n",
      "        -1.2561e+00, -3.2099e+00, -3.6523e-01,  4.3689e+00,  2.2546e+01,\n",
      "         1.4741e+01, -2.0607e+00, -2.0796e+00, -2.8843e+00, -2.7119e+00,\n",
      "         9.0225e-01, -3.1588e+00, -1.6679e+00, -2.6098e+00, -4.3941e+00,\n",
      "         5.6174e+00, -5.8566e-02, -2.8843e+00, -2.6797e+00,  3.8228e+00,\n",
      "         1.6197e+01,  4.8990e+00,  3.5236e+01,  8.4299e+00]) Cost: 195.761292\n",
      "Epochs 7200/10000 hypothesis: tensor([ 3.0567e+01,  5.2818e+00,  4.8929e+01,  4.9310e+01,  1.4381e+01,\n",
      "         4.9751e+01,  6.0143e+01,  5.9165e+00,  4.3659e+01,  3.9743e+01,\n",
      "         3.5690e+01,  4.7517e+01,  1.6557e+01,  1.6446e+01,  4.9312e+01,\n",
      "         2.7172e+01,  2.7173e+01,  5.0939e+01,  1.4739e+01,  5.7995e+01,\n",
      "         4.5615e+01,  3.7068e+01,  3.6934e+01,  2.7452e+01,  3.8672e+01,\n",
      "         3.5194e+01, -2.7657e+00,  1.3394e+00, -5.0808e+00, -4.3930e+00,\n",
      "        -5.0808e+00, -4.5055e-01, -5.4935e+00, -1.7183e+00, -4.8057e+00,\n",
      "        -4.7212e+00, -1.9403e+00,  5.3943e+00, -1.6886e+00, -5.6310e+00,\n",
      "        -3.4832e+00, -4.5305e+00, -6.3188e+00,  3.6294e+00,  4.4237e+01,\n",
      "         3.4917e+01,  3.1999e+01,  5.3006e+01,  2.0751e+01,  3.1280e+01,\n",
      "         3.1114e+01,  1.4352e+01,  4.3961e+01,  3.9662e+01, -4.6681e+00,\n",
      "         4.2641e+00, -8.6323e-01, -4.2554e+00, -4.6681e+00, -3.1783e+00,\n",
      "        -5.6310e+00,  3.5997e+00, -3.7869e-02, -2.7657e+00, -2.8485e+00,\n",
      "        -1.5510e+00, -4.5305e+00, -5.9061e+00, -4.7212e+00,  1.7777e+01,\n",
      "         9.9731e+00,  1.7270e+00,  3.1340e+00,  7.4376e+00,  9.9691e-02,\n",
      "         2.3725e-01, -3.1549e+00,  4.4314e+00,  1.3695e+01, -1.8856e+00,\n",
      "        -4.8025e-01,  1.8300e+01,  3.4622e+01,  1.9954e+01,  3.3989e+01,\n",
      "         6.6106e+00,  1.4716e+01,  2.6959e+01,  2.6296e+01,  1.0056e+01,\n",
      "        -2.0513e-01,  2.5279e+01, -2.9032e+00, -7.5537e-01,  3.3263e+00,\n",
      "         6.3355e+00,  3.8515e+00,  1.1930e+01,  3.2168e+00, -1.1149e+00,\n",
      "        -2.0545e+00, -2.3296e+00, -2.5202e+00,  9.6353e+00, -5.8811e-01,\n",
      "         1.0058e+01,  5.6163e+00, -4.8057e+00,  7.2687e+00,  3.7481e-01,\n",
      "        -3.5676e+00,  5.6945e+00,  3.2473e+01, -3.7052e+00, -4.2714e-01,\n",
      "        -1.2525e+00, -3.2080e+00, -3.6610e-01,  4.3720e+00,  2.2545e+01,\n",
      "         1.4741e+01, -2.0545e+00, -2.0779e+00, -2.8798e+00, -2.7109e+00,\n",
      "         9.0165e-01, -3.1549e+00, -1.6652e+00, -2.6047e+00, -4.3930e+00,\n",
      "         5.6163e+00, -6.1276e-02, -2.8798e+00, -2.6812e+00,  3.8234e+00,\n",
      "         1.6199e+01,  4.8988e+00,  3.5230e+01,  8.4286e+00]) Cost: 195.744598\n",
      "Epochs 7300/10000 hypothesis: tensor([ 3.0565e+01,  5.2850e+00,  4.8925e+01,  4.9311e+01,  1.4382e+01,\n",
      "         4.9754e+01,  6.0147e+01,  5.9191e+00,  4.3661e+01,  3.9745e+01,\n",
      "         3.5694e+01,  4.7520e+01,  1.6560e+01,  1.6450e+01,  4.9312e+01,\n",
      "         2.7174e+01,  2.7174e+01,  5.0938e+01,  1.4740e+01,  5.7997e+01,\n",
      "         4.5618e+01,  3.7071e+01,  3.6934e+01,  2.7450e+01,  3.8670e+01,\n",
      "         3.5196e+01, -2.7654e+00,  1.3428e+00, -5.0811e+00, -4.3918e+00,\n",
      "        -5.0811e+00, -4.4966e-01, -5.4947e+00, -1.7177e+00, -4.8054e+00,\n",
      "        -4.7227e+00, -1.9382e+00,  5.3947e+00, -1.6904e+00, -5.6326e+00,\n",
      "        -3.4820e+00, -4.5297e+00, -6.3219e+00,  3.6304e+00,  4.4239e+01,\n",
      "         3.4922e+01,  3.1998e+01,  5.3007e+01,  2.0750e+01,  3.1283e+01,\n",
      "         3.1116e+01,  1.4355e+01,  4.3963e+01,  3.9663e+01, -4.6675e+00,\n",
      "         4.2645e+00, -8.6325e-01, -4.2540e+00, -4.6675e+00, -3.1790e+00,\n",
      "        -5.6326e+00,  3.6031e+00, -3.6076e-02, -2.7654e+00, -2.8478e+00,\n",
      "        -1.5526e+00, -4.5297e+00, -5.9083e+00, -4.7227e+00,  1.7773e+01,\n",
      "         9.9713e+00,  1.7282e+00,  3.1344e+00,  7.4353e+00,  1.0179e-01,\n",
      "         2.3965e-01, -3.1511e+00,  4.4296e+00,  1.3693e+01, -1.8828e+00,\n",
      "        -4.7691e-01,  1.8296e+01,  3.4619e+01,  1.9951e+01,  3.3983e+01,\n",
      "         6.6078e+00,  1.4712e+01,  2.6953e+01,  2.6292e+01,  1.0054e+01,\n",
      "        -2.0119e-01,  2.5271e+01, -2.9033e+00, -7.5263e-01,  3.3277e+00,\n",
      "         6.3321e+00,  3.8509e+00,  1.1929e+01,  3.2168e+00, -1.1111e+00,\n",
      "        -2.0482e+00, -2.3239e+00, -2.5169e+00,  9.6405e+00, -5.8752e-01,\n",
      "         1.0054e+01,  5.6152e+00, -4.8054e+00,  7.2699e+00,  3.7751e-01,\n",
      "        -3.5647e+00,  5.6986e+00,  3.2468e+01, -3.7025e+00, -4.2175e-01,\n",
      "        -1.2489e+00, -3.2062e+00, -3.6696e-01,  4.3751e+00,  2.2543e+01,\n",
      "         1.4741e+01, -2.0482e+00, -2.0761e+00, -2.8754e+00, -2.7099e+00,\n",
      "         9.0105e-01, -3.1511e+00, -1.6625e+00, -2.5996e+00, -4.3918e+00,\n",
      "         5.6152e+00, -6.3985e-02, -2.8754e+00, -2.6827e+00,  3.8240e+00,\n",
      "         1.6202e+01,  4.8987e+00,  3.5224e+01,  8.4272e+00]) Cost: 195.727905\n",
      "Epochs 7400/10000 hypothesis: tensor([ 3.0563e+01,  5.2882e+00,  4.8922e+01,  4.9313e+01,  1.4383e+01,\n",
      "         4.9757e+01,  6.0151e+01,  5.9218e+00,  4.3662e+01,  3.9747e+01,\n",
      "         3.5698e+01,  4.7523e+01,  1.6562e+01,  1.6454e+01,  4.9312e+01,\n",
      "         2.7176e+01,  2.7175e+01,  5.0937e+01,  1.4741e+01,  5.7998e+01,\n",
      "         4.5622e+01,  3.7074e+01,  3.6934e+01,  2.7449e+01,  3.8667e+01,\n",
      "         3.5198e+01, -2.7651e+00,  1.3463e+00, -5.0815e+00, -4.3907e+00,\n",
      "        -5.0815e+00, -4.4877e-01, -5.4960e+00, -1.7170e+00, -4.8052e+00,\n",
      "        -4.7242e+00, -1.9362e+00,  5.3950e+00, -1.6922e+00, -5.6341e+00,\n",
      "        -3.4807e+00, -4.5288e+00, -6.3249e+00,  3.6313e+00,  4.4241e+01,\n",
      "         3.4926e+01,  3.1996e+01,  5.3008e+01,  2.0748e+01,  3.1285e+01,\n",
      "         3.1118e+01,  1.4358e+01,  4.3966e+01,  3.9664e+01, -4.6670e+00,\n",
      "         4.2649e+00, -8.6326e-01, -4.2525e+00, -4.6670e+00, -3.1796e+00,\n",
      "        -5.6341e+00,  3.6065e+00, -3.4287e-02, -2.7651e+00, -2.8471e+00,\n",
      "        -1.5541e+00, -4.5288e+00, -5.9105e+00, -4.7242e+00,  1.7770e+01,\n",
      "         9.9694e+00,  1.7294e+00,  3.1348e+00,  7.4329e+00,  1.0388e-01,\n",
      "         2.4204e-01, -3.1472e+00,  4.4279e+00,  1.3691e+01, -1.8800e+00,\n",
      "        -4.7358e-01,  1.8293e+01,  3.4615e+01,  1.9948e+01,  3.3977e+01,\n",
      "         6.6050e+00,  1.4709e+01,  2.6947e+01,  2.6288e+01,  1.0051e+01,\n",
      "        -1.9725e-01,  2.5264e+01, -2.9033e+00, -7.4990e-01,  3.3291e+00,\n",
      "         6.3287e+00,  3.8504e+00,  1.1927e+01,  3.2168e+00, -1.1072e+00,\n",
      "        -2.0419e+00, -2.3182e+00, -2.5136e+00,  9.6456e+00, -5.8694e-01,\n",
      "         1.0050e+01,  5.6141e+00, -4.8052e+00,  7.2710e+00,  3.8020e-01,\n",
      "        -3.5617e+00,  5.7027e+00,  3.2463e+01, -3.6999e+00, -4.1637e-01,\n",
      "        -1.2453e+00, -3.2044e+00, -3.6782e-01,  4.3782e+00,  2.2541e+01,\n",
      "         1.4740e+01, -2.0419e+00, -2.0743e+00, -2.8709e+00, -2.7090e+00,\n",
      "         9.0044e-01, -3.1472e+00, -1.6598e+00, -2.5946e+00, -4.3907e+00,\n",
      "         5.6141e+00, -6.6693e-02, -2.8709e+00, -2.6842e+00,  3.8245e+00,\n",
      "         1.6204e+01,  4.8985e+00,  3.5218e+01,  8.4259e+00]) Cost: 195.711273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 7500/10000 hypothesis: tensor([ 3.0561e+01,  5.2914e+00,  4.8919e+01,  4.9314e+01,  1.4384e+01,\n",
      "         4.9759e+01,  6.0155e+01,  5.9244e+00,  4.3664e+01,  3.9750e+01,\n",
      "         3.5702e+01,  4.7527e+01,  1.6565e+01,  1.6458e+01,  4.9312e+01,\n",
      "         2.7178e+01,  2.7176e+01,  5.0937e+01,  1.4742e+01,  5.7999e+01,\n",
      "         4.5625e+01,  3.7077e+01,  3.6933e+01,  2.7448e+01,  3.8664e+01,\n",
      "         3.5200e+01, -2.7649e+00,  1.3497e+00, -5.0818e+00, -4.3895e+00,\n",
      "        -5.0818e+00, -4.4789e-01, -5.4972e+00, -1.7164e+00, -4.8049e+00,\n",
      "        -4.7257e+00, -1.9341e+00,  5.3953e+00, -1.6941e+00, -5.6357e+00,\n",
      "        -3.4795e+00, -4.5280e+00, -6.3280e+00,  3.6322e+00,  4.4243e+01,\n",
      "         3.4930e+01,  3.1995e+01,  5.3009e+01,  2.0746e+01,  3.1288e+01,\n",
      "         3.1120e+01,  1.4362e+01,  4.3968e+01,  3.9666e+01, -4.6664e+00,\n",
      "         4.2653e+00, -8.6328e-01, -4.2511e+00, -4.6664e+00, -3.1802e+00,\n",
      "        -5.6357e+00,  3.6098e+00, -3.2498e-02, -2.7649e+00, -2.8465e+00,\n",
      "        -1.5556e+00, -4.5280e+00, -5.9126e+00, -4.7257e+00,  1.7767e+01,\n",
      "         9.9676e+00,  1.7306e+00,  3.1352e+00,  7.4306e+00,  1.0596e-01,\n",
      "         2.4443e-01, -3.1433e+00,  4.4261e+00,  1.3689e+01, -1.8772e+00,\n",
      "        -4.7024e-01,  1.8289e+01,  3.4611e+01,  1.9945e+01,  3.3971e+01,\n",
      "         6.6022e+00,  1.4706e+01,  2.6941e+01,  2.6283e+01,  1.0049e+01,\n",
      "        -1.9332e-01,  2.5257e+01, -2.9033e+00, -7.4717e-01,  3.3305e+00,\n",
      "         6.3253e+00,  3.8499e+00,  1.1926e+01,  3.2168e+00, -1.1033e+00,\n",
      "        -2.0356e+00, -2.3126e+00, -2.5103e+00,  9.6508e+00, -5.8635e-01,\n",
      "         1.0047e+01,  5.6130e+00, -4.8049e+00,  7.2721e+00,  3.8289e-01,\n",
      "        -3.5587e+00,  5.7067e+00,  3.2458e+01, -3.6972e+00, -4.1099e-01,\n",
      "        -1.2418e+00, -3.2026e+00, -3.6868e-01,  4.3814e+00,  2.2539e+01,\n",
      "         1.4740e+01, -2.0356e+00, -2.0725e+00, -2.8664e+00, -2.7080e+00,\n",
      "         8.9984e-01, -3.1433e+00, -1.6572e+00, -2.5895e+00, -4.3895e+00,\n",
      "         5.6130e+00, -6.9398e-02, -2.8664e+00, -2.6857e+00,  3.8251e+00,\n",
      "         1.6206e+01,  4.8983e+00,  3.5212e+01,  8.4246e+00]) Cost: 195.694641\n",
      "Epochs 7600/10000 hypothesis: tensor([ 3.0559e+01,  5.2945e+00,  4.8916e+01,  4.9316e+01,  1.4385e+01,\n",
      "         4.9762e+01,  6.0159e+01,  5.9270e+00,  4.3666e+01,  3.9752e+01,\n",
      "         3.5706e+01,  4.7530e+01,  1.6567e+01,  1.6462e+01,  4.9312e+01,\n",
      "         2.7180e+01,  2.7176e+01,  5.0936e+01,  1.4743e+01,  5.8000e+01,\n",
      "         4.5628e+01,  3.7079e+01,  3.6933e+01,  2.7446e+01,  3.8662e+01,\n",
      "         3.5202e+01, -2.7646e+00,  1.3532e+00, -5.0822e+00, -4.3884e+00,\n",
      "        -5.0822e+00, -4.4700e-01, -5.4985e+00, -1.7158e+00, -4.8047e+00,\n",
      "        -4.7272e+00, -1.9320e+00,  5.3957e+00, -1.6959e+00, -5.6372e+00,\n",
      "        -3.4783e+00, -4.5271e+00, -6.3310e+00,  3.6331e+00,  4.4245e+01,\n",
      "         3.4934e+01,  3.1994e+01,  5.3010e+01,  2.0745e+01,  3.1290e+01,\n",
      "         3.1122e+01,  1.4365e+01,  4.3971e+01,  3.9667e+01, -4.6659e+00,\n",
      "         4.2656e+00, -8.6329e-01, -4.2496e+00, -4.6659e+00, -3.1809e+00,\n",
      "        -5.6372e+00,  3.6132e+00, -3.0712e-02, -2.7646e+00, -2.8458e+00,\n",
      "        -1.5571e+00, -4.5271e+00, -5.9148e+00, -4.7272e+00,  1.7764e+01,\n",
      "         9.9658e+00,  1.7318e+00,  3.1356e+00,  7.4282e+00,  1.0805e-01,\n",
      "         2.4681e-01, -3.1395e+00,  4.4243e+00,  1.3687e+01, -1.8745e+00,\n",
      "        -4.6691e-01,  1.8285e+01,  3.4608e+01,  1.9942e+01,  3.3965e+01,\n",
      "         6.5994e+00,  1.4702e+01,  2.6935e+01,  2.6279e+01,  1.0047e+01,\n",
      "        -1.8939e-01,  2.5250e+01, -2.9034e+00, -7.4444e-01,  3.3319e+00,\n",
      "         6.3219e+00,  3.8493e+00,  1.1925e+01,  3.2168e+00, -1.0994e+00,\n",
      "        -2.0294e+00, -2.3069e+00, -2.5070e+00,  9.6559e+00, -5.8577e-01,\n",
      "         1.0043e+01,  5.6119e+00, -4.8047e+00,  7.2733e+00,  3.8558e-01,\n",
      "        -3.5558e+00,  5.7108e+00,  3.2453e+01, -3.6945e+00, -4.0561e-01,\n",
      "        -1.2382e+00, -3.2008e+00, -3.6954e-01,  4.3845e+00,  2.2537e+01,\n",
      "         1.4740e+01, -2.0294e+00, -2.0708e+00, -2.8620e+00, -2.7070e+00,\n",
      "         8.9924e-01, -3.1395e+00, -1.6545e+00, -2.5844e+00, -4.3884e+00,\n",
      "         5.6119e+00, -7.2101e-02, -2.8620e+00, -2.6871e+00,  3.8257e+00,\n",
      "         1.6209e+01,  4.8982e+00,  3.5207e+01,  8.4232e+00]) Cost: 195.678055\n",
      "Epochs 7700/10000 hypothesis: tensor([ 3.0557e+01,  5.2977e+00,  4.8913e+01,  4.9317e+01,  1.4386e+01,\n",
      "         4.9765e+01,  6.0163e+01,  5.9297e+00,  4.3667e+01,  3.9754e+01,\n",
      "         3.5710e+01,  4.7533e+01,  1.6570e+01,  1.6466e+01,  4.9312e+01,\n",
      "         2.7182e+01,  2.7177e+01,  5.0935e+01,  1.4745e+01,  5.8001e+01,\n",
      "         4.5632e+01,  3.7082e+01,  3.6933e+01,  2.7445e+01,  3.8659e+01,\n",
      "         3.5204e+01, -2.7643e+00,  1.3566e+00, -5.0825e+00, -4.3872e+00,\n",
      "        -5.0825e+00, -4.4612e-01, -5.4997e+00, -1.7152e+00, -4.8044e+00,\n",
      "        -4.7287e+00, -1.9299e+00,  5.3960e+00, -1.6977e+00, -5.6388e+00,\n",
      "        -3.4771e+00, -4.5263e+00, -6.3341e+00,  3.6340e+00,  4.4246e+01,\n",
      "         3.4939e+01,  3.1993e+01,  5.3011e+01,  2.0743e+01,  3.1293e+01,\n",
      "         3.1123e+01,  1.4368e+01,  4.3973e+01,  3.9668e+01, -4.6653e+00,\n",
      "         4.2660e+00, -8.6331e-01, -4.2481e+00, -4.6653e+00, -3.1815e+00,\n",
      "        -5.6388e+00,  3.6166e+00, -2.8927e-02, -2.7643e+00, -2.8451e+00,\n",
      "        -1.5586e+00, -4.5263e+00, -5.9169e+00, -4.7287e+00,  1.7760e+01,\n",
      "         9.9640e+00,  1.7330e+00,  3.1360e+00,  7.4259e+00,  1.1014e-01,\n",
      "         2.4920e-01, -3.1356e+00,  4.4225e+00,  1.3685e+01, -1.8717e+00,\n",
      "        -4.6359e-01,  1.8281e+01,  3.4604e+01,  1.9939e+01,  3.3959e+01,\n",
      "         6.5966e+00,  1.4699e+01,  2.6929e+01,  2.6274e+01,  1.0045e+01,\n",
      "        -1.8546e-01,  2.5243e+01, -2.9034e+00, -7.4171e-01,  3.3333e+00,\n",
      "         6.3185e+00,  3.8488e+00,  1.1923e+01,  3.2168e+00, -1.0956e+00,\n",
      "        -2.0231e+00, -2.3013e+00, -2.5037e+00,  9.6611e+00, -5.8518e-01,\n",
      "         1.0040e+01,  5.6108e+00, -4.8044e+00,  7.2744e+00,  3.8826e-01,\n",
      "        -3.5528e+00,  5.7149e+00,  3.2448e+01, -3.6919e+00, -4.0024e-01,\n",
      "        -1.2346e+00, -3.1990e+00, -3.7040e-01,  4.3876e+00,  2.2536e+01,\n",
      "         1.4739e+01, -2.0231e+00, -2.0690e+00, -2.8575e+00, -2.7061e+00,\n",
      "         8.9864e-01, -3.1356e+00, -1.6518e+00, -2.5794e+00, -4.3872e+00,\n",
      "         5.6108e+00, -7.4803e-02, -2.8575e+00, -2.6886e+00,  3.8263e+00,\n",
      "         1.6211e+01,  4.8980e+00,  3.5201e+01,  8.4219e+00]) Cost: 195.661484\n",
      "Epochs 7800/10000 hypothesis: tensor([ 3.0555e+01,  5.3009e+00,  4.8909e+01,  4.9319e+01,  1.4386e+01,\n",
      "         4.9768e+01,  6.0167e+01,  5.9323e+00,  4.3669e+01,  3.9756e+01,\n",
      "         3.5714e+01,  4.7536e+01,  1.6572e+01,  1.6470e+01,  4.9312e+01,\n",
      "         2.7184e+01,  2.7178e+01,  5.0934e+01,  1.4746e+01,  5.8002e+01,\n",
      "         4.5635e+01,  3.7085e+01,  3.6932e+01,  2.7444e+01,  3.8656e+01,\n",
      "         3.5205e+01, -2.7641e+00,  1.3601e+00, -5.0829e+00, -4.3861e+00,\n",
      "        -5.0829e+00, -4.4524e-01, -5.5010e+00, -1.7145e+00, -4.8041e+00,\n",
      "        -4.7302e+00, -1.9279e+00,  5.3963e+00, -1.6995e+00, -5.6403e+00,\n",
      "        -3.4759e+00, -4.5254e+00, -6.3371e+00,  3.6349e+00,  4.4248e+01,\n",
      "         3.4943e+01,  3.1991e+01,  5.3012e+01,  2.0742e+01,  3.1296e+01,\n",
      "         3.1125e+01,  1.4371e+01,  4.3976e+01,  3.9669e+01, -4.6648e+00,\n",
      "         4.2664e+00, -8.6333e-01, -4.2467e+00, -4.6648e+00, -3.1821e+00,\n",
      "        -5.6403e+00,  3.6199e+00, -2.7146e-02, -2.7641e+00, -2.8445e+00,\n",
      "        -1.5601e+00, -4.5254e+00, -5.9191e+00, -4.7302e+00,  1.7757e+01,\n",
      "         9.9621e+00,  1.7342e+00,  3.1364e+00,  7.4235e+00,  1.1222e-01,\n",
      "         2.5158e-01, -3.1318e+00,  4.4208e+00,  1.3683e+01, -1.8689e+00,\n",
      "        -4.6026e-01,  1.8277e+01,  3.4601e+01,  1.9936e+01,  3.3953e+01,\n",
      "         6.5938e+00,  1.4695e+01,  2.6923e+01,  2.6270e+01,  1.0043e+01,\n",
      "        -1.8154e-01,  2.5236e+01, -2.9034e+00, -7.3899e-01,  3.3348e+00,\n",
      "         6.3151e+00,  3.8483e+00,  1.1922e+01,  3.2169e+00, -1.0917e+00,\n",
      "        -2.0169e+00, -2.2956e+00, -2.5004e+00,  9.6662e+00, -5.8460e-01,\n",
      "         1.0036e+01,  5.6097e+00, -4.8041e+00,  7.2756e+00,  3.9094e-01,\n",
      "        -3.5499e+00,  5.7190e+00,  3.2443e+01, -3.6892e+00, -3.9488e-01,\n",
      "        -1.2311e+00, -3.1972e+00, -3.7126e-01,  4.3907e+00,  2.2534e+01,\n",
      "         1.4739e+01, -2.0169e+00, -2.0672e+00, -2.8531e+00, -2.7051e+00,\n",
      "         8.9804e-01, -3.1318e+00, -1.6491e+00, -2.5743e+00, -4.3861e+00,\n",
      "         5.6097e+00, -7.7504e-02, -2.8531e+00, -2.6901e+00,  3.8268e+00,\n",
      "         1.6213e+01,  4.8978e+00,  3.5195e+01,  8.4205e+00]) Cost: 195.644928\n",
      "Epochs 7900/10000 hypothesis: tensor([ 3.0553e+01,  5.3040e+00,  4.8906e+01,  4.9320e+01,  1.4387e+01,\n",
      "         4.9771e+01,  6.0171e+01,  5.9349e+00,  4.3671e+01,  3.9758e+01,\n",
      "         3.5717e+01,  4.7539e+01,  1.6575e+01,  1.6474e+01,  4.9313e+01,\n",
      "         2.7187e+01,  2.7179e+01,  5.0934e+01,  1.4747e+01,  5.8003e+01,\n",
      "         4.5639e+01,  3.7087e+01,  3.6932e+01,  2.7443e+01,  3.8654e+01,\n",
      "         3.5207e+01, -2.7638e+00,  1.3635e+00, -5.0832e+00, -4.3849e+00,\n",
      "        -5.0832e+00, -4.4435e-01, -5.5022e+00, -1.7139e+00, -4.8039e+00,\n",
      "        -4.7317e+00, -1.9258e+00,  5.3966e+00, -1.7013e+00, -5.6419e+00,\n",
      "        -3.4747e+00, -4.5246e+00, -6.3402e+00,  3.6359e+00,  4.4250e+01,\n",
      "         3.4947e+01,  3.1990e+01,  5.3013e+01,  2.0740e+01,  3.1298e+01,\n",
      "         3.1127e+01,  1.4375e+01,  4.3978e+01,  3.9671e+01, -4.6642e+00,\n",
      "         4.2667e+00, -8.6334e-01, -4.2452e+00, -4.6642e+00, -3.1828e+00,\n",
      "        -5.6419e+00,  3.6233e+00, -2.5366e-02, -2.7638e+00, -2.8438e+00,\n",
      "        -1.5617e+00, -4.5246e+00, -5.9212e+00, -4.7317e+00,  1.7754e+01,\n",
      "         9.9603e+00,  1.7354e+00,  3.1369e+00,  7.4212e+00,  1.1430e-01,\n",
      "         2.5396e-01, -3.1279e+00,  4.4190e+00,  1.3681e+01, -1.8662e+00,\n",
      "        -4.5694e-01,  1.8273e+01,  3.4597e+01,  1.9933e+01,  3.3947e+01,\n",
      "         6.5910e+00,  1.4692e+01,  2.6917e+01,  2.6266e+01,  1.0040e+01,\n",
      "        -1.7762e-01,  2.5228e+01, -2.9035e+00, -7.3627e-01,  3.3362e+00,\n",
      "         6.3117e+00,  3.8478e+00,  1.1920e+01,  3.2169e+00, -1.0878e+00,\n",
      "        -2.0106e+00, -2.2900e+00, -2.4970e+00,  9.6714e+00, -5.8402e-01,\n",
      "         1.0033e+01,  5.6085e+00, -4.8039e+00,  7.2767e+00,  3.9362e-01,\n",
      "        -3.5469e+00,  5.7230e+00,  3.2438e+01, -3.6866e+00, -3.8952e-01,\n",
      "        -1.2275e+00, -3.1954e+00, -3.7212e-01,  4.3938e+00,  2.2532e+01,\n",
      "         1.4739e+01, -2.0106e+00, -2.0655e+00, -2.8486e+00, -2.7041e+00,\n",
      "         8.9744e-01, -3.1279e+00, -1.6465e+00, -2.5693e+00, -4.3849e+00,\n",
      "         5.6085e+00, -8.0203e-02, -2.8486e+00, -2.6915e+00,  3.8274e+00,\n",
      "         1.6215e+01,  4.8976e+00,  3.5189e+01,  8.4192e+00]) Cost: 195.628448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 8000/10000 hypothesis: tensor([ 3.0551e+01,  5.3072e+00,  4.8903e+01,  4.9322e+01,  1.4388e+01,\n",
      "         4.9774e+01,  6.0175e+01,  5.9376e+00,  4.3672e+01,  3.9761e+01,\n",
      "         3.5721e+01,  4.7542e+01,  1.6577e+01,  1.6478e+01,  4.9313e+01,\n",
      "         2.7189e+01,  2.7180e+01,  5.0933e+01,  1.4748e+01,  5.8005e+01,\n",
      "         4.5642e+01,  3.7090e+01,  3.6932e+01,  2.7441e+01,  3.8651e+01,\n",
      "         3.5209e+01, -2.7635e+00,  1.3669e+00, -5.0836e+00, -4.3838e+00,\n",
      "        -5.0836e+00, -4.4348e-01, -5.5035e+00, -1.7133e+00, -4.8036e+00,\n",
      "        -4.7331e+00, -1.9237e+00,  5.3970e+00, -1.7031e+00, -5.6434e+00,\n",
      "        -3.4735e+00, -4.5237e+00, -6.3432e+00,  3.6368e+00,  4.4252e+01,\n",
      "         3.4951e+01,  3.1989e+01,  5.3014e+01,  2.0738e+01,  3.1301e+01,\n",
      "         3.1129e+01,  1.4378e+01,  4.3981e+01,  3.9672e+01, -4.6637e+00,\n",
      "         4.2671e+00, -8.6336e-01, -4.2438e+00, -4.6637e+00, -3.1834e+00,\n",
      "        -5.6434e+00,  3.6266e+00, -2.3589e-02, -2.7635e+00, -2.8431e+00,\n",
      "        -1.5632e+00, -4.5237e+00, -5.9233e+00, -4.7331e+00,  1.7750e+01,\n",
      "         9.9585e+00,  1.7366e+00,  3.1373e+00,  7.4189e+00,  1.1637e-01,\n",
      "         2.5634e-01, -3.1241e+00,  4.4172e+00,  1.3679e+01, -1.8634e+00,\n",
      "        -4.5362e-01,  1.8269e+01,  3.4594e+01,  1.9930e+01,  3.3941e+01,\n",
      "         6.5882e+00,  1.4688e+01,  2.6911e+01,  2.6261e+01,  1.0038e+01,\n",
      "        -1.7370e-01,  2.5221e+01, -2.9035e+00, -7.3355e-01,  3.3376e+00,\n",
      "         6.3083e+00,  3.8472e+00,  1.1919e+01,  3.2169e+00, -1.0840e+00,\n",
      "        -2.0044e+00, -2.2843e+00, -2.4937e+00,  9.6765e+00, -5.8344e-01,\n",
      "         1.0029e+01,  5.6074e+00, -4.8036e+00,  7.2779e+00,  3.9630e-01,\n",
      "        -3.5440e+00,  5.7271e+00,  3.2433e+01, -3.6839e+00, -3.8416e-01,\n",
      "        -1.2239e+00, -3.1936e+00, -3.7297e-01,  4.3969e+00,  2.2530e+01,\n",
      "         1.4739e+01, -2.0044e+00, -2.0637e+00, -2.8442e+00, -2.7032e+00,\n",
      "         8.9684e-01, -3.1241e+00, -1.6438e+00, -2.5642e+00, -4.3838e+00,\n",
      "         5.6074e+00, -8.2900e-02, -2.8442e+00, -2.6930e+00,  3.8280e+00,\n",
      "         1.6218e+01,  4.8975e+00,  3.5183e+01,  8.4179e+00]) Cost: 195.611969\n",
      "Epochs 8100/10000 hypothesis: tensor([ 3.0549e+01,  5.3104e+00,  4.8900e+01,  4.9323e+01,  1.4389e+01,\n",
      "         4.9776e+01,  6.0178e+01,  5.9402e+00,  4.3674e+01,  3.9763e+01,\n",
      "         3.5725e+01,  4.7545e+01,  1.6580e+01,  1.6482e+01,  4.9313e+01,\n",
      "         2.7191e+01,  2.7180e+01,  5.0932e+01,  1.4749e+01,  5.8006e+01,\n",
      "         4.5646e+01,  3.7093e+01,  3.6932e+01,  2.7440e+01,  3.8648e+01,\n",
      "         3.5211e+01, -2.7633e+00,  1.3704e+00, -5.0839e+00, -4.3826e+00,\n",
      "        -5.0839e+00, -4.4260e-01, -5.5047e+00, -1.7127e+00, -4.8034e+00,\n",
      "        -4.7346e+00, -1.9217e+00,  5.3973e+00, -1.7049e+00, -5.6450e+00,\n",
      "        -3.4723e+00, -4.5229e+00, -6.3463e+00,  3.6377e+00,  4.4253e+01,\n",
      "         3.4955e+01,  3.1988e+01,  5.3015e+01,  2.0737e+01,  3.1304e+01,\n",
      "         3.1131e+01,  1.4381e+01,  4.3983e+01,  3.9673e+01, -4.6631e+00,\n",
      "         4.2675e+00, -8.6338e-01, -4.2423e+00, -4.6631e+00, -3.1840e+00,\n",
      "        -5.6450e+00,  3.6300e+00, -2.1813e-02, -2.7633e+00, -2.8425e+00,\n",
      "        -1.5647e+00, -4.5229e+00, -5.9255e+00, -4.7346e+00,  1.7747e+01,\n",
      "         9.9567e+00,  1.7378e+00,  3.1377e+00,  7.4165e+00,  1.1845e-01,\n",
      "         2.5871e-01, -3.1203e+00,  4.4155e+00,  1.3677e+01, -1.8606e+00,\n",
      "        -4.5031e-01,  1.8265e+01,  3.4590e+01,  1.9927e+01,  3.3936e+01,\n",
      "         6.5854e+00,  1.4685e+01,  2.6905e+01,  2.6257e+01,  1.0036e+01,\n",
      "        -1.6979e-01,  2.5214e+01, -2.9035e+00, -7.3083e-01,  3.3390e+00,\n",
      "         6.3049e+00,  3.8467e+00,  1.1918e+01,  3.2169e+00, -1.0801e+00,\n",
      "        -1.9982e+00, -2.2787e+00, -2.4904e+00,  9.6816e+00, -5.8286e-01,\n",
      "         1.0025e+01,  5.6063e+00, -4.8034e+00,  7.2790e+00,  3.9897e-01,\n",
      "        -3.5410e+00,  5.7312e+00,  3.2428e+01, -3.6813e+00, -3.7881e-01,\n",
      "        -1.2204e+00, -3.1918e+00, -3.7383e-01,  4.4000e+00,  2.2529e+01,\n",
      "         1.4738e+01, -1.9982e+00, -2.0619e+00, -2.8397e+00, -2.7022e+00,\n",
      "         8.9623e-01, -3.1203e+00, -1.6412e+00, -2.5592e+00, -4.3826e+00,\n",
      "         5.6063e+00, -8.5595e-02, -2.8397e+00, -2.6945e+00,  3.8285e+00,\n",
      "         1.6220e+01,  4.8973e+00,  3.5177e+01,  8.4165e+00]) Cost: 195.595566\n",
      "Epochs 8200/10000 hypothesis: tensor([ 3.0547e+01,  5.3135e+00,  4.8896e+01,  4.9325e+01,  1.4390e+01,\n",
      "         4.9779e+01,  6.0182e+01,  5.9428e+00,  4.3676e+01,  3.9765e+01,\n",
      "         3.5729e+01,  4.7549e+01,  1.6582e+01,  1.6486e+01,  4.9313e+01,\n",
      "         2.7193e+01,  2.7181e+01,  5.0931e+01,  1.4750e+01,  5.8007e+01,\n",
      "         4.5649e+01,  3.7096e+01,  3.6931e+01,  2.7439e+01,  3.8646e+01,\n",
      "         3.5213e+01, -2.7630e+00,  1.3738e+00, -5.0843e+00, -4.3815e+00,\n",
      "        -5.0843e+00, -4.4172e-01, -5.5059e+00, -1.7120e+00, -4.8031e+00,\n",
      "        -4.7361e+00, -1.9196e+00,  5.3976e+00, -1.7068e+00, -5.6465e+00,\n",
      "        -3.4711e+00, -4.5220e+00, -6.3493e+00,  3.6386e+00,  4.4255e+01,\n",
      "         3.4960e+01,  3.1987e+01,  5.3016e+01,  2.0735e+01,  3.1306e+01,\n",
      "         3.1133e+01,  1.4385e+01,  4.3986e+01,  3.9674e+01, -4.6626e+00,\n",
      "         4.2679e+00, -8.6340e-01, -4.2409e+00, -4.6626e+00, -3.1847e+00,\n",
      "        -5.6465e+00,  3.6333e+00, -2.0039e-02, -2.7630e+00, -2.8418e+00,\n",
      "        -1.5662e+00, -4.5220e+00, -5.9276e+00, -4.7361e+00,  1.7744e+01,\n",
      "         9.9549e+00,  1.7390e+00,  3.1381e+00,  7.4142e+00,  1.2052e-01,\n",
      "         2.6108e-01, -3.1164e+00,  4.4137e+00,  1.3675e+01, -1.8579e+00,\n",
      "        -4.4700e-01,  1.8261e+01,  3.4587e+01,  1.9924e+01,  3.3930e+01,\n",
      "         6.5826e+00,  1.4681e+01,  2.6899e+01,  2.6253e+01,  1.0034e+01,\n",
      "        -1.6588e-01,  2.5207e+01, -2.9035e+00, -7.2812e-01,  3.3404e+00,\n",
      "         6.3015e+00,  3.8462e+00,  1.1916e+01,  3.2169e+00, -1.0763e+00,\n",
      "        -1.9919e+00, -2.2731e+00, -2.4871e+00,  9.6867e+00, -5.8228e-01,\n",
      "         1.0022e+01,  5.6052e+00, -4.8031e+00,  7.2801e+00,  4.0164e-01,\n",
      "        -3.5381e+00,  5.7352e+00,  3.2423e+01, -3.6787e+00, -3.7347e-01,\n",
      "        -1.2168e+00, -3.1899e+00, -3.7469e-01,  4.4031e+00,  2.2527e+01,\n",
      "         1.4738e+01, -1.9919e+00, -2.0602e+00, -2.8353e+00, -2.7012e+00,\n",
      "         8.9563e-01, -3.1164e+00, -1.6385e+00, -2.5542e+00, -4.3815e+00,\n",
      "         5.6052e+00, -8.8288e-02, -2.8353e+00, -2.6960e+00,  3.8291e+00,\n",
      "         1.6222e+01,  4.8971e+00,  3.5171e+01,  8.4152e+00]) Cost: 195.579117\n",
      "Epochs 8300/10000 hypothesis: tensor([ 3.0545e+01,  5.3167e+00,  4.8893e+01,  4.9326e+01,  1.4391e+01,\n",
      "         4.9782e+01,  6.0186e+01,  5.9454e+00,  4.3678e+01,  3.9767e+01,\n",
      "         3.5733e+01,  4.7552e+01,  1.6585e+01,  1.6490e+01,  4.9313e+01,\n",
      "         2.7195e+01,  2.7182e+01,  5.0931e+01,  1.4751e+01,  5.8008e+01,\n",
      "         4.5652e+01,  3.7098e+01,  3.6931e+01,  2.7437e+01,  3.8643e+01,\n",
      "         3.5215e+01, -2.7627e+00,  1.3772e+00, -5.0846e+00, -4.3803e+00,\n",
      "        -5.0846e+00, -4.4084e-01, -5.5072e+00, -1.7114e+00, -4.8029e+00,\n",
      "        -4.7376e+00, -1.9176e+00,  5.3979e+00, -1.7086e+00, -5.6480e+00,\n",
      "        -3.4699e+00, -4.5212e+00, -6.3523e+00,  3.6395e+00,  4.4257e+01,\n",
      "         3.4964e+01,  3.1985e+01,  5.3017e+01,  2.0733e+01,  3.1309e+01,\n",
      "         3.1135e+01,  1.4388e+01,  4.3988e+01,  3.9676e+01, -4.6620e+00,\n",
      "         4.2682e+00, -8.6342e-01, -4.2395e+00, -4.6620e+00, -3.1853e+00,\n",
      "        -5.6480e+00,  3.6366e+00, -1.8267e-02, -2.7627e+00, -2.8411e+00,\n",
      "        -1.5677e+00, -4.5212e+00, -5.9298e+00, -4.7376e+00,  1.7740e+01,\n",
      "         9.9530e+00,  1.7402e+00,  3.1385e+00,  7.4119e+00,  1.2259e-01,\n",
      "         2.6345e-01, -3.1126e+00,  4.4119e+00,  1.3673e+01, -1.8551e+00,\n",
      "        -4.4369e-01,  1.8257e+01,  3.4583e+01,  1.9921e+01,  3.3924e+01,\n",
      "         6.5798e+00,  1.4678e+01,  2.6893e+01,  2.6248e+01,  1.0031e+01,\n",
      "        -1.6197e-01,  2.5200e+01, -2.9036e+00, -7.2541e-01,  3.3418e+00,\n",
      "         6.2981e+00,  3.8456e+00,  1.1915e+01,  3.2169e+00, -1.0724e+00,\n",
      "        -1.9857e+00, -2.2674e+00, -2.4839e+00,  9.6918e+00, -5.8170e-01,\n",
      "         1.0018e+01,  5.6041e+00, -4.8029e+00,  7.2813e+00,  4.0431e-01,\n",
      "        -3.5352e+00,  5.7393e+00,  3.2418e+01, -3.6760e+00, -3.6813e-01,\n",
      "        -1.2133e+00, -3.1881e+00, -3.7554e-01,  4.4062e+00,  2.2525e+01,\n",
      "         1.4738e+01, -1.9857e+00, -2.0584e+00, -2.8309e+00, -2.7003e+00,\n",
      "         8.9503e-01, -3.1126e+00, -1.6359e+00, -2.5492e+00, -4.3803e+00,\n",
      "         5.6041e+00, -9.0979e-02, -2.8309e+00, -2.6974e+00,  3.8297e+00,\n",
      "         1.6225e+01,  4.8970e+00,  3.5165e+01,  8.4139e+00]) Cost: 195.562759\n",
      "Epochs 8400/10000 hypothesis: tensor([ 3.0543e+01,  5.3198e+00,  4.8890e+01,  4.9328e+01,  1.4391e+01,\n",
      "         4.9785e+01,  6.0190e+01,  5.9480e+00,  4.3679e+01,  3.9769e+01,\n",
      "         3.5737e+01,  4.7555e+01,  1.6587e+01,  1.6494e+01,  4.9313e+01,\n",
      "         2.7197e+01,  2.7183e+01,  5.0930e+01,  1.4752e+01,  5.8009e+01,\n",
      "         4.5656e+01,  3.7101e+01,  3.6931e+01,  2.7436e+01,  3.8640e+01,\n",
      "         3.5217e+01, -2.7625e+00,  1.3806e+00, -5.0850e+00, -4.3792e+00,\n",
      "        -5.0850e+00, -4.3997e-01, -5.5084e+00, -1.7108e+00, -4.8026e+00,\n",
      "        -4.7391e+00, -1.9155e+00,  5.3983e+00, -1.7104e+00, -5.6496e+00,\n",
      "        -3.4687e+00, -4.5203e+00, -6.3554e+00,  3.6404e+00,  4.4259e+01,\n",
      "         3.4968e+01,  3.1984e+01,  5.3018e+01,  2.0732e+01,  3.1311e+01,\n",
      "         3.1136e+01,  1.4391e+01,  4.3991e+01,  3.9677e+01, -4.6615e+00,\n",
      "         4.2686e+00, -8.6344e-01, -4.2380e+00, -4.6615e+00, -3.1859e+00,\n",
      "        -5.6496e+00,  3.6400e+00, -1.6498e-02, -2.7625e+00, -2.8405e+00,\n",
      "        -1.5692e+00, -4.5203e+00, -5.9319e+00, -4.7391e+00,  1.7737e+01,\n",
      "         9.9512e+00,  1.7414e+00,  3.1389e+00,  7.4096e+00,  1.2466e-01,\n",
      "         2.6582e-01, -3.1088e+00,  4.4102e+00,  1.3671e+01, -1.8524e+00,\n",
      "        -4.4038e-01,  1.8254e+01,  3.4580e+01,  1.9919e+01,  3.3918e+01,\n",
      "         6.5771e+00,  1.4675e+01,  2.6887e+01,  2.6244e+01,  1.0029e+01,\n",
      "        -1.5807e-01,  2.5193e+01, -2.9036e+00, -7.2270e-01,  3.3432e+00,\n",
      "         6.2947e+00,  3.8451e+00,  1.1913e+01,  3.2169e+00, -1.0686e+00,\n",
      "        -1.9795e+00, -2.2618e+00, -2.4806e+00,  9.6969e+00, -5.8113e-01,\n",
      "         1.0015e+01,  5.6030e+00, -4.8026e+00,  7.2824e+00,  4.0697e-01,\n",
      "        -3.5322e+00,  5.7433e+00,  3.2413e+01, -3.6734e+00, -3.6280e-01,\n",
      "        -1.2097e+00, -3.1863e+00, -3.7640e-01,  4.4093e+00,  2.2523e+01,\n",
      "         1.4737e+01, -1.9795e+00, -2.0567e+00, -2.8264e+00, -2.6993e+00,\n",
      "         8.9443e-01, -3.1088e+00, -1.6332e+00, -2.5441e+00, -4.3792e+00,\n",
      "         5.6030e+00, -9.3670e-02, -2.8264e+00, -2.6989e+00,  3.8303e+00,\n",
      "         1.6227e+01,  4.8968e+00,  3.5159e+01,  8.4125e+00]) Cost: 195.546402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 8500/10000 hypothesis: tensor([ 3.0541e+01,  5.3230e+00,  4.8887e+01,  4.9329e+01,  1.4392e+01,\n",
      "         4.9788e+01,  6.0194e+01,  5.9507e+00,  4.3681e+01,  3.9771e+01,\n",
      "         3.5741e+01,  4.7558e+01,  1.6590e+01,  1.6498e+01,  4.9313e+01,\n",
      "         2.7199e+01,  2.7184e+01,  5.0929e+01,  1.4753e+01,  5.8010e+01,\n",
      "         4.5659e+01,  3.7104e+01,  3.6931e+01,  2.7435e+01,  3.8638e+01,\n",
      "         3.5219e+01, -2.7622e+00,  1.3841e+00, -5.0853e+00, -4.3780e+00,\n",
      "        -5.0853e+00, -4.3910e-01, -5.5097e+00, -1.7102e+00, -4.8024e+00,\n",
      "        -4.7405e+00, -1.9135e+00,  5.3986e+00, -1.7122e+00, -5.6511e+00,\n",
      "        -3.4675e+00, -4.5195e+00, -6.3584e+00,  3.6413e+00,  4.4260e+01,\n",
      "         3.4972e+01,  3.1983e+01,  5.3019e+01,  2.0730e+01,  3.1314e+01,\n",
      "         3.1138e+01,  1.4394e+01,  4.3993e+01,  3.9678e+01, -4.6609e+00,\n",
      "         4.2690e+00, -8.6346e-01, -4.2366e+00, -4.6609e+00, -3.1866e+00,\n",
      "        -5.6511e+00,  3.6433e+00, -1.4731e-02, -2.7622e+00, -2.8398e+00,\n",
      "        -1.5707e+00, -4.5195e+00, -5.9340e+00, -4.7405e+00,  1.7734e+01,\n",
      "         9.9494e+00,  1.7426e+00,  3.1393e+00,  7.4073e+00,  1.2672e-01,\n",
      "         2.6818e-01, -3.1049e+00,  4.4084e+00,  1.3669e+01, -1.8496e+00,\n",
      "        -4.3708e-01,  1.8250e+01,  3.4576e+01,  1.9916e+01,  3.3912e+01,\n",
      "         6.5743e+00,  1.4671e+01,  2.6881e+01,  2.6239e+01,  1.0027e+01,\n",
      "        -1.5417e-01,  2.5185e+01, -2.9037e+00, -7.1999e-01,  3.3446e+00,\n",
      "         6.2914e+00,  3.8446e+00,  1.1912e+01,  3.2169e+00, -1.0647e+00,\n",
      "        -1.9733e+00, -2.2562e+00, -2.4773e+00,  9.7020e+00, -5.8055e-01,\n",
      "         1.0011e+01,  5.6019e+00, -4.8024e+00,  7.2836e+00,  4.0963e-01,\n",
      "        -3.5293e+00,  5.7474e+00,  3.2408e+01, -3.6708e+00, -3.5747e-01,\n",
      "        -1.2062e+00, -3.1845e+00, -3.7725e-01,  4.4124e+00,  2.2522e+01,\n",
      "         1.4737e+01, -1.9733e+00, -2.0549e+00, -2.8220e+00, -2.6983e+00,\n",
      "         8.9382e-01, -3.1049e+00, -1.6306e+00, -2.5391e+00, -4.3780e+00,\n",
      "         5.6019e+00, -9.6359e-02, -2.8220e+00, -2.7004e+00,  3.8308e+00,\n",
      "         1.6229e+01,  4.8966e+00,  3.5154e+01,  8.4112e+00]) Cost: 195.530075\n",
      "Epochs 8600/10000 hypothesis: tensor([ 3.0539e+01,  5.3261e+00,  4.8884e+01,  4.9330e+01,  1.4393e+01,\n",
      "         4.9791e+01,  6.0198e+01,  5.9533e+00,  4.3683e+01,  3.9774e+01,\n",
      "         3.5745e+01,  4.7561e+01,  1.6592e+01,  1.6502e+01,  4.9313e+01,\n",
      "         2.7201e+01,  2.7184e+01,  5.0928e+01,  1.4754e+01,  5.8011e+01,\n",
      "         4.5663e+01,  3.7106e+01,  3.6930e+01,  2.7434e+01,  3.8635e+01,\n",
      "         3.5220e+01, -2.7619e+00,  1.3875e+00, -5.0856e+00, -4.3769e+00,\n",
      "        -5.0856e+00, -4.3822e-01, -5.5109e+00, -1.7096e+00, -4.8021e+00,\n",
      "        -4.7420e+00, -1.9114e+00,  5.3989e+00, -1.7140e+00, -5.6527e+00,\n",
      "        -3.4663e+00, -4.5186e+00, -6.3614e+00,  3.6422e+00,  4.4262e+01,\n",
      "         3.4976e+01,  3.1982e+01,  5.3020e+01,  2.0728e+01,  3.1317e+01,\n",
      "         3.1140e+01,  1.4398e+01,  4.3996e+01,  3.9679e+01, -4.6604e+00,\n",
      "         4.2693e+00, -8.6348e-01, -4.2351e+00, -4.6604e+00, -3.1872e+00,\n",
      "        -5.6527e+00,  3.6466e+00, -1.2966e-02, -2.7619e+00, -2.8391e+00,\n",
      "        -1.5722e+00, -4.5186e+00, -5.9362e+00, -4.7420e+00,  1.7731e+01,\n",
      "         9.9476e+00,  1.7437e+00,  3.1397e+00,  7.4049e+00,  1.2879e-01,\n",
      "         2.7054e-01, -3.1011e+00,  4.4066e+00,  1.3667e+01, -1.8469e+00,\n",
      "        -4.3378e-01,  1.8246e+01,  3.4573e+01,  1.9913e+01,  3.3906e+01,\n",
      "         6.5715e+00,  1.4668e+01,  2.6875e+01,  2.6235e+01,  1.0025e+01,\n",
      "        -1.5028e-01,  2.5178e+01, -2.9037e+00, -7.1729e-01,  3.3460e+00,\n",
      "         6.2880e+00,  3.8441e+00,  1.1911e+01,  3.2169e+00, -1.0609e+00,\n",
      "        -1.9671e+00, -2.2506e+00, -2.4740e+00,  9.7071e+00, -5.7998e-01,\n",
      "         1.0008e+01,  5.6008e+00, -4.8021e+00,  7.2847e+00,  4.1229e-01,\n",
      "        -3.5264e+00,  5.7514e+00,  3.2403e+01, -3.6681e+00, -3.5214e-01,\n",
      "        -1.2027e+00, -3.1827e+00, -3.7811e-01,  4.4155e+00,  2.2520e+01,\n",
      "         1.4737e+01, -1.9671e+00, -2.0532e+00, -2.8176e+00, -2.6974e+00,\n",
      "         8.9322e-01, -3.1011e+00, -1.6279e+00, -2.5341e+00, -4.3769e+00,\n",
      "         5.6008e+00, -9.9046e-02, -2.8176e+00, -2.7018e+00,  3.8314e+00,\n",
      "         1.6231e+01,  4.8964e+00,  3.5148e+01,  8.4098e+00]) Cost: 195.513794\n",
      "Epochs 8700/10000 hypothesis: tensor([ 3.0537e+01,  5.3293e+00,  4.8880e+01,  4.9332e+01,  1.4394e+01,\n",
      "         4.9793e+01,  6.0202e+01,  5.9559e+00,  4.3684e+01,  3.9776e+01,\n",
      "         3.5749e+01,  4.7564e+01,  1.6595e+01,  1.6506e+01,  4.9313e+01,\n",
      "         2.7204e+01,  2.7185e+01,  5.0928e+01,  1.4755e+01,  5.8013e+01,\n",
      "         4.5666e+01,  3.7109e+01,  3.6930e+01,  2.7432e+01,  3.8633e+01,\n",
      "         3.5222e+01, -2.7617e+00,  1.3909e+00, -5.0860e+00, -4.3757e+00,\n",
      "        -5.0860e+00, -4.3735e-01, -5.5121e+00, -1.7089e+00, -4.8019e+00,\n",
      "        -4.7435e+00, -1.9094e+00,  5.3992e+00, -1.7158e+00, -5.6542e+00,\n",
      "        -3.4651e+00, -4.5178e+00, -6.3644e+00,  3.6431e+00,  4.4264e+01,\n",
      "         3.4980e+01,  3.1980e+01,  5.3022e+01,  2.0727e+01,  3.1319e+01,\n",
      "         3.1142e+01,  1.4401e+01,  4.3998e+01,  3.9681e+01, -4.6598e+00,\n",
      "         4.2697e+00, -8.6350e-01, -4.2337e+00, -4.6598e+00, -3.1878e+00,\n",
      "        -5.6542e+00,  3.6500e+00, -1.1202e-02, -2.7617e+00, -2.8385e+00,\n",
      "        -1.5738e+00, -4.5178e+00, -5.9383e+00, -4.7435e+00,  1.7727e+01,\n",
      "         9.9458e+00,  1.7449e+00,  3.1401e+00,  7.4026e+00,  1.3085e-01,\n",
      "         2.7290e-01, -3.0973e+00,  4.4049e+00,  1.3665e+01, -1.8441e+00,\n",
      "        -4.3048e-01,  1.8242e+01,  3.4569e+01,  1.9910e+01,  3.3900e+01,\n",
      "         6.5687e+00,  1.4664e+01,  2.6869e+01,  2.6231e+01,  1.0023e+01,\n",
      "        -1.4638e-01,  2.5171e+01, -2.9037e+00, -7.1458e-01,  3.3475e+00,\n",
      "         6.2846e+00,  3.8435e+00,  1.1909e+01,  3.2169e+00, -1.0571e+00,\n",
      "        -1.9609e+00, -2.2450e+00, -2.4707e+00,  9.7122e+00, -5.7940e-01,\n",
      "         1.0004e+01,  5.5996e+00, -4.8019e+00,  7.2858e+00,  4.1495e-01,\n",
      "        -3.5234e+00,  5.7554e+00,  3.2398e+01, -3.6655e+00, -3.4682e-01,\n",
      "        -1.1991e+00, -3.1810e+00, -3.7896e-01,  4.4186e+00,  2.2518e+01,\n",
      "         1.4736e+01, -1.9609e+00, -2.0514e+00, -2.8132e+00, -2.6964e+00,\n",
      "         8.9262e-01, -3.0973e+00, -1.6253e+00, -2.5291e+00, -4.3757e+00,\n",
      "         5.5996e+00, -1.0173e-01, -2.8132e+00, -2.7033e+00,  3.8320e+00,\n",
      "         1.6234e+01,  4.8963e+00,  3.5142e+01,  8.4085e+00]) Cost: 195.497513\n",
      "Epochs 8800/10000 hypothesis: tensor([ 3.0535e+01,  5.3324e+00,  4.8877e+01,  4.9333e+01,  1.4395e+01,\n",
      "         4.9796e+01,  6.0206e+01,  5.9585e+00,  4.3686e+01,  3.9778e+01,\n",
      "         3.5753e+01,  4.7567e+01,  1.6597e+01,  1.6510e+01,  4.9314e+01,\n",
      "         2.7206e+01,  2.7186e+01,  5.0927e+01,  1.4756e+01,  5.8014e+01,\n",
      "         4.5669e+01,  3.7112e+01,  3.6930e+01,  2.7431e+01,  3.8630e+01,\n",
      "         3.5224e+01, -2.7614e+00,  1.3943e+00, -5.0863e+00, -4.3746e+00,\n",
      "        -5.0863e+00, -4.3648e-01, -5.5134e+00, -1.7083e+00, -4.8016e+00,\n",
      "        -4.7450e+00, -1.9073e+00,  5.3995e+00, -1.7176e+00, -5.6557e+00,\n",
      "        -3.4639e+00, -4.5169e+00, -6.3675e+00,  3.6440e+00,  4.4266e+01,\n",
      "         3.4985e+01,  3.1979e+01,  5.3023e+01,  2.0725e+01,  3.1322e+01,\n",
      "         3.1144e+01,  1.4404e+01,  4.4001e+01,  3.9682e+01, -4.6593e+00,\n",
      "         4.2700e+00, -8.6352e-01, -4.2323e+00, -4.6593e+00, -3.1884e+00,\n",
      "        -5.6557e+00,  3.6533e+00, -9.4354e-03, -2.7614e+00, -2.8378e+00,\n",
      "        -1.5753e+00, -4.5169e+00, -5.9404e+00, -4.7450e+00,  1.7724e+01,\n",
      "         9.9440e+00,  1.7461e+00,  3.1406e+00,  7.4003e+00,  1.3291e-01,\n",
      "         2.7526e-01, -3.0935e+00,  4.4031e+00,  1.3663e+01, -1.8414e+00,\n",
      "        -4.2719e-01,  1.8238e+01,  3.4565e+01,  1.9907e+01,  3.3894e+01,\n",
      "         6.5660e+00,  1.4661e+01,  2.6863e+01,  2.6226e+01,  1.0020e+01,\n",
      "        -1.4250e-01,  2.5164e+01, -2.9038e+00, -7.1188e-01,  3.3489e+00,\n",
      "         6.2813e+00,  3.8430e+00,  1.1908e+01,  3.2170e+00, -1.0532e+00,\n",
      "        -1.9547e+00, -2.2394e+00, -2.4674e+00,  9.7173e+00, -5.7882e-01,\n",
      "         1.0001e+01,  5.5985e+00, -4.8016e+00,  7.2870e+00,  4.1761e-01,\n",
      "        -3.5205e+00,  5.7595e+00,  3.2393e+01, -3.6629e+00, -3.4151e-01,\n",
      "        -1.1956e+00, -3.1792e+00, -3.7981e-01,  4.4217e+00,  2.2516e+01,\n",
      "         1.4736e+01, -1.9547e+00, -2.0497e+00, -2.8088e+00, -2.6955e+00,\n",
      "         8.9202e-01, -3.0935e+00, -1.6226e+00, -2.5241e+00, -4.3746e+00,\n",
      "         5.5985e+00, -1.0440e-01, -2.8088e+00, -2.7047e+00,  3.8326e+00,\n",
      "         1.6236e+01,  4.8961e+00,  3.5136e+01,  8.4072e+00]) Cost: 195.481293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 8900/10000 hypothesis: tensor([ 3.0533e+01,  5.3356e+00,  4.8874e+01,  4.9335e+01,  1.4396e+01,\n",
      "         4.9799e+01,  6.0209e+01,  5.9611e+00,  4.3688e+01,  3.9780e+01,\n",
      "         3.5757e+01,  4.7570e+01,  1.6600e+01,  1.6514e+01,  4.9314e+01,\n",
      "         2.7208e+01,  2.7187e+01,  5.0926e+01,  1.4757e+01,  5.8015e+01,\n",
      "         4.5673e+01,  3.7114e+01,  3.6930e+01,  2.7430e+01,  3.8627e+01,\n",
      "         3.5226e+01, -2.7611e+00,  1.3977e+00, -5.0867e+00, -4.3735e+00,\n",
      "        -5.0867e+00, -4.3560e-01, -5.5146e+00, -1.7077e+00, -4.8014e+00,\n",
      "        -4.7464e+00, -1.9053e+00,  5.3999e+00, -1.7194e+00, -5.6573e+00,\n",
      "        -3.4627e+00, -4.5161e+00, -6.3705e+00,  3.6449e+00,  4.4267e+01,\n",
      "         3.4989e+01,  3.1978e+01,  5.3024e+01,  2.0723e+01,  3.1324e+01,\n",
      "         3.1146e+01,  1.4407e+01,  4.4003e+01,  3.9683e+01, -4.6587e+00,\n",
      "         4.2704e+00, -8.6353e-01, -4.2308e+00, -4.6587e+00, -3.1891e+00,\n",
      "        -5.6573e+00,  3.6566e+00, -7.6684e-03, -2.7611e+00, -2.8371e+00,\n",
      "        -1.5767e+00, -4.5161e+00, -5.9425e+00, -4.7464e+00,  1.7721e+01,\n",
      "         9.9422e+00,  1.7473e+00,  3.1410e+00,  7.3980e+00,  1.3498e-01,\n",
      "         2.7762e-01, -3.0897e+00,  4.4014e+00,  1.3661e+01, -1.8386e+00,\n",
      "        -4.2390e-01,  1.8234e+01,  3.4562e+01,  1.9904e+01,  3.3888e+01,\n",
      "         6.5632e+00,  1.4658e+01,  2.6857e+01,  2.6222e+01,  1.0018e+01,\n",
      "        -1.3861e-01,  2.5157e+01, -2.9038e+00, -7.0919e-01,  3.3503e+00,\n",
      "         6.2779e+00,  3.8425e+00,  1.1906e+01,  3.2170e+00, -1.0494e+00,\n",
      "        -1.9485e+00, -2.2338e+00, -2.4641e+00,  9.7224e+00, -5.7824e-01,\n",
      "         9.9971e+00,  5.5974e+00, -4.8014e+00,  7.2881e+00,  4.2026e-01,\n",
      "        -3.5176e+00,  5.7635e+00,  3.2388e+01, -3.6602e+00, -3.3619e-01,\n",
      "        -1.1921e+00, -3.1774e+00, -3.8066e-01,  4.4248e+00,  2.2515e+01,\n",
      "         1.4736e+01, -1.9485e+00, -2.0479e+00, -2.8044e+00, -2.6945e+00,\n",
      "         8.9143e-01, -3.0897e+00, -1.6200e+00, -2.5191e+00, -4.3735e+00,\n",
      "         5.5974e+00, -1.0707e-01, -2.8044e+00, -2.7062e+00,  3.8331e+00,\n",
      "         1.6238e+01,  4.8959e+00,  3.5130e+01,  8.4059e+00]) Cost: 195.465088\n",
      "Epochs 9000/10000 hypothesis: tensor([ 3.0531e+01,  5.3387e+00,  4.8871e+01,  4.9336e+01,  1.4397e+01,\n",
      "         4.9802e+01,  6.0213e+01,  5.9637e+00,  4.3689e+01,  3.9782e+01,\n",
      "         3.5761e+01,  4.7574e+01,  1.6602e+01,  1.6518e+01,  4.9314e+01,\n",
      "         2.7210e+01,  2.7187e+01,  5.0925e+01,  1.4758e+01,  5.8016e+01,\n",
      "         4.5676e+01,  3.7117e+01,  3.6929e+01,  2.7429e+01,  3.8625e+01,\n",
      "         3.5228e+01, -2.7609e+00,  1.4011e+00, -5.0870e+00, -4.3723e+00,\n",
      "        -5.0870e+00, -4.3472e-01, -5.5158e+00, -1.7071e+00, -4.8011e+00,\n",
      "        -4.7479e+00, -1.9032e+00,  5.4002e+00, -1.7212e+00, -5.6588e+00,\n",
      "        -3.4615e+00, -4.5153e+00, -6.3735e+00,  3.6458e+00,  4.4269e+01,\n",
      "         3.4993e+01,  3.1977e+01,  5.3025e+01,  2.0722e+01,  3.1327e+01,\n",
      "         3.1147e+01,  1.4411e+01,  4.4006e+01,  3.9684e+01, -4.6582e+00,\n",
      "         4.2708e+00, -8.6355e-01, -4.2294e+00, -4.6582e+00, -3.1897e+00,\n",
      "        -5.6588e+00,  3.6599e+00, -5.9034e-03, -2.7609e+00, -2.8365e+00,\n",
      "        -1.5782e+00, -4.5153e+00, -5.9447e+00, -4.7479e+00,  1.7718e+01,\n",
      "         9.9404e+00,  1.7485e+00,  3.1414e+00,  7.3957e+00,  1.3704e-01,\n",
      "         2.7998e-01, -3.0859e+00,  4.3996e+00,  1.3659e+01, -1.8359e+00,\n",
      "        -4.2061e-01,  1.8230e+01,  3.4558e+01,  1.9901e+01,  3.3883e+01,\n",
      "         6.5604e+00,  1.4654e+01,  2.6851e+01,  2.6218e+01,  1.0016e+01,\n",
      "        -1.3473e-01,  2.5150e+01, -2.9038e+00, -7.0649e-01,  3.3516e+00,\n",
      "         6.2745e+00,  3.8420e+00,  1.1905e+01,  3.2170e+00, -1.0456e+00,\n",
      "        -1.9423e+00, -2.2282e+00, -2.4609e+00,  9.7275e+00, -5.7766e-01,\n",
      "         9.9936e+00,  5.5964e+00, -4.8011e+00,  7.2892e+00,  4.2292e-01,\n",
      "        -3.5147e+00,  5.7675e+00,  3.2383e+01, -3.6576e+00, -3.3089e-01,\n",
      "        -1.1885e+00, -3.1756e+00, -3.8151e-01,  4.4278e+00,  2.2513e+01,\n",
      "         1.4736e+01, -1.9423e+00, -2.0462e+00, -2.8000e+00, -2.6935e+00,\n",
      "         8.9084e-01, -3.0859e+00, -1.6173e+00, -2.5141e+00, -4.3723e+00,\n",
      "         5.5964e+00, -1.0974e-01, -2.8000e+00, -2.7077e+00,  3.8337e+00,\n",
      "         1.6241e+01,  4.8958e+00,  3.5124e+01,  8.4045e+00]) Cost: 195.448898\n",
      "Epochs 9100/10000 hypothesis: tensor([ 3.0529e+01,  5.3418e+00,  4.8868e+01,  4.9338e+01,  1.4397e+01,\n",
      "         4.9805e+01,  6.0217e+01,  5.9663e+00,  4.3691e+01,  3.9784e+01,\n",
      "         3.5765e+01,  4.7577e+01,  1.6605e+01,  1.6522e+01,  4.9314e+01,\n",
      "         2.7212e+01,  2.7188e+01,  5.0925e+01,  1.4759e+01,  5.8017e+01,\n",
      "         4.5680e+01,  3.7120e+01,  3.6929e+01,  2.7427e+01,  3.8622e+01,\n",
      "         3.5230e+01, -2.7606e+00,  1.4045e+00, -5.0874e+00, -4.3712e+00,\n",
      "        -5.0874e+00, -4.3385e-01, -5.5171e+00, -1.7065e+00, -4.8009e+00,\n",
      "        -4.7494e+00, -1.9012e+00,  5.4005e+00, -1.7230e+00, -5.6603e+00,\n",
      "        -3.4603e+00, -4.5144e+00, -6.3765e+00,  3.6467e+00,  4.4271e+01,\n",
      "         3.4997e+01,  3.1976e+01,  5.3026e+01,  2.0720e+01,  3.1330e+01,\n",
      "         3.1149e+01,  1.4414e+01,  4.4008e+01,  3.9686e+01, -4.6577e+00,\n",
      "         4.2712e+00, -8.6356e-01, -4.2279e+00, -4.6577e+00, -3.1903e+00,\n",
      "        -5.6603e+00,  3.6632e+00, -4.1388e-03, -2.7606e+00, -2.8358e+00,\n",
      "        -1.5797e+00, -4.5144e+00, -5.9468e+00, -4.7494e+00,  1.7714e+01,\n",
      "         9.9386e+00,  1.7497e+00,  3.1418e+00,  7.3934e+00,  1.3910e-01,\n",
      "         2.8233e-01, -3.0820e+00,  4.3979e+00,  1.3657e+01, -1.8332e+00,\n",
      "        -4.1733e-01,  1.8226e+01,  3.4555e+01,  1.9898e+01,  3.3877e+01,\n",
      "         6.5577e+00,  1.4651e+01,  2.6845e+01,  2.6213e+01,  1.0014e+01,\n",
      "        -1.3085e-01,  2.5143e+01, -2.9038e+00, -7.0380e-01,  3.3530e+00,\n",
      "         6.2712e+00,  3.8414e+00,  1.1904e+01,  3.2170e+00, -1.0418e+00,\n",
      "        -1.9362e+00, -2.2226e+00, -2.4576e+00,  9.7326e+00, -5.7709e-01,\n",
      "         9.9901e+00,  5.5953e+00, -4.8009e+00,  7.2904e+00,  4.2557e-01,\n",
      "        -3.5118e+00,  5.7715e+00,  3.2379e+01, -3.6550e+00, -3.2558e-01,\n",
      "        -1.1850e+00, -3.1738e+00, -3.8236e-01,  4.4309e+00,  2.2511e+01,\n",
      "         1.4735e+01, -1.9362e+00, -2.0444e+00, -2.7956e+00, -2.6926e+00,\n",
      "         8.9025e-01, -3.0820e+00, -1.6147e+00, -2.5091e+00, -4.3712e+00,\n",
      "         5.5953e+00, -1.1241e-01, -2.7956e+00, -2.7091e+00,  3.8342e+00,\n",
      "         1.6243e+01,  4.8956e+00,  3.5118e+01,  8.4032e+00]) Cost: 195.432739\n",
      "Epochs 9200/10000 hypothesis: tensor([ 3.0527e+01,  5.3450e+00,  4.8865e+01,  4.9339e+01,  1.4398e+01,\n",
      "         4.9807e+01,  6.0221e+01,  5.9689e+00,  4.3693e+01,  3.9787e+01,\n",
      "         3.5769e+01,  4.7580e+01,  1.6607e+01,  1.6526e+01,  4.9314e+01,\n",
      "         2.7214e+01,  2.7189e+01,  5.0924e+01,  1.4760e+01,  5.8018e+01,\n",
      "         4.5683e+01,  3.7122e+01,  3.6929e+01,  2.7426e+01,  3.8619e+01,\n",
      "         3.5232e+01, -2.7603e+00,  1.4079e+00, -5.0877e+00, -4.3700e+00,\n",
      "        -5.0877e+00, -4.3298e-01, -5.5183e+00, -1.7058e+00, -4.8006e+00,\n",
      "        -4.7509e+00, -1.8991e+00,  5.4009e+00, -1.7248e+00, -5.6618e+00,\n",
      "        -3.4591e+00, -4.5136e+00, -6.3795e+00,  3.6476e+00,  4.4273e+01,\n",
      "         3.5001e+01,  3.1975e+01,  5.3027e+01,  2.0719e+01,  3.1332e+01,\n",
      "         3.1151e+01,  1.4417e+01,  4.4011e+01,  3.9687e+01, -4.6571e+00,\n",
      "         4.2715e+00, -8.6357e-01, -4.2265e+00, -4.6571e+00, -3.1909e+00,\n",
      "        -5.6618e+00,  3.6666e+00, -2.3770e-03, -2.7603e+00, -2.8352e+00,\n",
      "        -1.5812e+00, -4.5136e+00, -5.9489e+00, -4.7509e+00,  1.7711e+01,\n",
      "         9.9368e+00,  1.7509e+00,  3.1422e+00,  7.3910e+00,  1.4116e-01,\n",
      "         2.8469e-01, -3.0782e+00,  4.3961e+00,  1.3655e+01, -1.8304e+00,\n",
      "        -4.1404e-01,  1.8223e+01,  3.4551e+01,  1.9895e+01,  3.3871e+01,\n",
      "         6.5549e+00,  1.4647e+01,  2.6839e+01,  2.6209e+01,  1.0012e+01,\n",
      "        -1.2698e-01,  2.5136e+01, -2.9039e+00, -7.0111e-01,  3.3544e+00,\n",
      "         6.2678e+00,  3.8409e+00,  1.1902e+01,  3.2170e+00, -1.0379e+00,\n",
      "        -1.9300e+00, -2.2171e+00, -2.4543e+00,  9.7377e+00, -5.7651e-01,\n",
      "         9.9865e+00,  5.5942e+00, -4.8006e+00,  7.2915e+00,  4.2822e-01,\n",
      "        -3.5088e+00,  5.7756e+00,  3.2374e+01, -3.6524e+00, -3.2028e-01,\n",
      "        -1.1815e+00, -3.1720e+00, -3.8320e-01,  4.4340e+00,  2.2509e+01,\n",
      "         1.4735e+01, -1.9300e+00, -2.0427e+00, -2.7912e+00, -2.6916e+00,\n",
      "         8.8966e-01, -3.0782e+00, -1.6121e+00, -2.5041e+00, -4.3700e+00,\n",
      "         5.5942e+00, -1.1507e-01, -2.7912e+00, -2.7106e+00,  3.8348e+00,\n",
      "         1.6245e+01,  4.8954e+00,  3.5113e+01,  8.4019e+00]) Cost: 195.416641\n",
      "Epochs 9300/10000 hypothesis: tensor([ 3.0525e+01,  5.3481e+00,  4.8861e+01,  4.9341e+01,  1.4399e+01,\n",
      "         4.9810e+01,  6.0225e+01,  5.9715e+00,  4.3694e+01,  3.9789e+01,\n",
      "         3.5772e+01,  4.7583e+01,  1.6610e+01,  1.6530e+01,  4.9314e+01,\n",
      "         2.7216e+01,  2.7190e+01,  5.0923e+01,  1.4761e+01,  5.8019e+01,\n",
      "         4.5686e+01,  3.7125e+01,  3.6929e+01,  2.7425e+01,  3.8617e+01,\n",
      "         3.5234e+01, -2.7601e+00,  1.4113e+00, -5.0880e+00, -4.3689e+00,\n",
      "        -5.0880e+00, -4.3210e-01, -5.5195e+00, -1.7052e+00, -4.8004e+00,\n",
      "        -4.7523e+00, -1.8971e+00,  5.4012e+00, -1.7266e+00, -5.6634e+00,\n",
      "        -3.4579e+00, -4.5127e+00, -6.3825e+00,  3.6485e+00,  4.4275e+01,\n",
      "         3.5005e+01,  3.1973e+01,  5.3028e+01,  2.0717e+01,  3.1335e+01,\n",
      "         3.1153e+01,  1.4420e+01,  4.4013e+01,  3.9688e+01, -4.6566e+00,\n",
      "         4.2719e+00, -8.6359e-01, -4.2251e+00, -4.6566e+00, -3.1916e+00,\n",
      "        -5.6634e+00,  3.6699e+00, -6.1643e-04, -2.7601e+00, -2.8345e+00,\n",
      "        -1.5827e+00, -4.5127e+00, -5.9510e+00, -4.7523e+00,  1.7708e+01,\n",
      "         9.9350e+00,  1.7520e+00,  3.1426e+00,  7.3887e+00,  1.4321e-01,\n",
      "         2.8704e-01, -3.0744e+00,  4.3944e+00,  1.3654e+01, -1.8277e+00,\n",
      "        -4.1077e-01,  1.8219e+01,  3.4548e+01,  1.9892e+01,  3.3865e+01,\n",
      "         6.5521e+00,  1.4644e+01,  2.6833e+01,  2.6205e+01,  1.0009e+01,\n",
      "        -1.2311e-01,  2.5129e+01, -2.9039e+00, -6.9842e-01,  3.3558e+00,\n",
      "         6.2645e+00,  3.8404e+00,  1.1901e+01,  3.2170e+00, -1.0341e+00,\n",
      "        -1.9238e+00, -2.2115e+00, -2.4511e+00,  9.7428e+00, -5.7593e-01,\n",
      "         9.9830e+00,  5.5931e+00, -4.8004e+00,  7.2926e+00,  4.3087e-01,\n",
      "        -3.5059e+00,  5.7796e+00,  3.2369e+01, -3.6498e+00, -3.1499e-01,\n",
      "        -1.1780e+00, -3.1702e+00, -3.8405e-01,  4.4371e+00,  2.2508e+01,\n",
      "         1.4735e+01, -1.9238e+00, -2.0409e+00, -2.7868e+00, -2.6907e+00,\n",
      "         8.8907e-01, -3.0744e+00, -1.6094e+00, -2.4991e+00, -4.3689e+00,\n",
      "         5.5931e+00, -1.1773e-01, -2.7868e+00, -2.7120e+00,  3.8354e+00,\n",
      "         1.6247e+01,  4.8953e+00,  3.5107e+01,  8.4006e+00]) Cost: 195.400574\n",
      "Epochs 9400/10000 hypothesis: tensor([ 3.0523e+01,  5.3512e+00,  4.8858e+01,  4.9342e+01,  1.4400e+01,\n",
      "         4.9813e+01,  6.0229e+01,  5.9740e+00,  4.3696e+01,  3.9791e+01,\n",
      "         3.5776e+01,  4.7586e+01,  1.6612e+01,  1.6534e+01,  4.9314e+01,\n",
      "         2.7218e+01,  2.7191e+01,  5.0922e+01,  1.4762e+01,  5.8020e+01,\n",
      "         4.5690e+01,  3.7128e+01,  3.6928e+01,  2.7423e+01,  3.8614e+01,\n",
      "         3.5236e+01, -2.7598e+00,  1.4147e+00, -5.0884e+00, -4.3678e+00,\n",
      "        -5.0884e+00, -4.3123e-01, -5.5208e+00, -1.7046e+00, -4.8001e+00,\n",
      "        -4.7538e+00, -1.8951e+00,  5.4015e+00, -1.7283e+00, -5.6649e+00,\n",
      "        -3.4567e+00, -4.5119e+00, -6.3855e+00,  3.6494e+00,  4.4276e+01,\n",
      "         3.5009e+01,  3.1972e+01,  5.3029e+01,  2.0715e+01,  3.1337e+01,\n",
      "         3.1155e+01,  1.4424e+01,  4.4016e+01,  3.9689e+01, -4.6560e+00,\n",
      "         4.2723e+00, -8.6360e-01, -4.2236e+00, -4.6560e+00, -3.1922e+00,\n",
      "        -5.6649e+00,  3.6732e+00,  1.1418e-03, -2.7598e+00, -2.8339e+00,\n",
      "        -1.5842e+00, -4.5119e+00, -5.9531e+00, -4.7538e+00,  1.7704e+01,\n",
      "         9.9332e+00,  1.7532e+00,  3.1430e+00,  7.3864e+00,  1.4527e-01,\n",
      "         2.8939e-01, -3.0707e+00,  4.3926e+00,  1.3652e+01, -1.8250e+00,\n",
      "        -4.0749e-01,  1.8215e+01,  3.4544e+01,  1.9889e+01,  3.3859e+01,\n",
      "         6.5494e+00,  1.4641e+01,  2.6827e+01,  2.6200e+01,  1.0007e+01,\n",
      "        -1.1924e-01,  2.5121e+01, -2.9039e+00, -6.9574e-01,  3.3572e+00,\n",
      "         6.2611e+00,  3.8399e+00,  1.1899e+01,  3.2171e+00, -1.0303e+00,\n",
      "        -1.9177e+00, -2.2059e+00, -2.4478e+00,  9.7478e+00, -5.7535e-01,\n",
      "         9.9795e+00,  5.5920e+00, -4.8001e+00,  7.2937e+00,  4.3351e-01,\n",
      "        -3.5030e+00,  5.7836e+00,  3.2364e+01, -3.6471e+00, -3.0970e-01,\n",
      "        -1.1744e+00, -3.1684e+00, -3.8489e-01,  4.4401e+00,  2.2506e+01,\n",
      "         1.4734e+01, -1.9177e+00, -2.0392e+00, -2.7824e+00, -2.6897e+00,\n",
      "         8.8848e-01, -3.0707e+00, -1.6068e+00, -2.4942e+00, -4.3678e+00,\n",
      "         5.5920e+00, -1.2039e-01, -2.7824e+00, -2.7135e+00,  3.8359e+00,\n",
      "         1.6250e+01,  4.8951e+00,  3.5101e+01,  8.3993e+00]) Cost: 195.384506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 9500/10000 hypothesis: tensor([ 3.0521e+01,  5.3543e+00,  4.8855e+01,  4.9344e+01,  1.4401e+01,\n",
      "         4.9816e+01,  6.0233e+01,  5.9766e+00,  4.3697e+01,  3.9793e+01,\n",
      "         3.5780e+01,  4.7589e+01,  1.6615e+01,  1.6538e+01,  4.9314e+01,\n",
      "         2.7220e+01,  2.7191e+01,  5.0922e+01,  1.4763e+01,  5.8022e+01,\n",
      "         4.5693e+01,  3.7130e+01,  3.6928e+01,  2.7422e+01,  3.8612e+01,\n",
      "         3.5237e+01, -2.7595e+00,  1.4181e+00, -5.0887e+00, -4.3666e+00,\n",
      "        -5.0887e+00, -4.3036e-01, -5.5220e+00, -1.7040e+00, -4.7999e+00,\n",
      "        -4.7553e+00, -1.8930e+00,  5.4018e+00, -1.7301e+00, -5.6664e+00,\n",
      "        -3.4555e+00, -4.5111e+00, -6.3885e+00,  3.6503e+00,  4.4278e+01,\n",
      "         3.5014e+01,  3.1971e+01,  5.3030e+01,  2.0714e+01,  3.1340e+01,\n",
      "         3.1157e+01,  1.4427e+01,  4.4018e+01,  3.9690e+01, -4.6555e+00,\n",
      "         4.2726e+00, -8.6362e-01, -4.2222e+00, -4.6555e+00, -3.1928e+00,\n",
      "        -5.6664e+00,  3.6765e+00,  2.8999e-03, -2.7595e+00, -2.8332e+00,\n",
      "        -1.5857e+00, -4.5111e+00, -5.9552e+00, -4.7553e+00,  1.7701e+01,\n",
      "         9.9314e+00,  1.7544e+00,  3.1434e+00,  7.3841e+00,  1.4732e-01,\n",
      "         2.9174e-01, -3.0669e+00,  4.3909e+00,  1.3650e+01, -1.8223e+00,\n",
      "        -4.0422e-01,  1.8211e+01,  3.4541e+01,  1.9886e+01,  3.3853e+01,\n",
      "         6.5466e+00,  1.4637e+01,  2.6821e+01,  2.6196e+01,  1.0005e+01,\n",
      "        -1.1538e-01,  2.5114e+01, -2.9040e+00, -6.9305e-01,  3.3586e+00,\n",
      "         6.2578e+00,  3.8394e+00,  1.1898e+01,  3.2171e+00, -1.0265e+00,\n",
      "        -1.9115e+00, -2.2003e+00, -2.4446e+00,  9.7529e+00, -5.7478e-01,\n",
      "         9.9760e+00,  5.5909e+00, -4.7999e+00,  7.2949e+00,  4.3616e-01,\n",
      "        -3.5001e+00,  5.7876e+00,  3.2359e+01, -3.6445e+00, -3.0442e-01,\n",
      "        -1.1709e+00, -3.1667e+00, -3.8574e-01,  4.4432e+00,  2.2504e+01,\n",
      "         1.4734e+01, -1.9115e+00, -2.0374e+00, -2.7780e+00, -2.6888e+00,\n",
      "         8.8789e-01, -3.0669e+00, -1.6042e+00, -2.4892e+00, -4.3666e+00,\n",
      "         5.5909e+00, -1.2304e-01, -2.7780e+00, -2.7149e+00,  3.8365e+00,\n",
      "         1.6252e+01,  4.8949e+00,  3.5095e+01,  8.3979e+00]) Cost: 195.368484\n",
      "Epochs 9600/10000 hypothesis: tensor([ 3.0519e+01,  5.3574e+00,  4.8852e+01,  4.9345e+01,  1.4402e+01,\n",
      "         4.9818e+01,  6.0236e+01,  5.9792e+00,  4.3699e+01,  3.9795e+01,\n",
      "         3.5784e+01,  4.7592e+01,  1.6617e+01,  1.6542e+01,  4.9315e+01,\n",
      "         2.7223e+01,  2.7192e+01,  5.0921e+01,  1.4764e+01,  5.8023e+01,\n",
      "         4.5697e+01,  3.7133e+01,  3.6928e+01,  2.7421e+01,  3.8609e+01,\n",
      "         3.5239e+01, -2.7593e+00,  1.4214e+00, -5.0891e+00, -4.3655e+00,\n",
      "        -5.0891e+00, -4.2949e-01, -5.5232e+00, -1.7034e+00, -4.7996e+00,\n",
      "        -4.7567e+00, -1.8910e+00,  5.4022e+00, -1.7319e+00, -5.6679e+00,\n",
      "        -3.4543e+00, -4.5102e+00, -6.3915e+00,  3.6512e+00,  4.4280e+01,\n",
      "         3.5018e+01,  3.1970e+01,  5.3031e+01,  2.0712e+01,  3.1343e+01,\n",
      "         3.1159e+01,  1.4430e+01,  4.4021e+01,  3.9692e+01, -4.6549e+00,\n",
      "         4.2730e+00, -8.6363e-01, -4.2208e+00, -4.6549e+00, -3.1934e+00,\n",
      "        -5.6679e+00,  3.6798e+00,  4.6550e-03, -2.7593e+00, -2.8325e+00,\n",
      "        -1.5872e+00, -4.5102e+00, -5.9574e+00, -4.7567e+00,  1.7698e+01,\n",
      "         9.9296e+00,  1.7556e+00,  3.1438e+00,  7.3818e+00,  1.4937e-01,\n",
      "         2.9408e-01, -3.0631e+00,  4.3892e+00,  1.3648e+01, -1.8195e+00,\n",
      "        -4.0095e-01,  1.8207e+01,  3.4537e+01,  1.9883e+01,  3.3848e+01,\n",
      "         6.5439e+00,  1.4634e+01,  2.6815e+01,  2.6192e+01,  1.0003e+01,\n",
      "        -1.1152e-01,  2.5107e+01, -2.9040e+00, -6.9038e-01,  3.3600e+00,\n",
      "         6.2545e+00,  3.8389e+00,  1.1897e+01,  3.2171e+00, -1.0227e+00,\n",
      "        -1.9054e+00, -2.1948e+00, -2.4413e+00,  9.7580e+00, -5.7420e-01,\n",
      "         9.9725e+00,  5.5898e+00, -4.7996e+00,  7.2960e+00,  4.3880e-01,\n",
      "        -3.4972e+00,  5.7916e+00,  3.2354e+01, -3.6419e+00, -2.9914e-01,\n",
      "        -1.1674e+00, -3.1649e+00, -3.8658e-01,  4.4463e+00,  2.2502e+01,\n",
      "         1.4734e+01, -1.9054e+00, -2.0357e+00, -2.7736e+00, -2.6878e+00,\n",
      "         8.8730e-01, -3.0631e+00, -1.6016e+00, -2.4842e+00, -4.3655e+00,\n",
      "         5.5898e+00, -1.2569e-01, -2.7736e+00, -2.7164e+00,  3.8370e+00,\n",
      "         1.6254e+01,  4.8948e+00,  3.5089e+01,  8.3966e+00]) Cost: 195.352478\n",
      "Epochs 9700/10000 hypothesis: tensor([ 3.0517e+01,  5.3606e+00,  4.8849e+01,  4.9346e+01,  1.4402e+01,\n",
      "         4.9821e+01,  6.0240e+01,  5.9818e+00,  4.3701e+01,  3.9797e+01,\n",
      "         3.5788e+01,  4.7595e+01,  1.6619e+01,  1.6546e+01,  4.9315e+01,\n",
      "         2.7225e+01,  2.7193e+01,  5.0920e+01,  1.4765e+01,  5.8024e+01,\n",
      "         4.5700e+01,  3.7136e+01,  3.6927e+01,  2.7420e+01,  3.8606e+01,\n",
      "         3.5241e+01, -2.7590e+00,  1.4248e+00, -5.0894e+00, -4.3644e+00,\n",
      "        -5.0894e+00, -4.2862e-01, -5.5244e+00, -1.7028e+00, -4.7994e+00,\n",
      "        -4.7582e+00, -1.8890e+00,  5.4025e+00, -1.7337e+00, -5.6694e+00,\n",
      "        -3.4531e+00, -4.5094e+00, -6.3945e+00,  3.6521e+00,  4.4282e+01,\n",
      "         3.5022e+01,  3.1969e+01,  5.3032e+01,  2.0710e+01,  3.1345e+01,\n",
      "         3.1160e+01,  1.4433e+01,  4.4023e+01,  3.9693e+01, -4.6544e+00,\n",
      "         4.2734e+00, -8.6364e-01, -4.2194e+00, -4.6544e+00, -3.1940e+00,\n",
      "        -5.6694e+00,  3.6831e+00,  6.4090e-03, -2.7590e+00, -2.8319e+00,\n",
      "        -1.5887e+00, -4.5094e+00, -5.9595e+00, -4.7582e+00,  1.7695e+01,\n",
      "         9.9278e+00,  1.7568e+00,  3.1442e+00,  7.3795e+00,  1.5142e-01,\n",
      "         2.9643e-01, -3.0593e+00,  4.3874e+00,  1.3646e+01, -1.8168e+00,\n",
      "        -3.9768e-01,  1.8203e+01,  3.4534e+01,  1.9880e+01,  3.3842e+01,\n",
      "         6.5411e+00,  1.4631e+01,  2.6809e+01,  2.6187e+01,  1.0001e+01,\n",
      "        -1.0766e-01,  2.5100e+01, -2.9040e+00, -6.8770e-01,  3.3614e+00,\n",
      "         6.2511e+00,  3.8383e+00,  1.1895e+01,  3.2171e+00, -1.0189e+00,\n",
      "        -1.8992e+00, -2.1892e+00, -2.4381e+00,  9.7630e+00, -5.7363e-01,\n",
      "         9.9690e+00,  5.5887e+00, -4.7994e+00,  7.2971e+00,  4.4144e-01,\n",
      "        -3.4943e+00,  5.7956e+00,  3.2349e+01, -3.6393e+00, -2.9386e-01,\n",
      "        -1.1639e+00, -3.1631e+00, -3.8743e-01,  4.4493e+00,  2.2501e+01,\n",
      "         1.4734e+01, -1.8992e+00, -2.0340e+00, -2.7693e+00, -2.6869e+00,\n",
      "         8.8672e-01, -3.0593e+00, -1.5989e+00, -2.4793e+00, -4.3644e+00,\n",
      "         5.5887e+00, -1.2835e-01, -2.7693e+00, -2.7178e+00,  3.8376e+00,\n",
      "         1.6257e+01,  4.8946e+00,  3.5084e+01,  8.3953e+00]) Cost: 195.336487\n",
      "Epochs 9800/10000 hypothesis: tensor([ 3.0515e+01,  5.3637e+00,  4.8846e+01,  4.9348e+01,  1.4403e+01,\n",
      "         4.9824e+01,  6.0244e+01,  5.9844e+00,  4.3702e+01,  3.9800e+01,\n",
      "         3.5792e+01,  4.7598e+01,  1.6622e+01,  1.6550e+01,  4.9315e+01,\n",
      "         2.7227e+01,  2.7194e+01,  5.0919e+01,  1.4766e+01,  5.8025e+01,\n",
      "         4.5703e+01,  3.7138e+01,  3.6927e+01,  2.7418e+01,  3.8604e+01,\n",
      "         3.5243e+01, -2.7587e+00,  1.4282e+00, -5.0898e+00, -4.3632e+00,\n",
      "        -5.0898e+00, -4.2775e-01, -5.5257e+00, -1.7021e+00, -4.7991e+00,\n",
      "        -4.7597e+00, -1.8869e+00,  5.4028e+00, -1.7355e+00, -5.6710e+00,\n",
      "        -3.4519e+00, -4.5085e+00, -6.3975e+00,  3.6530e+00,  4.4283e+01,\n",
      "         3.5026e+01,  3.1967e+01,  5.3033e+01,  2.0709e+01,  3.1348e+01,\n",
      "         3.1162e+01,  1.4437e+01,  4.4026e+01,  3.9694e+01, -4.6538e+00,\n",
      "         4.2737e+00, -8.6366e-01, -4.2179e+00, -4.6538e+00, -3.1947e+00,\n",
      "        -5.6710e+00,  3.6864e+00,  8.1617e-03, -2.7587e+00, -2.8312e+00,\n",
      "        -1.5902e+00, -4.5085e+00, -5.9616e+00, -4.7597e+00,  1.7691e+01,\n",
      "         9.9260e+00,  1.7579e+00,  3.1446e+00,  7.3772e+00,  1.5347e-01,\n",
      "         2.9877e-01, -3.0555e+00,  4.3857e+00,  1.3644e+01, -1.8141e+00,\n",
      "        -3.9442e-01,  1.8200e+01,  3.4530e+01,  1.9877e+01,  3.3836e+01,\n",
      "         6.5384e+00,  1.4627e+01,  2.6804e+01,  2.6183e+01,  9.9985e+00,\n",
      "        -1.0381e-01,  2.5093e+01, -2.9041e+00, -6.8502e-01,  3.3628e+00,\n",
      "         6.2478e+00,  3.8378e+00,  1.1894e+01,  3.2171e+00, -1.0151e+00,\n",
      "        -1.8931e+00, -2.1837e+00, -2.4348e+00,  9.7681e+00, -5.7305e-01,\n",
      "         9.9655e+00,  5.5876e+00, -4.7991e+00,  7.2982e+00,  4.4407e-01,\n",
      "        -3.4914e+00,  5.7996e+00,  3.2344e+01, -3.6367e+00, -2.8859e-01,\n",
      "        -1.1604e+00, -3.1613e+00, -3.8827e-01,  4.4524e+00,  2.2499e+01,\n",
      "         1.4733e+01, -1.8931e+00, -2.0322e+00, -2.7649e+00, -2.6859e+00,\n",
      "         8.8613e-01, -3.0555e+00, -1.5963e+00, -2.4743e+00, -4.3632e+00,\n",
      "         5.5876e+00, -1.3099e-01, -2.7649e+00, -2.7193e+00,  3.8381e+00,\n",
      "         1.6259e+01,  4.8944e+00,  3.5078e+01,  8.3940e+00]) Cost: 195.320572\n",
      "Epochs 9900/10000 hypothesis: tensor([ 3.0513e+01,  5.3668e+00,  4.8842e+01,  4.9349e+01,  1.4404e+01,\n",
      "         4.9827e+01,  6.0248e+01,  5.9869e+00,  4.3704e+01,  3.9802e+01,\n",
      "         3.5796e+01,  4.7601e+01,  1.6624e+01,  1.6554e+01,  4.9315e+01,\n",
      "         2.7229e+01,  2.7195e+01,  5.0919e+01,  1.4767e+01,  5.8026e+01,\n",
      "         4.5707e+01,  3.7141e+01,  3.6927e+01,  2.7417e+01,  3.8601e+01,\n",
      "         3.5245e+01, -2.7585e+00,  1.4316e+00, -5.0901e+00, -4.3621e+00,\n",
      "        -5.0901e+00, -4.2688e-01, -5.5269e+00, -1.7015e+00, -4.7989e+00,\n",
      "        -4.7611e+00, -1.8849e+00,  5.4032e+00, -1.7373e+00, -5.6725e+00,\n",
      "        -3.4507e+00, -4.5077e+00, -6.4005e+00,  3.6539e+00,  4.4285e+01,\n",
      "         3.5030e+01,  3.1966e+01,  5.3034e+01,  2.0707e+01,  3.1350e+01,\n",
      "         3.1164e+01,  1.4440e+01,  4.4028e+01,  3.9695e+01, -4.6533e+00,\n",
      "         4.2741e+00, -8.6367e-01, -4.2165e+00, -4.6533e+00, -3.1953e+00,\n",
      "        -5.6725e+00,  3.6897e+00,  9.9133e-03, -2.7585e+00, -2.8306e+00,\n",
      "        -1.5917e+00, -4.5077e+00, -5.9637e+00, -4.7611e+00,  1.7688e+01,\n",
      "         9.9242e+00,  1.7591e+00,  3.1450e+00,  7.3749e+00,  1.5551e-01,\n",
      "         3.0111e-01, -3.0517e+00,  4.3840e+00,  1.3642e+01, -1.8114e+00,\n",
      "        -3.9115e-01,  1.8196e+01,  3.4527e+01,  1.9874e+01,  3.3830e+01,\n",
      "         6.5357e+00,  1.4624e+01,  2.6798e+01,  2.6179e+01,  9.9963e+00,\n",
      "        -9.9960e-02,  2.5086e+01, -2.9041e+00, -6.8235e-01,  3.3641e+00,\n",
      "         6.2445e+00,  3.8373e+00,  1.1893e+01,  3.2171e+00, -1.0113e+00,\n",
      "        -1.8869e+00, -2.1781e+00, -2.4316e+00,  9.7731e+00, -5.7248e-01,\n",
      "         9.9620e+00,  5.5865e+00, -4.7989e+00,  7.2994e+00,  4.4671e-01,\n",
      "        -3.4885e+00,  5.8036e+00,  3.2339e+01, -3.6341e+00, -2.8333e-01,\n",
      "        -1.1569e+00, -3.1596e+00, -3.8911e-01,  4.4554e+00,  2.2497e+01,\n",
      "         1.4733e+01, -1.8869e+00, -2.0305e+00, -2.7605e+00, -2.6850e+00,\n",
      "         8.8554e-01, -3.0517e+00, -1.5937e+00, -2.4693e+00, -4.3621e+00,\n",
      "         5.5865e+00, -1.3364e-01, -2.7605e+00, -2.7207e+00,  3.8387e+00,\n",
      "         1.6261e+01,  4.8943e+00,  3.5072e+01,  8.3927e+00]) Cost: 195.304657\n",
      "Epochs 10000/10000 hypothesis: tensor([ 3.0511e+01,  5.3699e+00,  4.8839e+01,  4.9351e+01,  1.4405e+01,\n",
      "         4.9829e+01,  6.0252e+01,  5.9895e+00,  4.3706e+01,  3.9804e+01,\n",
      "         3.5800e+01,  4.7605e+01,  1.6627e+01,  1.6558e+01,  4.9315e+01,\n",
      "         2.7231e+01,  2.7195e+01,  5.0918e+01,  1.4768e+01,  5.8027e+01,\n",
      "         4.5710e+01,  3.7144e+01,  3.6927e+01,  2.7416e+01,  3.8599e+01,\n",
      "         3.5247e+01, -2.7582e+00,  1.4349e+00, -5.0904e+00, -4.3610e+00,\n",
      "        -5.0904e+00, -4.2601e-01, -5.5281e+00, -1.7009e+00, -4.7986e+00,\n",
      "        -4.7626e+00, -1.8829e+00,  5.4035e+00, -1.7390e+00, -5.6740e+00,\n",
      "        -3.4496e+00, -4.5069e+00, -6.4035e+00,  3.6548e+00,  4.4287e+01,\n",
      "         3.5034e+01,  3.1965e+01,  5.3035e+01,  2.0706e+01,  3.1353e+01,\n",
      "         3.1166e+01,  1.4443e+01,  4.4031e+01,  3.9697e+01, -4.6528e+00,\n",
      "         4.2745e+00, -8.6369e-01, -4.2151e+00, -4.6528e+00, -3.1959e+00,\n",
      "        -5.6740e+00,  3.6930e+00,  1.1662e-02, -2.7582e+00, -2.8299e+00,\n",
      "        -1.5931e+00, -4.5069e+00, -5.9658e+00, -4.7626e+00,  1.7685e+01,\n",
      "         9.9224e+00,  1.7603e+00,  3.1455e+00,  7.3726e+00,  1.5755e-01,\n",
      "         3.0344e-01, -3.0480e+00,  4.3822e+00,  1.3640e+01, -1.8087e+00,\n",
      "        -3.8790e-01,  1.8192e+01,  3.4523e+01,  1.9871e+01,  3.3824e+01,\n",
      "         6.5329e+00,  1.4620e+01,  2.6792e+01,  2.6175e+01,  9.9941e+00,\n",
      "        -9.6114e-02,  2.5079e+01, -2.9041e+00, -6.7968e-01,  3.3655e+00,\n",
      "         6.2411e+00,  3.8368e+00,  1.1891e+01,  3.2172e+00, -1.0075e+00,\n",
      "        -1.8808e+00, -2.1726e+00, -2.4283e+00,  9.7782e+00, -5.7190e-01,\n",
      "         9.9585e+00,  5.5854e+00, -4.7986e+00,  7.3005e+00,  4.4934e-01,\n",
      "        -3.4856e+00,  5.8076e+00,  3.2334e+01, -3.6315e+00, -2.7807e-01,\n",
      "        -1.1534e+00, -3.1578e+00, -3.8995e-01,  4.4585e+00,  2.2495e+01,\n",
      "         1.4733e+01, -1.8808e+00, -2.0288e+00, -2.7562e+00, -2.6840e+00,\n",
      "         8.8496e-01, -3.0480e+00, -1.5911e+00, -2.4644e+00, -4.3610e+00,\n",
      "         5.5854e+00, -1.3628e-01, -2.7562e+00, -2.7222e+00,  3.8393e+00,\n",
      "         1.6263e+01,  4.8941e+00,  3.5066e+01,  8.3914e+00]) Cost: 195.288773\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10000\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = x_train.float().matmul(W) + b\n",
    "    cost = torch.mean((hypothesis - y_train.float())**2)   \n",
    "# torch.mean을 해주면 최종 값의 size가 torch.Size([])이 됨. 따라서 hypothesis(x_train으로 만든)나 y_train 값중 하나라고 nan값이 있으면 cost도 nan 됨\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "    if(epoch%100==0):\n",
    "        print('Epochs {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047b5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "645df2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "226df7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "        \n",
    "model = PModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a11dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0e83e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb790c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-207-5fbc32b2f35d>:4: UserWarning: Using a target size (torch.Size([139, 1])) that is different to the input size (torch.Size([139])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  cost = F.mse_loss(prediction.squeeze(), y_train.float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/10000 Cost: 502.843536\n",
      "Epoch  200/10000 Cost: 502.676056\n",
      "Epoch  300/10000 Cost: 502.602081\n",
      "Epoch  400/10000 Cost: 502.546600\n",
      "Epoch  500/10000 Cost: 502.501526\n",
      "Epoch  600/10000 Cost: 502.464111\n",
      "Epoch  700/10000 Cost: 502.432526\n",
      "Epoch  800/10000 Cost: 502.405457\n",
      "Epoch  900/10000 Cost: 502.381927\n",
      "Epoch 1000/10000 Cost: 502.360962\n",
      "Epoch 1100/10000 Cost: 502.342010\n",
      "Epoch 1200/10000 Cost: 502.324738\n",
      "Epoch 1300/10000 Cost: 502.308533\n",
      "Epoch 1400/10000 Cost: 502.293365\n",
      "Epoch 1500/10000 Cost: 502.278870\n",
      "Epoch 1600/10000 Cost: 502.264893\n",
      "Epoch 1700/10000 Cost: 502.251343\n",
      "Epoch 1800/10000 Cost: 502.238129\n",
      "Epoch 1900/10000 Cost: 502.225250\n",
      "Epoch 2000/10000 Cost: 502.212463\n",
      "Epoch 2100/10000 Cost: 502.199890\n",
      "Epoch 2200/10000 Cost: 502.187469\n",
      "Epoch 2300/10000 Cost: 502.175140\n",
      "Epoch 2400/10000 Cost: 502.162933\n",
      "Epoch 2500/10000 Cost: 502.150726\n",
      "Epoch 2600/10000 Cost: 502.138611\n",
      "Epoch 2700/10000 Cost: 502.126587\n",
      "Epoch 2800/10000 Cost: 502.114594\n",
      "Epoch 2900/10000 Cost: 502.102570\n",
      "Epoch 3000/10000 Cost: 502.090576\n",
      "Epoch 3100/10000 Cost: 502.078735\n",
      "Epoch 3200/10000 Cost: 502.066864\n",
      "Epoch 3300/10000 Cost: 502.055023\n",
      "Epoch 3400/10000 Cost: 502.043121\n",
      "Epoch 3500/10000 Cost: 502.031250\n",
      "Epoch 3600/10000 Cost: 502.019501\n",
      "Epoch 3700/10000 Cost: 502.007751\n",
      "Epoch 3800/10000 Cost: 501.996002\n",
      "Epoch 3900/10000 Cost: 501.984314\n",
      "Epoch 4000/10000 Cost: 501.972626\n",
      "Epoch 4100/10000 Cost: 501.960938\n",
      "Epoch 4200/10000 Cost: 501.949280\n",
      "Epoch 4300/10000 Cost: 501.937683\n",
      "Epoch 4400/10000 Cost: 501.925995\n",
      "Epoch 4500/10000 Cost: 501.914490\n",
      "Epoch 4600/10000 Cost: 501.902893\n",
      "Epoch 4700/10000 Cost: 501.891296\n",
      "Epoch 4800/10000 Cost: 501.879822\n",
      "Epoch 4900/10000 Cost: 501.868317\n",
      "Epoch 5000/10000 Cost: 501.856842\n",
      "Epoch 5100/10000 Cost: 501.845398\n",
      "Epoch 5200/10000 Cost: 501.833923\n",
      "Epoch 5300/10000 Cost: 501.822510\n",
      "Epoch 5400/10000 Cost: 501.811127\n",
      "Epoch 5500/10000 Cost: 501.799744\n",
      "Epoch 5600/10000 Cost: 501.788422\n",
      "Epoch 5700/10000 Cost: 501.777039\n",
      "Epoch 5800/10000 Cost: 501.765747\n",
      "Epoch 5900/10000 Cost: 501.754425\n",
      "Epoch 6000/10000 Cost: 501.743195\n",
      "Epoch 6100/10000 Cost: 501.731903\n",
      "Epoch 6200/10000 Cost: 501.720673\n",
      "Epoch 6300/10000 Cost: 501.709442\n",
      "Epoch 6400/10000 Cost: 501.698242\n",
      "Epoch 6500/10000 Cost: 501.687012\n",
      "Epoch 6600/10000 Cost: 501.675903\n",
      "Epoch 6700/10000 Cost: 501.664764\n",
      "Epoch 6800/10000 Cost: 501.653687\n",
      "Epoch 6900/10000 Cost: 501.642578\n",
      "Epoch 7000/10000 Cost: 501.631500\n",
      "Epoch 7100/10000 Cost: 501.620422\n",
      "Epoch 7200/10000 Cost: 501.609344\n",
      "Epoch 7300/10000 Cost: 501.598419\n",
      "Epoch 7400/10000 Cost: 501.587402\n",
      "Epoch 7500/10000 Cost: 501.576416\n",
      "Epoch 7600/10000 Cost: 501.565491\n",
      "Epoch 7700/10000 Cost: 501.554535\n",
      "Epoch 7800/10000 Cost: 501.543610\n",
      "Epoch 7900/10000 Cost: 501.532684\n",
      "Epoch 8000/10000 Cost: 501.521881\n",
      "Epoch 8100/10000 Cost: 501.510986\n",
      "Epoch 8200/10000 Cost: 501.500122\n",
      "Epoch 8300/10000 Cost: 501.489349\n",
      "Epoch 8400/10000 Cost: 501.478546\n",
      "Epoch 8500/10000 Cost: 501.467834\n",
      "Epoch 8600/10000 Cost: 501.457062\n",
      "Epoch 8700/10000 Cost: 501.446289\n",
      "Epoch 8800/10000 Cost: 501.435547\n",
      "Epoch 8900/10000 Cost: 501.424866\n",
      "Epoch 9000/10000 Cost: 501.414215\n",
      "Epoch 9100/10000 Cost: 501.403503\n",
      "Epoch 9200/10000 Cost: 501.392883\n",
      "Epoch 9300/10000 Cost: 501.382233\n",
      "Epoch 9400/10000 Cost: 501.371674\n",
      "Epoch 9500/10000 Cost: 501.361115\n",
      "Epoch 9600/10000 Cost: 501.350494\n",
      "Epoch 9700/10000 Cost: 501.339935\n",
      "Epoch 9800/10000 Cost: 501.329376\n",
      "Epoch 9900/10000 Cost: 501.318939\n",
      "Epoch 10000/10000 Cost: 501.308380\n"
     ]
    }
   ],
   "source": [
    "nb_epochs =10000\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "    prediction = model(x_train.float())\n",
    "    cost = F.mse_loss(prediction.squeeze(), y_train.float())\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    cost.backward() \n",
    "    optimizer.step() \n",
    "    \n",
    "    if(epoch%100==0):\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b3d2c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.3392, -0.4443,  0.2725]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4773], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "02b26bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 3])\n",
      "torch.DoubleTensor\n",
      "torch.Size([91, 4])\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "###Test\n",
    "x_test = torch.from_numpy(test_x.values)\n",
    "print(x_test.shape)\n",
    "print(x_test.type())\n",
    "y_test = torch.from_numpy(test_y.values)\n",
    "print(y_test.shape)\n",
    "print(y_test.type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2b1fdc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan\n",
      "10 nan\n",
      "20 nan\n",
      "30 nan\n",
      "40 nan\n",
      "50 nan\n",
      "60 nan\n",
      "70 nan\n",
      "80 nan\n",
      "90 nan\n",
      "100 nan\n",
      "110 nan\n",
      "120 nan\n",
      "130 nan\n",
      "140 nan\n",
      "150 nan\n",
      "160 nan\n",
      "170 nan\n",
      "180 nan\n",
      "190 nan\n",
      "200 nan\n",
      "210 nan\n",
      "220 nan\n",
      "230 nan\n",
      "240 nan\n",
      "250 nan\n",
      "260 nan\n",
      "270 nan\n",
      "280 nan\n",
      "290 nan\n",
      "300 nan\n",
      "310 nan\n",
      "320 nan\n",
      "330 nan\n",
      "340 nan\n",
      "350 nan\n",
      "360 nan\n",
      "370 nan\n",
      "380 nan\n",
      "390 nan\n",
      "400 nan\n",
      "410 nan\n",
      "420 nan\n",
      "430 nan\n",
      "440 nan\n",
      "450 nan\n",
      "460 nan\n",
      "470 nan\n",
      "480 nan\n",
      "490 nan\n",
      "500 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CNDLMembers\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\CNDLMembers\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([91, 4])) that is different to the input size (torch.Size([91, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "model_t = PModel()\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False) \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "for epoch in range(501):\n",
    "    y_pred =model(x_test.float())\n",
    "    loss = criterion(y_pred, y_test.float()) \n",
    "    \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    \n",
    "    if(epoch%10==0):\n",
    "        print(epoch, loss.item())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd533ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
